{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import importlib, os, math\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from ir_crosslingual.induce_multilingual_embedding_space import mono_embedding_loading as mono\n",
    "from ir_crosslingual.induce_multilingual_embedding_space import multi_embedding_learning as multi\n",
    "from ir_crosslingual.induce_multilingual_embedding_space import subspace_creation as sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ir_crosslingual.features.text_based' from '/Users/i500969/Desktop/Admin/Uni-Mannheim/02_Courses/2020_FSS/Information-Retrieval/03_Project/03_Implementation/04_Feature-Extraction/ir-crosslingual/ir_crosslingual/features/text_based.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ir_crosslingual.features import text_based\n",
    "importlib.reload(text_based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ir_crosslingual.features.vector_based' from '/Users/i500969/Desktop/Admin/Uni-Mannheim/02_Courses/2020_FSS/Information-Retrieval/03_Project/03_Implementation/04_Feature-Extraction/ir-crosslingual/ir_crosslingual/features/vector_based.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ir_crosslingual.features import vector_based\n",
    "importlib.reload(vector_based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ir_crosslingual.supervised_classification.sentence_vector_creation' from '/Users/i500969/Desktop/Admin/Uni-Mannheim/02_Courses/2020_FSS/Information-Retrieval/03_Project/03_Implementation/04_Feature-Extraction/ir-crosslingual/ir_crosslingual/supervised_classification/sentence_vector_creation.py'>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ir_crosslingual.supervised_classification import sentence_vector_creation as sentence\n",
    "importlib.reload(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variables and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../../../../04_Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO/IDEA: Include \":\" as special punctuation to look for in equal_occurrence_punctuation\n",
    "tb_features = {'difference_count_words': [text_based.difference_count_tokens, 'preprocessed', False],\n",
    "            'difference_count_punctuation': [text_based.difference_count_tokens, 'preprocessed', True],\n",
    "            'equal_occ_question': [text_based.equal_occurrence_punctuation, 'preprocessed', '?'],\n",
    "            'equal_occ_exclamation': [text_based.equal_occurrence_punctuation, 'preprocessed', '!']\n",
    "           }\n",
    "for word_group in 'noun verb adverb adjective wh pronoun'.split():\n",
    "    tb_features['difference_count_{}'.format(word_group)] = [text_based.difference_count_nltk_tags, 'preprocessed', word_group]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vb_features = {'cosine_similarity': [vector_based.cosine_sim, 'vec']\n",
    "            # 'euclidean_distance': [vector_based.euclidean_dist, 'vec'],\n",
    "            # 'jenson_shannon_distance': [vector_based.jenson_shannon_dist, 'vec'],\n",
    "            # 'wasserstein_distance': [vector_based.wasserstein_dist, 'vec'],\n",
    "              #'greedy_association_similarity': [vector_based.gas, 'word_embeddings']\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from dataset_creation.py as I haven't merged it into this branch yet\n",
    "def create_datasets(europarl_dataset: str, n_train: int, frac_pos: float, n_test: int):\n",
    "    if isinstance(europarl_dataset, str) and os.path.isfile(europarl_dataset):\n",
    "        _, df = tmx_dataframe(europarl_dataset)\n",
    "    else:\n",
    "        df = europarl_dataset\n",
    "    n_train_pos = math.ceil(n_train*frac_pos)\n",
    "    df_train_pos = df[:n_train_pos]\n",
    "    df_train_pos.loc[:, 'translation'] = 1\n",
    "    multiple = math.ceil(n_train/n_train_pos)\n",
    "    df_train_neg = pd.concat([df_train_pos[['source_sentence']]] * multiple, ignore_index=True)[:n_train-n_train_pos]\n",
    "    df_train_neg['target_sentence'] = np.random.choice(df[n_train_pos:-n_test]['target_sentence'],\n",
    "                                                       n_train-n_train_pos)\n",
    "    df_train_neg.loc[:, 'translation'] = 0\n",
    "    df_train = df_train_pos.append(df_train_neg, ignore_index=True)\n",
    "    df_test = df[-n_test:].reset_index(drop=True)\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Parameterize by source and target language\n",
    "def get_sen_embedding(sentence, language):\n",
    "    if language == 'english':\n",
    "        return sen_emb_en[sen_en.index(sentence)]\n",
    "    elif language == 'german':\n",
    "        return sen_emb_de[sen_de.index(sentence)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_word_embeddings(idx, word_embeddings, words_found):\n",
    "    embeddings = list()\n",
    "    for word in words_found[idx]:\n",
    "        embeddings.append(word_embeddings[word])\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Improve code by removing multiple for loops\n",
    "# TODO: Parameterize by source and target language\n",
    "def load_data():\n",
    "    data = pd.DataFrame({'source_sentence': sen_en, 'target_sentence': sen_de})\n",
    "    # Extract train and test data\n",
    "    train_data, test_data = create_datasets(data, n_train=4800, frac_pos=0.7, n_test=200)\n",
    "    data_sets = [train_data, test_data]\n",
    "    origins = {'source': 'english', 'target': 'german'}\n",
    "    for data in data_sets:\n",
    "        for origin, language in origins.items():\n",
    "            data['{}_preprocessed'.format(origin)] = data.apply(lambda row: sentence.preprocess_sentences(sentences=[row['{}_sentence'.format(origin)]], language=language)[0], axis=1)\n",
    "            data['{}_vec'.format(origin)] = data.apply(lambda row: get_sen_embedding(row['{}_sentence'.format(origin)], language), axis=1)\n",
    "    for data in data_sets:\n",
    "        data['source_word_embeddings'] = data.apply(lambda row: get_list_of_word_embeddings(row.name, emb_en, words_found_en), axis=1)\n",
    "        data['target_word_embeddings'] = data.apply(lambda row: get_list_of_word_embeddings(row.name, emb_de, words_found_de), axis=1)\n",
    "    \n",
    "    \n",
    "    # Extract text-based features\n",
    "    for data in [train_data, test_data]:\n",
    "        for name, function in tb_features.items():\n",
    "            print('Start extraction feature {}'.format(name))\n",
    "            data[name] = data.apply(lambda row: function[0](row['source_{}'.format(function[1])], row['target_{}'.format(function[1])], function[2]), axis=1)\n",
    "    \n",
    "    # Extract vector-based features\n",
    "    for data in [train_data, test_data]:\n",
    "        for name, function in vb_features.items():\n",
    "            print('Start extraction feature {}'.format(name))\n",
    "            data[name] = data.apply(lambda row: function[0](row['source_{}'.format(function[1])] @ W, row['target_{}'.format(function[1])]), axis=1)\n",
    "            \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_most_similar_sentence(idx, sentence, test_data, model):\n",
    "    #tmp = pd.DataFrame({'source_sentence': sentence,\n",
    "            #'target_sentence': test_data['target_sentence'], 'target_preprocessed': test_data['target_preprocessed'], 'target_vec': test_data['target_vec'], 'target_word_embeddings': test_data['target_word_embeddings']})\n",
    "    tmp = pd.DataFrame()\n",
    "    #tmp['source_preprocessed'] = tmp.apply(lambda row: test_data['source_preprocessed'].iloc[idx], axis=1)\n",
    "    #tmp['source_word_embeddings'] = tmp.apply(lambda row: test_data['source_word_embeddings'].iloc[idx], axis=1)\n",
    "    #for name, function in tb_features.items():\n",
    "    #    tmp[name] = tmp.apply(lambda row: function[0](row['source_{}'.format(function[1])], row['target_{}'.format(function[1])], function[2]), axis=1)\n",
    "    #for name, function in vb_features.items():\n",
    "    #    tmp[name] = tmp.apply(lambda row: function[0](row['source_{}'.format(function[1])] @ W, row['target_{}'.format(function[1])]), axis=1)\n",
    "    tmp['cosine_similarity'] = cosine_similarity((test_data['source_vec'].iloc[idx] @ W).reshape(1,-1), np.vstack(test_data['target_vec']))[0]\n",
    "    \n",
    "    preds = model.predict_proba(tmp[features])\n",
    "\n",
    "    ranked_indices = preds[:,1].argsort()[::-1]\n",
    "    topk_sen = list(test_data['target_sentence'].iloc[ranked_indices])\n",
    "    topk_prob = preds[:,1][ranked_indices]\n",
    "\n",
    "    print('Done with sentence id {}, top 3: {}'.format(idx, ranked_indices[:3]))\n",
    "    return [topk_sen, topk_prob]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load raw data\n",
    "TODO: Parameterize by source and target language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load word embeddings and projection matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_en, id2word_en, word2id_en = mono.load_monolingual_embedding('{}fastText_mon_emb/wiki.en.vec'.format(data_path), 50000)\n",
    "emb_de, id2word_de, word2id_de = mono.load_monolingual_embedding('{}fastText_mon_emb/wiki.de.vec'.format(data_path), 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13700 valid translation pairs in expert dictionary.\n",
      "977 other pairs contained at least one unknown word (0 in source language, 977 in target language).\n",
      "Resulting subspace dimension: (13700, 300)\n"
     ]
    }
   ],
   "source": [
    "W = multi.learn_projection_matrix(emb_en, emb_de, '{}expert_dictionaries/en-de/MUSE_en-de.0-5000.txt'.format(data_path), word2id_en, word2id_de)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Europarl sentences and transform to sentence vector embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_en = sentence.load_sentences('{}corpus/de-en/Europarl.de-en.en'.format(data_path), 5000)\n",
    "sen_de = sentence.load_sentences('{}corpus/de-en/Europarl.de-en.de'.format(data_path), 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_en_preprocessed = sentence.preprocess_sentences(sentences=sen_en, language='english')\n",
    "sen_de_preprocessed = sentence.preprocess_sentences(sentences=sen_de, language='german')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find a term of the sentence '['sicherheitsberater', 'gefahrguttransport']' in word embedding vocabulary and thus, could not calculate the respective embedding vector.\n",
      "Could not find a term of the sentence '['lebensmittelsicherheit']' in word embedding vocabulary and thus, could not calculate the respective embedding vector.\n",
      "Could not find a term of the sentence '['arbeitsplan']' in word embedding vocabulary and thus, could not calculate the respective embedding vector.\n",
      "Could not find a term of the sentence '['kapitalsteuer']' in word embedding vocabulary and thus, could not calculate the respective embedding vector.\n"
     ]
    }
   ],
   "source": [
    "sen_emb_de, id2sentence_de, words_found_de, invalid_sentences_de = sentence.transform_into_sentence_vectors(sen_de_preprocessed, 'german', emb_de, word2id_de, preprocessed=True)\n",
    "sen_emb_en, id2sentence_en, words_found_en, invalid_sentences_en = sentence.transform_into_sentence_vectors(sen_en_preprocessed, 'english', emb_en, word2id_en, preprocessed=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete invalid sentences from lists of sentences\n",
    "for idx in invalid_sentences_de.union(invalid_sentences_en):\n",
    "    del sen_en[idx]\n",
    "    del sen_de[idx]\n",
    "    del sen_en_preprocessed[idx]\n",
    "    del sen_de_preprocessed[idx]\n",
    "    sen_emb_en = np.delete(sen_emb_en, idx, axis=0)\n",
    "    sen_emb_de = np.delete(sen_emb_de, idx, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised classifier for cross-lingual retrieval (L2R) - DEMO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation and feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start extraction feature difference_count_words\n",
      "Start extraction feature difference_count_punctuation\n",
      "Start extraction feature equal_occ_question\n",
      "Start extraction feature equal_occ_exclamation\n",
      "Start extraction feature difference_count_noun\n",
      "Start extraction feature difference_count_verb\n",
      "Start extraction feature difference_count_adverb\n",
      "Start extraction feature difference_count_adjective\n",
      "Start extraction feature difference_count_wh\n",
      "Start extraction feature difference_count_pronoun\n",
      "Start extraction feature difference_count_words\n",
      "Start extraction feature difference_count_punctuation\n",
      "Start extraction feature equal_occ_question\n",
      "Start extraction feature equal_occ_exclamation\n",
      "Start extraction feature difference_count_noun\n",
      "Start extraction feature difference_count_verb\n",
      "Start extraction feature difference_count_adverb\n",
      "Start extraction feature difference_count_adjective\n",
      "Start extraction feature difference_count_wh\n",
      "Start extraction feature difference_count_pronoun\n",
      "Start extraction feature cosine_similarity\n",
      "Start extraction feature cosine_similarity\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train_data, test_data = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a logistic regression model on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(tb_features.keys()) + list(vb_features.keys())\n",
    "label = 'translation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data[features]\n",
    "y_train = train_data[[label]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = test_data.copy().drop(columns=features, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on positive test samples only to get an idea of the confidence values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = logisticRegr.predict_proba(test_data[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['predictions_proba'] = test_data.apply(lambda row: logisticRegr.predict_proba(np.asarray(row[features]).reshape(1,-1))[0][1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['predictions'] = test_data.apply(lambda row: logisticRegr.predict(np.asarray(row[features]).reshape(1,-1))[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['predictions'].sum() / len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data.loc[test_data['predictions_proba'] < 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data.loc[(test_data['predictions'] == 1) & (test_data['predictions_proba'] < 0.9)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict most similar test target sentence for each test source sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with sentence id 0, probability of 0.9757173382060058\n",
      "Done with sentence id 1, probability of 0.8872214773460967\n",
      "Done with sentence id 2, probability of 0.9818735405710378\n",
      "Done with sentence id 3, probability of 0.9709061963180804\n",
      "Done with sentence id 4, probability of 0.9334326624616233\n",
      "Done with sentence id 5, probability of 0.9766423876289393\n",
      "Done with sentence id 6, probability of 0.9775807729722865\n",
      "Done with sentence id 7, probability of 0.960392498117143\n",
      "Done with sentence id 8, probability of 0.9558612024017931\n",
      "Done with sentence id 9, probability of 0.9850161298645863\n",
      "Done with sentence id 10, probability of 0.9108725814374754\n",
      "Done with sentence id 11, probability of 0.9821001377663224\n",
      "Done with sentence id 12, probability of 0.9674735151758352\n",
      "Done with sentence id 13, probability of 0.9707028240100429\n",
      "Done with sentence id 14, probability of 0.981715064797588\n",
      "Done with sentence id 15, probability of 0.9861990280901168\n",
      "Done with sentence id 16, probability of 0.9755899483233125\n",
      "Done with sentence id 17, probability of 0.9335227346268454\n",
      "Done with sentence id 18, probability of 0.9553440351331566\n",
      "Done with sentence id 19, probability of 0.9785177504241377\n",
      "Done with sentence id 20, probability of 0.9736888910610073\n",
      "Done with sentence id 21, probability of 0.9776383846432501\n",
      "Done with sentence id 22, probability of 0.9056097293913833\n",
      "Done with sentence id 23, probability of 0.9075987499376774\n",
      "Done with sentence id 24, probability of 0.9552737914165343\n",
      "Done with sentence id 25, probability of 0.953400098001996\n",
      "Done with sentence id 26, probability of 0.9608571341072321\n",
      "Done with sentence id 27, probability of 0.9525655703985066\n",
      "Done with sentence id 28, probability of 0.9218312978230742\n",
      "Done with sentence id 29, probability of 0.9714491044434693\n",
      "Done with sentence id 30, probability of 0.9656658123676617\n",
      "Done with sentence id 31, probability of 0.9455130519407856\n",
      "Done with sentence id 32, probability of 0.980525334109916\n",
      "Done with sentence id 33, probability of 0.9706871112010436\n",
      "Done with sentence id 34, probability of 0.9628872012272206\n",
      "Done with sentence id 35, probability of 0.9787295024372229\n",
      "Done with sentence id 36, probability of 0.9624038909165946\n",
      "Done with sentence id 37, probability of 0.8981909508167296\n",
      "Done with sentence id 38, probability of 0.9828104503738863\n",
      "Done with sentence id 39, probability of 0.9700650435203505\n",
      "Done with sentence id 40, probability of 0.9332521327352625\n",
      "Done with sentence id 41, probability of 0.9460004275767254\n",
      "Done with sentence id 42, probability of 0.9441032036276741\n",
      "Done with sentence id 43, probability of 0.9962727594448872\n",
      "Done with sentence id 44, probability of 0.924452824527975\n",
      "Done with sentence id 45, probability of 0.9553653785652165\n",
      "Done with sentence id 46, probability of 0.9699601782447801\n",
      "Done with sentence id 47, probability of 0.9610570475292363\n",
      "Done with sentence id 48, probability of 0.9672674680461676\n",
      "Done with sentence id 49, probability of 0.9724458733533755\n",
      "Done with sentence id 50, probability of 0.9860871169140057\n",
      "Done with sentence id 51, probability of 0.9818319591846958\n",
      "Done with sentence id 52, probability of 0.9408589968055601\n",
      "Done with sentence id 53, probability of 0.9443657938534682\n",
      "Done with sentence id 54, probability of 0.9108725814374754\n",
      "Done with sentence id 55, probability of 0.9779504800732722\n",
      "Done with sentence id 56, probability of 0.9863848083233993\n",
      "Done with sentence id 57, probability of 0.8940878780631021\n",
      "Done with sentence id 58, probability of 0.8954234872398739\n",
      "Done with sentence id 59, probability of 0.9744376671078098\n",
      "Done with sentence id 60, probability of 0.9580130077159975\n",
      "Done with sentence id 61, probability of 0.8982948588387186\n",
      "Done with sentence id 62, probability of 0.9692306055003835\n",
      "Done with sentence id 63, probability of 0.9770284406058565\n",
      "Done with sentence id 64, probability of 0.9590868646569164\n",
      "Done with sentence id 65, probability of 0.9317652931066294\n",
      "Done with sentence id 66, probability of 0.9267860362863173\n",
      "Done with sentence id 67, probability of 0.9606339719919743\n",
      "Done with sentence id 68, probability of 0.9505986575497262\n",
      "Done with sentence id 69, probability of 0.9803499083052526\n",
      "Done with sentence id 70, probability of 0.9505698696569963\n",
      "Done with sentence id 71, probability of 0.9642271027585905\n",
      "Done with sentence id 72, probability of 0.9728617677420646\n",
      "Done with sentence id 73, probability of 0.9665686953963728\n",
      "Done with sentence id 74, probability of 0.9824301096706877\n",
      "Done with sentence id 75, probability of 0.893346823485323\n",
      "Done with sentence id 76, probability of 0.939377521151625\n",
      "Done with sentence id 77, probability of 0.9350685175651812\n",
      "Done with sentence id 78, probability of 0.910878376821936\n",
      "Done with sentence id 79, probability of 0.9435659523681166\n",
      "Done with sentence id 80, probability of 0.9758393794574233\n",
      "Done with sentence id 81, probability of 0.968197965405531\n",
      "Done with sentence id 82, probability of 0.9582849618990916\n",
      "Done with sentence id 83, probability of 0.9736967302475871\n",
      "Done with sentence id 84, probability of 0.9648551628641345\n",
      "Done with sentence id 85, probability of 0.9833534337146752\n",
      "Done with sentence id 86, probability of 0.9865721762729445\n",
      "Done with sentence id 87, probability of 0.9415891773618773\n",
      "Done with sentence id 88, probability of 0.9770639165206899\n",
      "Done with sentence id 89, probability of 0.93208419607424\n",
      "Done with sentence id 90, probability of 0.9653514840533115\n",
      "Done with sentence id 91, probability of 0.8706193340514083\n",
      "Done with sentence id 92, probability of 0.9819066696147795\n",
      "Done with sentence id 93, probability of 0.9761021254820554\n",
      "Done with sentence id 94, probability of 0.9647300946546427\n",
      "Done with sentence id 95, probability of 0.9786794733871849\n",
      "Done with sentence id 96, probability of 0.9446120998915117\n",
      "Done with sentence id 97, probability of 0.9030250936007628\n",
      "Done with sentence id 98, probability of 0.9603519264231999\n",
      "Done with sentence id 99, probability of 0.9645237217463386\n",
      "Done with sentence id 100, probability of 0.9488623240302269\n",
      "Done with sentence id 101, probability of 0.9411087577118152\n",
      "Done with sentence id 102, probability of 0.9292014186819524\n",
      "Done with sentence id 103, probability of 0.9574215756071786\n",
      "Done with sentence id 104, probability of 0.9116951163187326\n",
      "Done with sentence id 105, probability of 0.9507085925960901\n",
      "Done with sentence id 106, probability of 0.2324755649691038\n",
      "Done with sentence id 107, probability of 0.9179558331235546\n",
      "Done with sentence id 108, probability of 0.9612732486473259\n",
      "Done with sentence id 109, probability of 0.8958864114431934\n",
      "Done with sentence id 110, probability of 0.9667330768733345\n",
      "Done with sentence id 111, probability of 0.9433181372793012\n",
      "Done with sentence id 112, probability of 0.7242826232661709\n",
      "Done with sentence id 113, probability of 0.8781371204820911\n",
      "Done with sentence id 114, probability of 0.9514378675849725\n",
      "Done with sentence id 115, probability of 0.8998834150228281\n",
      "Done with sentence id 116, probability of 0.9732295463947095\n",
      "Done with sentence id 117, probability of 0.9393829096111846\n",
      "Done with sentence id 118, probability of 0.9764991380376039\n",
      "Done with sentence id 119, probability of 0.8947388926214218\n",
      "Done with sentence id 120, probability of 0.9727959148076017\n",
      "Done with sentence id 121, probability of 0.9201965226068656\n",
      "Done with sentence id 122, probability of 0.9413765312815471\n",
      "Done with sentence id 123, probability of 0.9744742693862093\n",
      "Done with sentence id 124, probability of 0.9614153072695335\n",
      "Done with sentence id 125, probability of 0.9323195131774054\n",
      "Done with sentence id 126, probability of 0.4812692030351999\n",
      "Done with sentence id 127, probability of 0.979500729783487\n",
      "Done with sentence id 128, probability of 0.9635723790136412\n",
      "Done with sentence id 129, probability of 0.9821684679025281\n",
      "Done with sentence id 130, probability of 0.8971277887896414\n",
      "Done with sentence id 131, probability of 0.8480453651968104\n",
      "Done with sentence id 132, probability of 0.9758140528013951\n",
      "Done with sentence id 133, probability of 0.9572968328764369\n",
      "Done with sentence id 134, probability of 0.9763120064976212\n",
      "Done with sentence id 135, probability of 0.9805573819171538\n",
      "Done with sentence id 136, probability of 0.9381326304477396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with sentence id 137, probability of 0.9914754719256659\n",
      "Done with sentence id 138, probability of 0.8497503248542408\n",
      "Done with sentence id 139, probability of 0.9644426718075325\n",
      "Done with sentence id 140, probability of 0.9772465800667844\n",
      "Done with sentence id 141, probability of 0.9585897048153665\n",
      "Done with sentence id 142, probability of 0.9505351812290433\n",
      "Done with sentence id 143, probability of 0.9818249123952723\n",
      "Done with sentence id 144, probability of 0.9700032432252923\n",
      "Done with sentence id 145, probability of 0.9670404230837744\n",
      "Done with sentence id 146, probability of 0.9381802177082811\n",
      "Done with sentence id 147, probability of 0.9691347630258935\n",
      "Done with sentence id 148, probability of 0.9851238268692458\n",
      "Done with sentence id 149, probability of 0.908556517750997\n",
      "Done with sentence id 150, probability of 0.9647368471748304\n",
      "Done with sentence id 151, probability of 0.747321800539163\n",
      "Done with sentence id 152, probability of 0.965023500401264\n",
      "Done with sentence id 153, probability of 0.9303905335328301\n",
      "Done with sentence id 154, probability of 0.9616877404343407\n",
      "Done with sentence id 155, probability of 0.9611254417012857\n",
      "Done with sentence id 156, probability of 0.9412548233250404\n",
      "Done with sentence id 157, probability of 0.9592407714600587\n",
      "Done with sentence id 158, probability of 0.9421318887719103\n",
      "Done with sentence id 159, probability of 0.9352657262765303\n",
      "Done with sentence id 160, probability of 0.9238505016449674\n",
      "Done with sentence id 161, probability of 0.973959040883398\n",
      "Done with sentence id 162, probability of 0.9522683953669779\n",
      "Done with sentence id 163, probability of 0.9609208561121362\n",
      "Done with sentence id 164, probability of 0.9661034952197318\n",
      "Done with sentence id 165, probability of 0.986788448332329\n",
      "Done with sentence id 166, probability of 0.9450715849384851\n",
      "Done with sentence id 167, probability of 0.9650381992632541\n",
      "Done with sentence id 168, probability of 0.9917341200880524\n",
      "Done with sentence id 169, probability of 0.9758848532967391\n",
      "Done with sentence id 170, probability of 0.9676429822075759\n",
      "Done with sentence id 171, probability of 0.972954640650299\n",
      "Done with sentence id 172, probability of 0.955955327114405\n",
      "Done with sentence id 173, probability of 0.9107252557694315\n",
      "Done with sentence id 174, probability of 0.9259431499347661\n",
      "Done with sentence id 175, probability of 0.9131017314265665\n",
      "Done with sentence id 176, probability of 0.9733453365004475\n",
      "Done with sentence id 177, probability of 0.9754445588406165\n",
      "Done with sentence id 178, probability of 0.919638943993238\n",
      "Done with sentence id 179, probability of 0.961276296962347\n",
      "Done with sentence id 180, probability of 0.9480966013843334\n",
      "Done with sentence id 181, probability of 0.8387371315990793\n",
      "Done with sentence id 182, probability of 0.8627173635714505\n",
      "Done with sentence id 183, probability of 0.9754868348067315\n",
      "Done with sentence id 184, probability of 0.8051220899058431\n",
      "Done with sentence id 185, probability of 0.966613493979279\n",
      "Done with sentence id 186, probability of 0.9564787988635632\n",
      "Done with sentence id 187, probability of 0.962951664635471\n",
      "Done with sentence id 188, probability of 0.9758857343544084\n",
      "Done with sentence id 189, probability of 0.9646363408651731\n",
      "Done with sentence id 190, probability of 0.9620021358561068\n",
      "Done with sentence id 191, probability of 0.9244243392569994\n",
      "Done with sentence id 192, probability of 0.9745253008593273\n",
      "Done with sentence id 193, probability of 0.9715159070138635\n",
      "Done with sentence id 194, probability of 0.9389827697905413\n",
      "Done with sentence id 195, probability of 0.9371711393970669\n",
      "Done with sentence id 196, probability of 0.9539312246508491\n",
      "Done with sentence id 197, probability of 0.922259633624771\n",
      "Done with sentence id 198, probability of 0.7732677269693625\n",
      "Done with sentence id 199, probability of 0.9515095721527145\n"
     ]
    }
   ],
   "source": [
    "predictions['prediction'] = predictions.apply(lambda row: predict_most_similar_sentence(row.name, row['source_sentence'], test_data, logisticRegr), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['prediction_sentence'] = predictions.apply(lambda row: row['prediction'][0], axis=1)\n",
    "predictions['prediction_probability'] = predictions.apply(lambda row: row['prediction'][1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['true_prediction'] = predictions.apply(lambda row: 1 if row['target_sentence'] == row['prediction_sentence'] else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fifth run: Without greedy association similarity and with count of pos tags, without apply function in predict_most_similar_sentence\n",
    "# Training size: 4800 instances\n",
    "sum(predictions['true_prediction']) / len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.375"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fourth run: Without greedy association similarity and with count of pos tags\n",
    "# Training size: 4800 instances\n",
    "sum(predictions['true_prediction']) / len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions.loc[predictions['prediction_probability'] < 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions.loc[(predictions['true_prediction'] == 1) & (predictions['prediction_probability'] < 0.9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Third run: Without greedy association similarity and with count of pos tags\n",
    "# Training size: 800 instances\n",
    "# sum(predictions['true_prediction']) / len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second run: With greedy association similarity but without count of pos tags \n",
    "# However, computation of the greedy association similarity was wrong in this run\n",
    "# Extraction of the greedy association similarity feature very time consuming\n",
    "# Training size: 800 instances\n",
    "# sum(predictions['true_prediction']) / len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.305"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First run: Without greedy association similarity and without count of pos tags\n",
    "# Training size: 800 instances\n",
    "# sum(predictions['true_prediction']) / len(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
