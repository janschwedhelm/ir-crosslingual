{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import importlib, datetime\n",
    "import copy\n",
    "from sklearn.externals import joblib\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ir_crosslingual.features.element_based' from '/Users/jani/PycharmProjects/ir-crosslingual/ir_crosslingual/features/element_based.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ir_crosslingual.supervised_classification import sup_model\n",
    "importlib.reload(sup_model)\n",
    "\n",
    "from ir_crosslingual.utils import paths\n",
    "importlib.reload(paths)\n",
    "\n",
    "from ir_crosslingual.embeddings import embeddings\n",
    "importlib.reload(embeddings)\n",
    "\n",
    "from ir_crosslingual.sentences import sentences\n",
    "importlib.reload(sentences)\n",
    "\n",
    "from ir_crosslingual.features import element_based\n",
    "importlib.reload(element_based)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- INFO: Learn projection matrix for en-de\n",
      "---- INFO: Found 13700 valid translation pairs in expert dictionary.\n",
      "---- INFO: 977 other pairs contained at least one unknown word (0 in source language, 977 in target language).\n",
      "---- DONE: Seed dictionary extracted for the languages: en-de\n",
      "---- INFO: Resulting subspace dimension: (13700, 300)\n",
      "---- INFO: Resulting subspace dimension: (13700, 300)\n",
      "---- DONE: Projection matrix learned from en to de\n",
      "---- INFO: Learn projection matrix for de-en\n",
      "---- INFO: Found 10604 valid translation pairs in expert dictionary.\n",
      "---- INFO: 262 other pairs contained at least one unknown word (0 in source language, 262 in target language).\n",
      "---- DONE: Seed dictionary extracted for the languages: de-en\n",
      "---- INFO: Resulting subspace dimension: (10604, 300)\n",
      "---- INFO: Resulting subspace dimension: (10604, 300)\n",
      "---- DONE: Projection matrix learned from de to en\n",
      "---- INFO: File loaded containing training data\n",
      "---- INFO: File loaded containing test collection\n",
      "---- DONE: All files loaded and features extracted\n"
     ]
    }
   ],
   "source": [
    "train_file_avg = f'{paths.data_path}extracted_data/global/training_data_avg.pkl'\n",
    "test_file_avg = f'{paths.data_path}extracted_data/global/test_collection_avg.pkl'\n",
    "sens_avg, train_data_avg, test_collection_avg, features_avg = sentences.Sentences.load_from_file(train_file_avg, test_file_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce embedding dimensionality and extract elements as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_scaler = {}\n",
    "for prefix in ['src', 'trg']:\n",
    "    mean_scaler['{}'.format(prefix)] = StandardScaler(with_std=False)\n",
    "    X = np.vstack(sens_avg.train_data['{}_embedding'.format(prefix)])\n",
    "    mean_scaler['{}'.format(prefix)].fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = {}\n",
    "for prefix in ['src', 'trg']:\n",
    "    pca['{}'.format(prefix)] = PCA(n_components=10, random_state=42)\n",
    "    X = np.vstack(sens_avg.train_data['{}_embedding'.format(prefix)])\n",
    "    X = mean_scaler['{}'.format(prefix)].transform(X)\n",
    "    pca['{}'.format(prefix)].fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- INFO: Unique queries extracted\n",
      "---- INFO: Unique documents extracted\n",
      "---- INFO: Started extraction for src language.\n",
      "---- INFO: src_embedding_pca elements extracted for train data.\n",
      "---- INFO: src_embedding_pca elements extracted for unique queries.\n",
      "---- INFO: Unique queries merged to test collection\n",
      "---- INFO: Started extraction for trg language.\n",
      "---- INFO: trg_embedding_pca elements extracted for train data.\n",
      "---- INFO: trg_embedding_pca elements extracted for unique documents.\n",
      "---- INFO: Unique documents merged to test collection\n",
      "---- DONE: Extracted all vector elements and merged to test collection\n"
     ]
    }
   ],
   "source": [
    "sens_avg = element_based.vec2features(sens_avg, pca, mean_scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove pairs that cointain sentences equal to '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens_avg.train_data = sens_avg.train_data[(sens_avg.train_data['src_sentence'] != '.') & (sens_avg.train_data['trg_sentence'] != '.')]\n",
    "sens_avg.test_collection = sens_avg.test_collection[(sens_avg.test_collection['src_sentence'] != '.') & (sens_avg.test_collection['trg_sentence'] != '.')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale features (z-scores for numerical, OneHotEncoding for categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define features\n",
    "model_features = ['src_sentence', 'trg_sentence', 'translation',\n",
    "                  'norm_diff_translated_words', 'abs_diff_num_words', 'abs_diff_num_punctuation',\n",
    "                  'abs_diff_occ_question_mark', 'abs_diff_occ_exclamation_mark',\n",
    "                  'rel_diff_num_words', 'rel_diff_num_punctuation', 'norm_diff_num_words',\n",
    "                  'norm_diff_num_punctuation', 'euclidean_distance', 'cosine_similarity'] \\\n",
    "                 + ['src_embedding_pca_{}'.format(i) for i in range(10)] \\\n",
    "                 + ['trg_embedding_pca_{}'.format(i) for i in range(10)]\n",
    "num_features = ['norm_diff_translated_words', 'abs_diff_num_words', 'abs_diff_num_punctuation',\n",
    "                'rel_diff_num_words', 'rel_diff_num_punctuation', 'norm_diff_num_words',\n",
    "                'norm_diff_num_punctuation', 'euclidean_distance', 'cosine_similarity'] \\\n",
    "                 + ['src_embedding_pca_{}'.format(i) for i in range(10)] \\\n",
    "                 + ['trg_embedding_pca_{}'.format(i) for i in range(10)]\n",
    "cat_features = ['abs_diff_occ_question_mark', 'abs_diff_occ_exclamation_mark']\n",
    "meta_features = ['src_sentence', 'trg_sentence']\n",
    "label = 'translation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit scaler on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column transformer / scaler\n",
    "numeric_pipeline = make_pipeline(StandardScaler())\n",
    "cat_pipeline     = make_pipeline(OneHotEncoder())\n",
    "\n",
    "transformers = [\n",
    "('num', numeric_pipeline, num_features),\n",
    "('cat', cat_pipeline, cat_features)\n",
    "]\n",
    "\n",
    "ct = ColumnTransformer(transformers, remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function that get feature names of transformed columns\n",
    "def get_transformer_feature_names(columnTransformer):\n",
    "\n",
    "    output_features = []\n",
    "\n",
    "    for name, pipe, features in columnTransformer.transformers_:\n",
    "        if name!='remainder':\n",
    "            for i in pipe:\n",
    "                trans_features = []\n",
    "                if hasattr(i,'categories_'):\n",
    "                    trans_features.extend(i.get_feature_names(features))\n",
    "                else:\n",
    "                    trans_features = features\n",
    "            output_features.extend(trans_features)\n",
    "\n",
    "    return output_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted.\n"
     ]
    }
   ],
   "source": [
    "# fit scaler on training data and scale training columns\n",
    "ct.fit(sens_avg.train_data[model_features])\n",
    "print('Fitted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data scaled.\n"
     ]
    }
   ],
   "source": [
    "sens_avg.train_data = pd.DataFrame(ct.transform(sens_avg.train_data[model_features]))\n",
    "sens_avg.train_data.columns = get_transformer_feature_names(ct) + meta_features + [label]\n",
    "sens_avg.train_data = sens_avg.train_data.infer_objects()\n",
    "print('Train data scaled.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide test collection into chunks which allows for faster operations on test collection\n",
    "n = 500000  #chunk row size\n",
    "chunks_test_collection = [sens_avg.test_collection[i:i+n] for i in range(0, sens_avg.test_collection.shape[0], n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0 scaled.\n",
      "Chunk 1 scaled.\n",
      "Chunk 2 scaled.\n",
      "Chunk 3 scaled.\n",
      "Chunk 4 scaled.\n",
      "Chunk 5 scaled.\n",
      "Chunk 6 scaled.\n",
      "Chunk 7 scaled.\n",
      "Chunk 8 scaled.\n",
      "Chunk 9 scaled.\n",
      "Chunk 10 scaled.\n",
      "Chunk 11 scaled.\n",
      "Chunk 12 scaled.\n",
      "Chunk 13 scaled.\n",
      "Chunk 14 scaled.\n",
      "Chunk 15 scaled.\n",
      "Chunk 16 scaled.\n",
      "Chunk 17 scaled.\n",
      "Chunk 18 scaled.\n",
      "Chunk 19 scaled.\n"
     ]
    }
   ],
   "source": [
    "# scale columns of test collection\n",
    "for i, chunk in enumerate(chunks_test_collection):\n",
    "    chunks_test_collection[i] = pd.DataFrame(ct.transform(chunk[model_features]))\n",
    "    chunks_test_collection[i].columns = get_transformer_feature_names(ct) + meta_features + [label]\n",
    "    chunks_test_collection[i] = chunks_test_collection[i].infer_objects()\n",
    "    print('Chunk {} scaled.'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update data attribute of Sentences object\n",
    "sens_avg.test_collection = pd.concat([chunk for chunk in chunks_test_collection], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline MLP models using \"average\" aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Use self-selected features based on intuition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_1 = 'norm_diff_translated_words norm_diff_num_punctuation abs_diff_occ_question_mark_0 abs_diff_occ_question_mark_1 abs_diff_occ_question_mark_2 abs_diff_occ_exclamation_mark_0 abs_diff_occ_exclamation_mark_1 abs_diff_occ_exclamation_mark_2 norm_diff_num_words euclidean_distance cosine_similarity'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time fitting the multilayer perceptron: 0:00:12.432663\n",
      "Accuracy: 0.9737696696696697\n",
      "Precision: 0.003631841552830935\n",
      "Recall: 0.955955955955956\n",
      "F1: 0.007236191565858815\n",
      "---- INFO: Start computing the MAP\n",
      "---- INFO: Probabilities predicted\n",
      "---- INFO: Dataframe with evaluation ranking created\n",
      "---- INFO: Probabilities sorted for each query\n",
      "---- INFO: Index of ranking of true translation retrieved\n",
      "MAP: 0.8000676445473803\n"
     ]
    }
   ],
   "source": [
    "# Create baseline MLP classifier\n",
    "mlp_1 = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(5,), random_state=1, learning_rate='adaptive', activation='tanh')\n",
    "\n",
    "# Fit baseline model on training data\n",
    "start = datetime.datetime.now()\n",
    "mlp_1.fit(sens_avg.train_data[features_1], sens_avg.train_data[label])\n",
    "stop = datetime.datetime.now()\n",
    "print('Computation time fitting the multilayer perceptron: {}'.format(stop-start))\n",
    "\n",
    "# Evaluate baseline model on test collection\n",
    "sup = sup_model.SupModel()\n",
    "sup.evaluate_boolean(mlp_1, sens_avg, features_1)\n",
    "print('Accuracy: {}'.format(sup.accuracy))\n",
    "print('Precision: {}'.format(sup.precision))\n",
    "print('Recall: {}'.format(sup.recall))\n",
    "print('F1: {}'.format(sup.f1))\n",
    "\n",
    "print('MAP: {}'.format(sup.compute_map(mlp_1, sens_avg, features_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Use features selected through RFECV (see logistic_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_2 = list(set(features_1 + ['abs_diff_num_words', 'abs_diff_num_punctuation']) - set(['norm_diff_num_punctuation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time fitting the multilayer perceptron: 0:00:13.530632\n",
      "Accuracy: 0.9767011011011011\n",
      "Precision: 0.00415916063688217\n",
      "Recall: 0.972972972972973\n",
      "F1: 0.008282914358755859\n",
      "---- INFO: Start computing the MAP\n",
      "---- INFO: Probabilities predicted\n",
      "---- INFO: Dataframe with evaluation ranking created\n",
      "---- INFO: Probabilities sorted for each query\n",
      "---- INFO: Index of ranking of true translation retrieved\n",
      "MAP: 0.8277222438347304\n"
     ]
    }
   ],
   "source": [
    "# Create baseline MLP classifier\n",
    "mlp_2 = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(5,), random_state=42, learning_rate='adaptive', activation='tanh')\n",
    "\n",
    "# Fit baseline model on training data\n",
    "start = datetime.datetime.now()\n",
    "mlp_2.fit(sens_avg.train_data[features_2], sens_avg.train_data[label])\n",
    "stop = datetime.datetime.now()\n",
    "print('Computation time fitting the multilayer perceptron: {}'.format(stop-start))\n",
    "\n",
    "# Evaluate baseline model on test collection\n",
    "sup = sup_model.SupModel()\n",
    "sup.evaluate_boolean(mlp_2, sens_avg, features_2)\n",
    "print('Accuracy: {}'.format(sup.accuracy))\n",
    "print('Precision: {}'.format(sup.precision))\n",
    "print('Recall: {}'.format(sup.recall))\n",
    "print('F1: {}'.format(sup.f1))\n",
    "\n",
    "print('MAP: {}'.format(sup.compute_map(mlp_2, sens_avg, features_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Use correlation-based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_corr = 'norm_diff_translated_words abs_diff_num_punctuation abs_diff_occ_question_mark_0 abs_diff_occ_question_mark_1 abs_diff_occ_question_mark_2 abs_diff_occ_exclamation_mark_0 abs_diff_occ_exclamation_mark_1 abs_diff_occ_exclamation_mark_2 abs_diff_num_words cosine_similarity'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time fitting the multilayer perceptron: 0:00:07.112758\n",
      "Accuracy: 0.9745493493493493\n",
      "Precision: 0.0037193661792428796\n",
      "Recall: 0.94994994994995\n",
      "F1: 0.00740972086667968\n",
      "---- INFO: Start computing the MAP\n",
      "---- INFO: Probabilities predicted\n",
      "---- INFO: Dataframe with evaluation ranking created\n",
      "---- INFO: Probabilities sorted for each query\n",
      "---- INFO: Index of ranking of true translation retrieved\n",
      "MAP: 0.8256640284049531\n"
     ]
    }
   ],
   "source": [
    "# Create baseline MLP classifier\n",
    "mlp_corr = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(5,), random_state=42, learning_rate='adaptive', activation='tanh')\n",
    "\n",
    "# Fit baseline model on training data\n",
    "start = datetime.datetime.now()\n",
    "mlp_corr.fit(sens_avg.train_data[features_corr], sens_avg.train_data[label])\n",
    "stop = datetime.datetime.now()\n",
    "print('Computation time fitting the multilayer perceptron: {}'.format(stop-start))\n",
    "\n",
    "# Evaluate baseline model on test collection\n",
    "sup = sup_model.SupModel()\n",
    "sup.evaluate_boolean(mlp_corr, sens_avg, features_corr)\n",
    "print('Accuracy: {}'.format(sup.accuracy))\n",
    "print('Precision: {}'.format(sup.precision))\n",
    "print('Recall: {}'.format(sup.recall))\n",
    "print('F1: {}'.format(sup.f1))\n",
    "\n",
    "print('MAP: {}'.format(sup.compute_map(mlp_corr, sens_avg, features_corr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Use all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_3 = features_2 + ['norm_diff_num_punctuation', 'rel_diff_num_words', 'rel_diff_num_punctuation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time fitting the multilayer perceptron: 0:00:14.093721\n",
      "Accuracy: 0.9767005005005005\n",
      "Precision: 0.004154810551763976\n",
      "Recall: 0.9719719719719719\n",
      "F1: 0.008274251823573523\n",
      "---- INFO: Start computing the MAP\n",
      "---- INFO: Probabilities predicted\n",
      "---- INFO: Dataframe with evaluation ranking created\n",
      "---- INFO: Probabilities sorted for each query\n",
      "---- INFO: Index of ranking of true translation retrieved\n",
      "MAP: 0.821184407892351\n"
     ]
    }
   ],
   "source": [
    "# Create baseline MLP classifier\n",
    "mlp_3 = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(5,), random_state=1, learning_rate='adaptive', activation='tanh')\n",
    "\n",
    "# Fit baseline model on training data\n",
    "start = datetime.datetime.now()\n",
    "mlp_3.fit(sens_avg.train_data[features_3], sens_avg.train_data[label])\n",
    "stop = datetime.datetime.now()\n",
    "print('Computation time fitting the multilayer perceptron: {}'.format(stop-start))\n",
    "\n",
    "# Evaluate baseline model on test collection\n",
    "sup = sup_model.SupModel()\n",
    "sup.evaluate_boolean(mlp_3, sens_avg, features_3)\n",
    "print('Accuracy: {}'.format(sup.accuracy))\n",
    "print('Precision: {}'.format(sup.precision))\n",
    "print('Recall: {}'.format(sup.recall))\n",
    "print('F1: {}'.format(sup.f1))\n",
    "\n",
    "print('MAP: {}'.format(sup.compute_map(mlp_3, sens_avg, features_3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Use best of {1,2,3,4} + extracted elements of dimension reduced sentence embedding (10-dim) as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_4 = features_2 + ['src_embedding_pca_{}'.format(i) for i in range(10)] + ['trg_embedding_pca_{}'.format(i) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time fitting the multilayer perceptron: 0:00:20.210128\n",
      "Accuracy: 0.9838556556556557\n",
      "Precision: 0.006040322232700332\n",
      "Recall: 0.980980980980981\n",
      "F1: 0.012006713958417565\n",
      "---- INFO: Start computing the MAP\n",
      "---- INFO: Probabilities predicted\n",
      "---- INFO: Dataframe with evaluation ranking created\n",
      "---- INFO: Probabilities sorted for each query\n",
      "---- INFO: Index of ranking of true translation retrieved\n",
      "MAP: 0.850281183980444\n"
     ]
    }
   ],
   "source": [
    "# Create baseline MLP classifier\n",
    "mlp_4 = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(8,), random_state=1, learning_rate='adaptive', activation='tanh')\n",
    "\n",
    "# Fit baseline model on training data\n",
    "start = datetime.datetime.now()\n",
    "mlp_4.fit(sens_avg.train_data[features_4], sens_avg.train_data[label])\n",
    "stop = datetime.datetime.now()\n",
    "print('Computation time fitting the multilayer perceptron: {}'.format(stop-start))\n",
    "\n",
    "# Evaluate baseline model on test collection\n",
    "sup = sup_model.SupModel()\n",
    "sup.evaluate_boolean(mlp_4, sens_avg, features_4)\n",
    "print('Accuracy: {}'.format(sup.accuracy))\n",
    "print('Precision: {}'.format(sup.precision))\n",
    "print('Recall: {}'.format(sup.recall))\n",
    "print('F1: {}'.format(sup.f1))\n",
    "\n",
    "print('MAP: {}'.format(sup.compute_map(mlp_4, sens_avg, features_4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparametertuning of best model (variant 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create random grid for tuning best model (1st run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden layers\n",
    "hidden_layers = [(4,4), (3,3,2), (8,), (2,2,2,1), (8,3,2), (7,), (9,), (4,3,2)]\n",
    "\n",
    "# Activation function\n",
    "activation = ['identity', 'logistic', 'tanh', 'relu']\n",
    "\n",
    "# Optimizer\n",
    "optimizer = ['lbfgs', 'sgd', 'adam']\n",
    "\n",
    "# Alpha\n",
    "alpha = [0.1, 0.01, 0.001, 0.0001]\n",
    "\n",
    "# Batch size\n",
    "batch_size = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "# Learning rate\n",
    "learning_rate = ['constant', 'invscaling', 'adaptive']\n",
    "\n",
    "# Learning rate init\n",
    "learning_rate_init = [0.1, 0.01, 0.001, 0.0001]\n",
    "\n",
    "# Maximum iterations\n",
    "max_iter = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {\n",
    "    'hidden_layer_sizes': hidden_layers,\n",
    "    'activation': activation,\n",
    "    'solver': optimizer,\n",
    "    'alpha': alpha,\n",
    "    'batch_size': batch_size,\n",
    "    'learning_rate': learning_rate,\n",
    "    'learning_rate_init': learning_rate_init,\n",
    "    'max_iter': max_iter\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform random search for optimal hyperparameters (1st run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   15.4s\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   17.2s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   26.5s\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done  39 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done  43 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done  47 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=-1)]: Done  54 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done  55 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=-1)]: Done  59 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done  60 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done  61 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done  62 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done  63 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=-1)]: Done  67 tasks      | elapsed: 11.2min\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed: 11.2min\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=-1)]: Done  71 tasks      | elapsed: 13.3min\n",
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed: 13.5min\n",
      "[Parallel(n_jobs=-1)]: Done  73 tasks      | elapsed: 13.5min\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=-1)]: Done  75 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed: 13.7min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed: 13.7min\n",
      "[Parallel(n_jobs=-1)]: Done  78 tasks      | elapsed: 13.8min\n",
      "[Parallel(n_jobs=-1)]: Done  79 tasks      | elapsed: 13.8min\n",
      "[Parallel(n_jobs=-1)]: Done  80 tasks      | elapsed: 15.3min\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed: 15.4min\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed: 15.4min\n",
      "[Parallel(n_jobs=-1)]: Done  83 tasks      | elapsed: 15.5min\n",
      "[Parallel(n_jobs=-1)]: Done  84 tasks      | elapsed: 15.5min\n",
      "[Parallel(n_jobs=-1)]: Done  85 tasks      | elapsed: 15.7min\n",
      "[Parallel(n_jobs=-1)]: Done  86 tasks      | elapsed: 15.8min\n",
      "[Parallel(n_jobs=-1)]: Done  87 tasks      | elapsed: 16.0min\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed: 16.0min\n",
      "[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed: 16.9min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 17.0min\n",
      "[Parallel(n_jobs=-1)]: Done  91 tasks      | elapsed: 17.7min\n",
      "[Parallel(n_jobs=-1)]: Done  92 tasks      | elapsed: 17.7min\n",
      "[Parallel(n_jobs=-1)]: Done  93 tasks      | elapsed: 18.0min\n",
      "[Parallel(n_jobs=-1)]: Done  94 tasks      | elapsed: 18.4min\n",
      "[Parallel(n_jobs=-1)]: Done  95 tasks      | elapsed: 18.5min\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed: 18.7min\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed: 18.8min\n",
      "[Parallel(n_jobs=-1)]: Done  98 tasks      | elapsed: 19.1min\n",
      "[Parallel(n_jobs=-1)]: Done  99 tasks      | elapsed: 19.2min\n",
      "[Parallel(n_jobs=-1)]: Done 100 tasks      | elapsed: 19.4min\n",
      "[Parallel(n_jobs=-1)]: Done 101 tasks      | elapsed: 20.1min\n",
      "[Parallel(n_jobs=-1)]: Done 102 tasks      | elapsed: 20.3min\n",
      "[Parallel(n_jobs=-1)]: Done 103 tasks      | elapsed: 20.5min\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed: 20.7min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed: 21.4min\n",
      "[Parallel(n_jobs=-1)]: Done 106 tasks      | elapsed: 22.0min\n",
      "[Parallel(n_jobs=-1)]: Done 107 tasks      | elapsed: 23.8min\n",
      "[Parallel(n_jobs=-1)]: Done 108 tasks      | elapsed: 24.4min\n",
      "[Parallel(n_jobs=-1)]: Done 109 tasks      | elapsed: 25.2min\n",
      "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed: 25.4min\n",
      "[Parallel(n_jobs=-1)]: Done 111 tasks      | elapsed: 25.8min\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed: 25.8min\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed: 26.4min\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed: 26.8min\n",
      "[Parallel(n_jobs=-1)]: Done 115 tasks      | elapsed: 27.1min\n",
      "[Parallel(n_jobs=-1)]: Done 116 tasks      | elapsed: 31.0min\n",
      "[Parallel(n_jobs=-1)]: Done 117 tasks      | elapsed: 32.0min\n",
      "[Parallel(n_jobs=-1)]: Done 118 tasks      | elapsed: 32.3min\n",
      "[Parallel(n_jobs=-1)]: Done 119 tasks      | elapsed: 32.5min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed: 33.7min\n",
      "[Parallel(n_jobs=-1)]: Done 121 tasks      | elapsed: 34.0min\n",
      "[Parallel(n_jobs=-1)]: Done 122 tasks      | elapsed: 34.2min\n",
      "[Parallel(n_jobs=-1)]: Done 123 tasks      | elapsed: 35.1min\n",
      "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed: 35.1min\n",
      "[Parallel(n_jobs=-1)]: Done 125 tasks      | elapsed: 35.5min\n",
      "[Parallel(n_jobs=-1)]: Done 126 tasks      | elapsed: 35.7min\n",
      "[Parallel(n_jobs=-1)]: Done 127 tasks      | elapsed: 36.4min\n",
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed: 36.8min\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed: 37.0min\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed: 37.0min\n",
      "[Parallel(n_jobs=-1)]: Done 131 tasks      | elapsed: 37.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed: 37.8min\n",
      "[Parallel(n_jobs=-1)]: Done 133 tasks      | elapsed: 38.0min\n",
      "[Parallel(n_jobs=-1)]: Done 134 tasks      | elapsed: 38.0min\n",
      "[Parallel(n_jobs=-1)]: Done 135 tasks      | elapsed: 38.0min\n",
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed: 38.2min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed: 38.2min\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed: 38.3min\n",
      "[Parallel(n_jobs=-1)]: Done 139 tasks      | elapsed: 38.4min\n",
      "[Parallel(n_jobs=-1)]: Done 140 tasks      | elapsed: 38.5min\n",
      "[Parallel(n_jobs=-1)]: Done 141 tasks      | elapsed: 39.1min\n",
      "[Parallel(n_jobs=-1)]: Done 142 tasks      | elapsed: 39.2min\n",
      "[Parallel(n_jobs=-1)]: Done 143 tasks      | elapsed: 39.2min\n",
      "[Parallel(n_jobs=-1)]: Done 144 tasks      | elapsed: 39.4min\n",
      "[Parallel(n_jobs=-1)]: Done 145 tasks      | elapsed: 40.0min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 40.2min\n",
      "[Parallel(n_jobs=-1)]: Done 147 tasks      | elapsed: 40.6min\n",
      "[Parallel(n_jobs=-1)]: Done 148 tasks      | elapsed: 40.7min\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed: 42.0min\n",
      "[Parallel(n_jobs=-1)]: Done 150 tasks      | elapsed: 42.0min\n",
      "[Parallel(n_jobs=-1)]: Done 151 tasks      | elapsed: 42.0min\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed: 42.3min\n",
      "[Parallel(n_jobs=-1)]: Done 153 tasks      | elapsed: 42.8min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 43.3min\n",
      "[Parallel(n_jobs=-1)]: Done 155 tasks      | elapsed: 43.8min\n",
      "[Parallel(n_jobs=-1)]: Done 156 tasks      | elapsed: 44.2min\n",
      "[Parallel(n_jobs=-1)]: Done 157 tasks      | elapsed: 44.3min\n",
      "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed: 44.3min\n",
      "[Parallel(n_jobs=-1)]: Done 159 tasks      | elapsed: 44.7min\n",
      "[Parallel(n_jobs=-1)]: Done 160 tasks      | elapsed: 45.4min\n",
      "[Parallel(n_jobs=-1)]: Done 161 tasks      | elapsed: 47.6min\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed: 47.6min\n",
      "[Parallel(n_jobs=-1)]: Done 163 tasks      | elapsed: 48.0min\n",
      "[Parallel(n_jobs=-1)]: Done 164 tasks      | elapsed: 49.0min\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed: 50.0min\n",
      "[Parallel(n_jobs=-1)]: Done 166 tasks      | elapsed: 50.1min\n",
      "[Parallel(n_jobs=-1)]: Done 167 tasks      | elapsed: 51.4min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed: 51.7min\n",
      "[Parallel(n_jobs=-1)]: Done 169 tasks      | elapsed: 52.5min\n",
      "[Parallel(n_jobs=-1)]: Done 170 tasks      | elapsed: 53.4min\n",
      "[Parallel(n_jobs=-1)]: Done 171 tasks      | elapsed: 53.7min\n",
      "[Parallel(n_jobs=-1)]: Done 172 tasks      | elapsed: 54.2min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed: 54.3min\n",
      "[Parallel(n_jobs=-1)]: Done 174 tasks      | elapsed: 54.3min\n",
      "[Parallel(n_jobs=-1)]: Done 175 tasks      | elapsed: 54.5min\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed: 54.5min\n",
      "[Parallel(n_jobs=-1)]: Done 177 tasks      | elapsed: 54.6min\n",
      "[Parallel(n_jobs=-1)]: Done 178 tasks      | elapsed: 54.6min\n",
      "[Parallel(n_jobs=-1)]: Done 179 tasks      | elapsed: 54.9min\n",
      "[Parallel(n_jobs=-1)]: Done 180 tasks      | elapsed: 55.1min\n",
      "[Parallel(n_jobs=-1)]: Done 181 tasks      | elapsed: 55.2min\n",
      "[Parallel(n_jobs=-1)]: Done 182 tasks      | elapsed: 55.2min\n",
      "[Parallel(n_jobs=-1)]: Done 183 tasks      | elapsed: 55.2min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 55.2min\n",
      "[Parallel(n_jobs=-1)]: Done 185 tasks      | elapsed: 55.3min\n",
      "[Parallel(n_jobs=-1)]: Done 186 tasks      | elapsed: 55.3min\n",
      "[Parallel(n_jobs=-1)]: Done 187 tasks      | elapsed: 55.4min\n",
      "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed: 55.5min\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed: 55.8min\n",
      "[Parallel(n_jobs=-1)]: Done 190 tasks      | elapsed: 55.9min\n",
      "[Parallel(n_jobs=-1)]: Done 191 tasks      | elapsed: 55.9min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 56.0min\n",
      "[Parallel(n_jobs=-1)]: Done 193 tasks      | elapsed: 56.2min\n",
      "[Parallel(n_jobs=-1)]: Done 194 tasks      | elapsed: 56.3min\n",
      "[Parallel(n_jobs=-1)]: Done 195 tasks      | elapsed: 56.3min\n",
      "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed: 56.5min\n",
      "[Parallel(n_jobs=-1)]: Done 197 tasks      | elapsed: 56.7min\n",
      "[Parallel(n_jobs=-1)]: Done 198 tasks      | elapsed: 56.7min\n",
      "[Parallel(n_jobs=-1)]: Done 199 tasks      | elapsed: 56.8min\n",
      "[Parallel(n_jobs=-1)]: Done 200 tasks      | elapsed: 56.9min\n",
      "[Parallel(n_jobs=-1)]: Done 201 tasks      | elapsed: 57.9min\n",
      "[Parallel(n_jobs=-1)]: Done 202 tasks      | elapsed: 57.9min\n",
      "[Parallel(n_jobs=-1)]: Done 203 tasks      | elapsed: 57.9min\n",
      "[Parallel(n_jobs=-1)]: Done 204 tasks      | elapsed: 58.2min\n",
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed: 59.1min\n",
      "[Parallel(n_jobs=-1)]: Done 206 tasks      | elapsed: 59.2min\n",
      "[Parallel(n_jobs=-1)]: Done 207 tasks      | elapsed: 59.8min\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed: 60.4min\n",
      "[Parallel(n_jobs=-1)]: Done 209 tasks      | elapsed: 60.6min\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed: 60.8min\n",
      "[Parallel(n_jobs=-1)]: Done 211 tasks      | elapsed: 61.0min\n",
      "[Parallel(n_jobs=-1)]: Done 212 tasks      | elapsed: 61.1min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed: 61.2min\n",
      "[Parallel(n_jobs=-1)]: Done 214 tasks      | elapsed: 61.2min\n",
      "[Parallel(n_jobs=-1)]: Done 215 tasks      | elapsed: 61.3min\n",
      "[Parallel(n_jobs=-1)]: Done 216 tasks      | elapsed: 61.3min\n",
      "[Parallel(n_jobs=-1)]: Done 217 tasks      | elapsed: 61.4min\n",
      "[Parallel(n_jobs=-1)]: Done 218 tasks      | elapsed: 61.4min\n",
      "[Parallel(n_jobs=-1)]: Done 219 tasks      | elapsed: 61.4min\n",
      "[Parallel(n_jobs=-1)]: Done 220 tasks      | elapsed: 61.5min\n",
      "[Parallel(n_jobs=-1)]: Done 221 tasks      | elapsed: 61.5min\n",
      "[Parallel(n_jobs=-1)]: Done 222 tasks      | elapsed: 61.6min\n",
      "[Parallel(n_jobs=-1)]: Done 223 tasks      | elapsed: 61.8min\n",
      "[Parallel(n_jobs=-1)]: Done 224 tasks      | elapsed: 61.8min\n",
      "[Parallel(n_jobs=-1)]: Done 225 tasks      | elapsed: 62.0min\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed: 62.1min\n",
      "[Parallel(n_jobs=-1)]: Done 227 tasks      | elapsed: 62.2min\n",
      "[Parallel(n_jobs=-1)]: Done 228 tasks      | elapsed: 62.3min\n",
      "[Parallel(n_jobs=-1)]: Done 229 tasks      | elapsed: 62.4min\n",
      "[Parallel(n_jobs=-1)]: Done 230 tasks      | elapsed: 62.5min\n",
      "[Parallel(n_jobs=-1)]: Done 231 tasks      | elapsed: 62.6min\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed: 62.6min\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed: 62.7min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed: 63.7min\n",
      "[Parallel(n_jobs=-1)]: Done 235 tasks      | elapsed: 64.1min\n",
      "[Parallel(n_jobs=-1)]: Done 236 tasks      | elapsed: 64.3min\n",
      "[Parallel(n_jobs=-1)]: Done 237 tasks      | elapsed: 65.3min\n",
      "[Parallel(n_jobs=-1)]: Done 238 tasks      | elapsed: 65.6min\n",
      "[Parallel(n_jobs=-1)]: Done 239 tasks      | elapsed: 65.8min\n",
      "[Parallel(n_jobs=-1)]: Done 240 tasks      | elapsed: 66.0min\n",
      "[Parallel(n_jobs=-1)]: Done 241 tasks      | elapsed: 66.3min\n",
      "[Parallel(n_jobs=-1)]: Done 242 tasks      | elapsed: 66.5min\n",
      "[Parallel(n_jobs=-1)]: Done 243 tasks      | elapsed: 66.7min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed: 68.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=False),\n",
       "                   error_score=nan,\n",
       "                   estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
       "                                           batch_size='auto', beta_1=0.9,\n",
       "                                           beta_2=0.999, early_stopping=False,\n",
       "                                           epsilon=1e-08,\n",
       "                                           hidden_layer_sizes=(100,),\n",
       "                                           learning_rate='constant',\n",
       "                                           learning_rate_init=0.001,\n",
       "                                           max_fun=15000, max_iter=200,\n",
       "                                           momentum=0.9, n_iter...\n",
       "                                        'hidden_layer_sizes': [(4, 4),\n",
       "                                                               (3, 3, 2), (8,),\n",
       "                                                               (2, 2, 2, 1),\n",
       "                                                               (8, 3, 2), (7,),\n",
       "                                                               (9,),\n",
       "                                                               (4, 3, 2)],\n",
       "                                        'learning_rate': ['constant',\n",
       "                                                          'invscaling',\n",
       "                                                          'adaptive'],\n",
       "                                        'learning_rate_init': [0.1, 0.01, 0.001,\n",
       "                                                               0.0001],\n",
       "                                        'max_iter': [200, 400, 600, 800, 1000,\n",
       "                                                     1200, 1400, 1600, 1800,\n",
       "                                                     2000],\n",
       "                                        'solver': ['lbfgs', 'sgd', 'adam']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=20)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, random_state=42)\n",
    "mlp = MLPClassifier(random_state=42)\n",
    "randomized_search = RandomizedSearchCV(estimator = mlp, param_distributions = parameter_grid, n_iter = 50, \n",
    "                                       cv = cv, verbose=20, random_state=42, n_jobs = -1)\n",
    "randomized_search.fit(sens_avg.train_data[features_4], sens_avg.train_data[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate random search to identify optimal hyperparameters and resulting MAP (1st run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'solver': 'lbfgs',\n",
       " 'max_iter': 1200,\n",
       " 'learning_rate_init': 0.001,\n",
       " 'learning_rate': 'adaptive',\n",
       " 'hidden_layer_sizes': (9,),\n",
       " 'batch_size': 2000,\n",
       " 'alpha': 0.1,\n",
       " 'activation': 'tanh'}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify best hyperparameters retrieved by random search\n",
    "randomized_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9742503350737163"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify best hyperparameters retrieved by random search\n",
    "randomized_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit best model on training data\n",
    "best_model = randomized_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time fitting the multilayer perceptron: 0:01:35.418652\n",
      "Accuracy: 0.9847024024024024\n",
      "Precision: 0.006391833019051954\n",
      "Recall: 0.983983983983984\n",
      "F1: 0.012701160935208573\n",
      "---- INFO: Start computing the MAP\n",
      "---- INFO: Probabilities predicted\n",
      "---- INFO: Dataframe with evaluation ranking created\n",
      "---- INFO: Probabilities sorted for each query\n",
      "---- INFO: Index of ranking of true translation retrieved\n",
      "MAP: 0.8666164677324514\n"
     ]
    }
   ],
   "source": [
    "# Evaluate best model on test collection\n",
    "start = datetime.datetime.now()\n",
    "best_model.fit(sens_avg.train_data[features_4], sens_avg.train_data[label])\n",
    "stop = datetime.datetime.now()\n",
    "print('Computation time fitting the multilayer perceptron: {}'.format(stop-start))\n",
    "\n",
    "# Evaluation on test collection\n",
    "sup = sup_model.SupModel()\n",
    "sup.evaluate_boolean(best_model, sens_avg, features_4)\n",
    "print('Accuracy: {}'.format(sup.accuracy))\n",
    "print('Precision: {}'.format(sup.precision))\n",
    "print('Recall: {}'.format(sup.recall))\n",
    "print('F1: {}'.format(sup.f1))\n",
    "\n",
    "print('MAP: {}'.format(sup.compute_map(best_model, sens_avg, features_4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create random grid for tuning best model (variant 4) (2nd run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden layers\n",
    "hidden_layers_2 = [(i,) for i in range(10, 32, 2)]\n",
    "\n",
    "# Activation function\n",
    "activation_2 = ['identity', 'logistic', 'tanh', 'relu']\n",
    "\n",
    "# Optimizer\n",
    "optimizer_2 = ['lbfgs', 'sgd', 'adam']\n",
    "\n",
    "# Alpha\n",
    "alpha_2 = [0.001, 0.005, 0.05, 0.1, 0.15, 0.2]\n",
    "\n",
    "# Batch size\n",
    "batch_size_2 = [int(x) for x in np.linspace(start = 1500, stop = 2500, num = 5)]\n",
    "\n",
    "# Learning rate\n",
    "learning_rate_2 = ['constant', 'invscaling', 'adaptive']\n",
    "\n",
    "# Learning rate init\n",
    "learning_rate_init_2 = [0.0005, 0.001, 0.0015, 0.002]\n",
    "\n",
    "# Maximum iterations\n",
    "max_iter_2 = [int(x) for x in np.linspace(start = 500, stop = 1500, num = 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid_2 = {\n",
    "    'hidden_layer_sizes': hidden_layers_2,\n",
    "    'activation': activation_2,\n",
    "    'solver': optimizer_2,\n",
    "    'alpha': alpha_2,\n",
    "    'batch_size': batch_size_2,\n",
    "    'learning_rate': learning_rate_2,\n",
    "    'learning_rate_init': learning_rate_init_2,\n",
    "    'max_iter': max_iter_2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform random search for optimal hyperparameters (2nd run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   30.5s\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   32.2s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:   34.6s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   36.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   51.9s\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:   56.0s\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done  39 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done  43 tasks      | elapsed: 12.6min\n",
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed: 12.9min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=-1)]: Done  47 tasks      | elapsed: 13.4min\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed: 13.7min\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed: 13.8min\n",
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed: 14.1min\n",
      "[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed: 14.1min\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed: 14.3min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed: 14.5min\n",
      "[Parallel(n_jobs=-1)]: Done  54 tasks      | elapsed: 14.7min\n",
      "[Parallel(n_jobs=-1)]: Done  55 tasks      | elapsed: 14.8min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed: 15.4min\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed: 16.1min\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed: 16.6min\n",
      "[Parallel(n_jobs=-1)]: Done  59 tasks      | elapsed: 16.7min\n",
      "[Parallel(n_jobs=-1)]: Done  60 tasks      | elapsed: 16.7min\n",
      "[Parallel(n_jobs=-1)]: Done  61 tasks      | elapsed: 17.1min\n",
      "[Parallel(n_jobs=-1)]: Done  62 tasks      | elapsed: 17.1min\n",
      "[Parallel(n_jobs=-1)]: Done  63 tasks      | elapsed: 17.3min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 17.4min\n",
      "[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed: 17.8min\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed: 21.3min\n",
      "[Parallel(n_jobs=-1)]: Done  67 tasks      | elapsed: 22.6min\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed: 23.4min\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed: 23.9min\n",
      "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed: 26.1min\n",
      "[Parallel(n_jobs=-1)]: Done  71 tasks      | elapsed: 26.3min\n",
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed: 26.4min\n",
      "[Parallel(n_jobs=-1)]: Done  73 tasks      | elapsed: 26.5min\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed: 27.7min\n",
      "[Parallel(n_jobs=-1)]: Done  75 tasks      | elapsed: 27.8min\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed: 28.5min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed: 29.0min\n",
      "[Parallel(n_jobs=-1)]: Done  78 tasks      | elapsed: 29.1min\n",
      "[Parallel(n_jobs=-1)]: Done  79 tasks      | elapsed: 29.2min\n",
      "[Parallel(n_jobs=-1)]: Done  80 tasks      | elapsed: 29.2min\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed: 29.2min\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed: 29.3min\n",
      "[Parallel(n_jobs=-1)]: Done  83 tasks      | elapsed: 29.3min\n",
      "[Parallel(n_jobs=-1)]: Done  84 tasks      | elapsed: 29.4min\n",
      "[Parallel(n_jobs=-1)]: Done  85 tasks      | elapsed: 29.5min\n",
      "[Parallel(n_jobs=-1)]: Done  86 tasks      | elapsed: 29.5min\n",
      "[Parallel(n_jobs=-1)]: Done  87 tasks      | elapsed: 29.6min\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed: 29.7min\n",
      "[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed: 29.8min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 29.8min\n",
      "[Parallel(n_jobs=-1)]: Done  91 tasks      | elapsed: 31.8min\n",
      "[Parallel(n_jobs=-1)]: Done  92 tasks      | elapsed: 31.8min\n",
      "[Parallel(n_jobs=-1)]: Done  93 tasks      | elapsed: 32.0min\n",
      "[Parallel(n_jobs=-1)]: Done  94 tasks      | elapsed: 32.0min\n",
      "[Parallel(n_jobs=-1)]: Done  95 tasks      | elapsed: 32.8min\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed: 32.9min\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed: 32.9min\n",
      "[Parallel(n_jobs=-1)]: Done  98 tasks      | elapsed: 33.2min\n",
      "[Parallel(n_jobs=-1)]: Done  99 tasks      | elapsed: 33.5min\n",
      "[Parallel(n_jobs=-1)]: Done 100 tasks      | elapsed: 33.8min\n",
      "[Parallel(n_jobs=-1)]: Done 101 tasks      | elapsed: 33.8min\n",
      "[Parallel(n_jobs=-1)]: Done 102 tasks      | elapsed: 33.9min\n",
      "[Parallel(n_jobs=-1)]: Done 103 tasks      | elapsed: 34.1min\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed: 34.1min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed: 34.3min\n",
      "[Parallel(n_jobs=-1)]: Done 106 tasks      | elapsed: 34.4min\n",
      "[Parallel(n_jobs=-1)]: Done 107 tasks      | elapsed: 34.6min\n",
      "[Parallel(n_jobs=-1)]: Done 108 tasks      | elapsed: 34.7min\n",
      "[Parallel(n_jobs=-1)]: Done 109 tasks      | elapsed: 34.9min\n",
      "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed: 34.9min\n",
      "[Parallel(n_jobs=-1)]: Done 111 tasks      | elapsed: 35.4min\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed: 35.5min\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed: 35.8min\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed: 35.8min\n",
      "[Parallel(n_jobs=-1)]: Done 115 tasks      | elapsed: 36.1min\n",
      "[Parallel(n_jobs=-1)]: Done 116 tasks      | elapsed: 36.5min\n",
      "[Parallel(n_jobs=-1)]: Done 117 tasks      | elapsed: 36.7min\n",
      "[Parallel(n_jobs=-1)]: Done 118 tasks      | elapsed: 36.7min\n",
      "[Parallel(n_jobs=-1)]: Done 119 tasks      | elapsed: 37.2min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed: 37.4min\n",
      "[Parallel(n_jobs=-1)]: Done 121 tasks      | elapsed: 38.2min\n",
      "[Parallel(n_jobs=-1)]: Done 122 tasks      | elapsed: 38.6min\n",
      "[Parallel(n_jobs=-1)]: Done 123 tasks      | elapsed: 38.7min\n",
      "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed: 38.9min\n",
      "[Parallel(n_jobs=-1)]: Done 125 tasks      | elapsed: 39.0min\n",
      "[Parallel(n_jobs=-1)]: Done 126 tasks      | elapsed: 39.1min\n",
      "[Parallel(n_jobs=-1)]: Done 127 tasks      | elapsed: 39.1min\n",
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed: 39.2min\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed: 39.4min\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed: 39.5min\n",
      "[Parallel(n_jobs=-1)]: Done 131 tasks      | elapsed: 39.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed: 39.8min\n",
      "[Parallel(n_jobs=-1)]: Done 133 tasks      | elapsed: 39.8min\n",
      "[Parallel(n_jobs=-1)]: Done 134 tasks      | elapsed: 40.0min\n",
      "[Parallel(n_jobs=-1)]: Done 135 tasks      | elapsed: 40.0min\n",
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed: 40.2min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed: 40.3min\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed: 40.3min\n",
      "[Parallel(n_jobs=-1)]: Done 139 tasks      | elapsed: 40.3min\n",
      "[Parallel(n_jobs=-1)]: Done 140 tasks      | elapsed: 40.5min\n",
      "[Parallel(n_jobs=-1)]: Done 141 tasks      | elapsed: 41.1min\n",
      "[Parallel(n_jobs=-1)]: Done 142 tasks      | elapsed: 41.4min\n",
      "[Parallel(n_jobs=-1)]: Done 143 tasks      | elapsed: 41.5min\n",
      "[Parallel(n_jobs=-1)]: Done 144 tasks      | elapsed: 41.8min\n",
      "[Parallel(n_jobs=-1)]: Done 145 tasks      | elapsed: 42.5min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 43.0min\n",
      "[Parallel(n_jobs=-1)]: Done 147 tasks      | elapsed: 43.1min\n",
      "[Parallel(n_jobs=-1)]: Done 148 tasks      | elapsed: 43.2min\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed: 44.0min\n",
      "[Parallel(n_jobs=-1)]: Done 150 tasks      | elapsed: 44.1min\n",
      "[Parallel(n_jobs=-1)]: Done 151 tasks      | elapsed: 44.5min\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed: 44.7min\n",
      "[Parallel(n_jobs=-1)]: Done 153 tasks      | elapsed: 44.8min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 45.8min\n",
      "[Parallel(n_jobs=-1)]: Done 155 tasks      | elapsed: 45.9min\n",
      "[Parallel(n_jobs=-1)]: Done 156 tasks      | elapsed: 48.3min\n",
      "[Parallel(n_jobs=-1)]: Done 157 tasks      | elapsed: 48.4min\n",
      "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed: 48.6min\n",
      "[Parallel(n_jobs=-1)]: Done 159 tasks      | elapsed: 49.7min\n",
      "[Parallel(n_jobs=-1)]: Done 160 tasks      | elapsed: 50.1min\n",
      "[Parallel(n_jobs=-1)]: Done 161 tasks      | elapsed: 50.2min\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed: 51.6min\n",
      "[Parallel(n_jobs=-1)]: Done 163 tasks      | elapsed: 51.7min\n",
      "[Parallel(n_jobs=-1)]: Done 164 tasks      | elapsed: 51.8min\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed: 52.0min\n",
      "[Parallel(n_jobs=-1)]: Done 166 tasks      | elapsed: 52.5min\n",
      "[Parallel(n_jobs=-1)]: Done 167 tasks      | elapsed: 52.8min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed: 52.9min\n",
      "[Parallel(n_jobs=-1)]: Done 169 tasks      | elapsed: 53.4min\n",
      "[Parallel(n_jobs=-1)]: Done 170 tasks      | elapsed: 53.5min\n",
      "[Parallel(n_jobs=-1)]: Done 171 tasks      | elapsed: 57.3min\n",
      "[Parallel(n_jobs=-1)]: Done 172 tasks      | elapsed: 57.7min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed: 58.1min\n",
      "[Parallel(n_jobs=-1)]: Done 174 tasks      | elapsed: 59.1min\n",
      "[Parallel(n_jobs=-1)]: Done 175 tasks      | elapsed: 59.5min\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed: 59.9min\n",
      "[Parallel(n_jobs=-1)]: Done 177 tasks      | elapsed: 60.5min\n",
      "[Parallel(n_jobs=-1)]: Done 178 tasks      | elapsed: 60.8min\n",
      "[Parallel(n_jobs=-1)]: Done 179 tasks      | elapsed: 61.2min\n",
      "[Parallel(n_jobs=-1)]: Done 180 tasks      | elapsed: 62.3min\n",
      "[Parallel(n_jobs=-1)]: Done 181 tasks      | elapsed: 62.7min\n",
      "[Parallel(n_jobs=-1)]: Done 182 tasks      | elapsed: 62.9min\n",
      "[Parallel(n_jobs=-1)]: Done 183 tasks      | elapsed: 62.9min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 63.4min\n",
      "[Parallel(n_jobs=-1)]: Done 185 tasks      | elapsed: 63.6min\n",
      "[Parallel(n_jobs=-1)]: Done 186 tasks      | elapsed: 64.0min\n",
      "[Parallel(n_jobs=-1)]: Done 187 tasks      | elapsed: 64.1min\n",
      "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed: 64.2min\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed: 64.3min\n",
      "[Parallel(n_jobs=-1)]: Done 190 tasks      | elapsed: 64.3min\n",
      "[Parallel(n_jobs=-1)]: Done 191 tasks      | elapsed: 64.4min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 64.5min\n",
      "[Parallel(n_jobs=-1)]: Done 193 tasks      | elapsed: 64.6min\n",
      "[Parallel(n_jobs=-1)]: Done 194 tasks      | elapsed: 64.6min\n",
      "[Parallel(n_jobs=-1)]: Done 195 tasks      | elapsed: 64.6min\n",
      "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed: 65.3min\n",
      "[Parallel(n_jobs=-1)]: Done 197 tasks      | elapsed: 65.3min\n",
      "[Parallel(n_jobs=-1)]: Done 198 tasks      | elapsed: 65.4min\n",
      "[Parallel(n_jobs=-1)]: Done 199 tasks      | elapsed: 65.4min\n",
      "[Parallel(n_jobs=-1)]: Done 200 tasks      | elapsed: 65.5min\n",
      "[Parallel(n_jobs=-1)]: Done 201 tasks      | elapsed: 65.5min\n",
      "[Parallel(n_jobs=-1)]: Done 202 tasks      | elapsed: 65.5min\n",
      "[Parallel(n_jobs=-1)]: Done 203 tasks      | elapsed: 65.7min\n",
      "[Parallel(n_jobs=-1)]: Done 204 tasks      | elapsed: 65.7min\n",
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed: 66.0min\n",
      "[Parallel(n_jobs=-1)]: Done 206 tasks      | elapsed: 68.1min\n",
      "[Parallel(n_jobs=-1)]: Done 207 tasks      | elapsed: 68.1min\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed: 68.9min\n",
      "[Parallel(n_jobs=-1)]: Done 209 tasks      | elapsed: 69.7min\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed: 69.7min\n",
      "[Parallel(n_jobs=-1)]: Done 211 tasks      | elapsed: 70.3min\n",
      "[Parallel(n_jobs=-1)]: Done 212 tasks      | elapsed: 70.4min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed: 70.8min\n",
      "[Parallel(n_jobs=-1)]: Done 214 tasks      | elapsed: 70.9min\n",
      "[Parallel(n_jobs=-1)]: Done 215 tasks      | elapsed: 71.3min\n",
      "[Parallel(n_jobs=-1)]: Done 216 tasks      | elapsed: 71.6min\n",
      "[Parallel(n_jobs=-1)]: Done 217 tasks      | elapsed: 72.0min\n",
      "[Parallel(n_jobs=-1)]: Done 218 tasks      | elapsed: 72.1min\n",
      "[Parallel(n_jobs=-1)]: Done 219 tasks      | elapsed: 72.7min\n",
      "[Parallel(n_jobs=-1)]: Done 220 tasks      | elapsed: 72.9min\n",
      "[Parallel(n_jobs=-1)]: Done 221 tasks      | elapsed: 75.4min\n",
      "[Parallel(n_jobs=-1)]: Done 222 tasks      | elapsed: 75.4min\n",
      "[Parallel(n_jobs=-1)]: Done 223 tasks      | elapsed: 77.3min\n",
      "[Parallel(n_jobs=-1)]: Done 224 tasks      | elapsed: 77.3min\n",
      "[Parallel(n_jobs=-1)]: Done 225 tasks      | elapsed: 78.1min\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed: 78.6min\n",
      "[Parallel(n_jobs=-1)]: Done 227 tasks      | elapsed: 79.0min\n",
      "[Parallel(n_jobs=-1)]: Done 228 tasks      | elapsed: 79.5min\n",
      "[Parallel(n_jobs=-1)]: Done 229 tasks      | elapsed: 80.0min\n",
      "[Parallel(n_jobs=-1)]: Done 230 tasks      | elapsed: 80.2min\n",
      "[Parallel(n_jobs=-1)]: Done 231 tasks      | elapsed: 81.9min\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed: 82.4min\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed: 82.7min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed: 83.5min\n",
      "[Parallel(n_jobs=-1)]: Done 235 tasks      | elapsed: 84.3min\n",
      "[Parallel(n_jobs=-1)]: Done 236 tasks      | elapsed: 84.4min\n",
      "[Parallel(n_jobs=-1)]: Done 237 tasks      | elapsed: 85.5min\n",
      "[Parallel(n_jobs=-1)]: Done 238 tasks      | elapsed: 85.6min\n",
      "[Parallel(n_jobs=-1)]: Done 239 tasks      | elapsed: 85.7min\n",
      "[Parallel(n_jobs=-1)]: Done 240 tasks      | elapsed: 85.7min\n",
      "[Parallel(n_jobs=-1)]: Done 241 tasks      | elapsed: 85.8min\n",
      "[Parallel(n_jobs=-1)]: Done 242 tasks      | elapsed: 85.9min\n",
      "[Parallel(n_jobs=-1)]: Done 243 tasks      | elapsed: 85.9min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed: 87.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=False),\n",
       "                   error_score=nan,\n",
       "                   estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
       "                                           batch_size='auto', beta_1=0.9,\n",
       "                                           beta_2=0.999, early_stopping=False,\n",
       "                                           epsilon=1e-08,\n",
       "                                           hidden_layer_sizes=(100,),\n",
       "                                           learning_rate='constant',\n",
       "                                           learning_rate_init=0.001,\n",
       "                                           max_fun=15000, max_iter=200,\n",
       "                                           momentum=0.9, n_iter...\n",
       "                                        'hidden_layer_sizes': [(10,), (12,),\n",
       "                                                               (14,), (16,),\n",
       "                                                               (18,), (20,),\n",
       "                                                               (22,), (24,),\n",
       "                                                               (26,), (28,),\n",
       "                                                               (30,)],\n",
       "                                        'learning_rate': ['constant',\n",
       "                                                          'invscaling',\n",
       "                                                          'adaptive'],\n",
       "                                        'learning_rate_init': [0.0005, 0.001,\n",
       "                                                               0.0015, 0.002],\n",
       "                                        'max_iter': [500, 750, 1000, 1250,\n",
       "                                                     1500],\n",
       "                                        'solver': ['lbfgs', 'sgd', 'adam']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=20)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, random_state=42)\n",
    "mlp_final = MLPClassifier()\n",
    "randomized_search_2 = RandomizedSearchCV(estimator = mlp_final, param_distributions = parameter_grid_2, n_iter = 50, \n",
    "                                         cv = cv, verbose=20, random_state=42, n_jobs = -1)\n",
    "randomized_search_2.fit(sens_avg.train_data[features_4], sens_avg.train_data[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate random search to identify optimal hyperparameters (2nd run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'solver': 'lbfgs',\n",
       " 'max_iter': 1250,\n",
       " 'learning_rate_init': 0.001,\n",
       " 'learning_rate': 'adaptive',\n",
       " 'hidden_layer_sizes': (26,),\n",
       " 'batch_size': 2250,\n",
       " 'alpha': 0.001,\n",
       " 'activation': 'tanh'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify best hyperparameters retrieved by random search\n",
    "randomized_search_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9759167016743684"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify best hyperparameters retrieved by random search\n",
    "randomized_search_2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit best model on training data\n",
    "best_model_2 = randomized_search_2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time fitting the multilayer perceptron: 0:02:12.130973\n",
      "Accuracy: 0.9855294294294294\n",
      "Precision: 0.006775049129413058\n",
      "Recall: 0.986986986986987\n",
      "F1: 0.013457719421563744\n",
      "---- INFO: Start computing the MAP\n",
      "---- INFO: Probabilities predicted\n",
      "---- INFO: Dataframe with evaluation ranking created\n",
      "---- INFO: Probabilities sorted for each query\n",
      "---- INFO: Index of ranking of true translation retrieved\n",
      "MAP: 0.8584644422131052\n"
     ]
    }
   ],
   "source": [
    "# Evaluate best model on test collection\n",
    "start = datetime.datetime.now()\n",
    "best_model_2.fit(sens_avg.train_data[features_4], sens_avg.train_data[label])\n",
    "stop = datetime.datetime.now()\n",
    "print('Computation time fitting the multilayer perceptron: {}'.format(stop-start))\n",
    "\n",
    "# Evaluation on test collection\n",
    "sup = sup_model.SupModel()\n",
    "sup.evaluate_boolean(best_model_2, sens_avg, features_4)\n",
    "print('Accuracy: {}'.format(sup.accuracy))\n",
    "print('Precision: {}'.format(sup.precision))\n",
    "print('Recall: {}'.format(sup.recall))\n",
    "print('F1: {}'.format(sup.f1))\n",
    "\n",
    "print('MAP: {}'.format(sup.compute_map(best_model_2, sens_avg, features_4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Did not further improve w.r.t. MAP -> choose model from first random search as best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_model.SupModel.save_model(model=best_model, name='mlp_avg_best', prepared_features=sens_avg.prepared_features, features_dict=sens_avg.features_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../main/models/scaler/ct.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(ct, '../main/models/scaler/ct.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prefix in ['src', 'trg']:\n",
    "    joblib.dump(pca['{}'.format(prefix)], '../main/models/pca/pca_{}.pkl'.format(prefix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save mean_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prefix in ['src', 'trg']:\n",
    "    joblib.dump(mean_scaler['{}'.format(prefix)], '../main/models/mean_scaler/mean_scaler_{}.pkl'.format(prefix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get order of relevant features to use it in app and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
