{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import importlib, datetime\n",
    "import copy\n",
    "from sklearn.externals import joblib\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ir_crosslingual.features.element_based' from '/Users/jani/PycharmProjects/ir-crosslingual/ir_crosslingual/features/element_based.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ir_crosslingual.supervised_classification import sup_model\n",
    "importlib.reload(sup_model)\n",
    "\n",
    "from ir_crosslingual.utils import paths\n",
    "importlib.reload(paths)\n",
    "\n",
    "from ir_crosslingual.embeddings import embeddings\n",
    "importlib.reload(embeddings)\n",
    "\n",
    "from ir_crosslingual.sentences import sentences\n",
    "importlib.reload(sentences)\n",
    "\n",
    "from ir_crosslingual.features import element_based\n",
    "importlib.reload(element_based)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- INFO: Learn projection matrix for en-de\n",
      "---- INFO: Found 13700 valid translation pairs in expert dictionary.\n",
      "---- INFO: 977 other pairs contained at least one unknown word (0 in source language, 977 in target language).\n",
      "---- DONE: Seed dictionary extracted for the languages: en-de\n",
      "---- INFO: Resulting subspace dimension: (13700, 300)\n",
      "---- INFO: Resulting subspace dimension: (13700, 300)\n",
      "---- DONE: Projection matrix learned from en to de\n",
      "---- INFO: Learn projection matrix for de-en\n",
      "---- INFO: Found 10604 valid translation pairs in expert dictionary.\n",
      "---- INFO: 262 other pairs contained at least one unknown word (0 in source language, 262 in target language).\n",
      "---- DONE: Seed dictionary extracted for the languages: de-en\n",
      "---- INFO: Resulting subspace dimension: (10604, 300)\n",
      "---- INFO: Resulting subspace dimension: (10604, 300)\n",
      "---- DONE: Projection matrix learned from de to en\n",
      "---- INFO: File loaded containing training data\n",
      "---- INFO: File loaded containing test collection\n",
      "---- DONE: All files loaded and features extracted\n"
     ]
    }
   ],
   "source": [
    "train_file_avg = f'{paths.data_path}extracted_data/global/training_data_avg.pkl'\n",
    "test_file_avg = f'{paths.data_path}extracted_data/global/test_collection_avg.pkl'\n",
    "sens_avg, train_data_avg, test_collection_avg, features_avg = sentences.Sentences.load_from_file(train_file_avg, test_file_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce embedding dimensionality and extract elements as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_scaler = {}\n",
    "for prefix in ['src', 'trg']:\n",
    "    mean_scaler['{}'.format(prefix)] = StandardScaler(with_std=False)\n",
    "    X = np.vstack(sens_avg.train_data['{}_embedding'.format(prefix)])\n",
    "    mean_scaler['{}'.format(prefix)].fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = {}\n",
    "for prefix in ['src', 'trg']:\n",
    "    pca['{}'.format(prefix)] = PCA(n_components=10, random_state=42)\n",
    "    X = np.vstack(sens_avg.train_data['{}_embedding'.format(prefix)])\n",
    "    X = mean_scaler['{}'.format(prefix)].transform(X)\n",
    "    pca['{}'.format(prefix)].fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- INFO: Unique queries extracted\n",
      "---- INFO: Unique documents extracted\n",
      "---- INFO: Started extraction for src language.\n",
      "---- INFO: src_embedding_pca elements extracted for train data.\n",
      "---- INFO: src_embedding_pca elements extracted for unique queries.\n",
      "---- INFO: Unique queries merged to test collection\n",
      "---- INFO: Started extraction for trg language.\n",
      "---- INFO: trg_embedding_pca elements extracted for train data.\n",
      "---- INFO: trg_embedding_pca elements extracted for unique documents.\n",
      "---- INFO: Unique documents merged to test collection\n",
      "---- DONE: Extracted all vector elements and merged to test collection\n"
     ]
    }
   ],
   "source": [
    "sens_avg = element_based.vec2features(sens_avg, pca, mean_scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove pairs that cointain sentences equal to '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens_avg.train_data = sens_avg.train_data[(sens_avg.train_data['src_sentence'] != '.') & (sens_avg.train_data['trg_sentence'] != '.')]\n",
    "sens_avg.test_collection = sens_avg.test_collection[(sens_avg.test_collection['src_sentence'] != '.') & (sens_avg.test_collection['trg_sentence'] != '.')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale features (z-scores for numerical, OneHotEncoding for categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define features\n",
    "model_features = ['src_sentence', 'trg_sentence', 'translation',\n",
    "                  'norm_diff_translated_words', 'abs_diff_num_words', 'abs_diff_num_punctuation',\n",
    "                  'abs_diff_occ_question_mark', 'abs_diff_occ_exclamation_mark',\n",
    "                  'rel_diff_num_words', 'rel_diff_num_punctuation', 'norm_diff_num_words',\n",
    "                  'norm_diff_num_punctuation', 'euclidean_distance', 'cosine_similarity'] \\\n",
    "                 + ['src_embedding_pca_{}'.format(i) for i in range(10)] \\\n",
    "                 + ['trg_embedding_pca_{}'.format(i) for i in range(10)]\n",
    "num_features = ['norm_diff_translated_words', 'abs_diff_num_words', 'abs_diff_num_punctuation',\n",
    "                'rel_diff_num_words', 'rel_diff_num_punctuation', 'norm_diff_num_words',\n",
    "                'norm_diff_num_punctuation', 'euclidean_distance', 'cosine_similarity'] \\\n",
    "                 + ['src_embedding_pca_{}'.format(i) for i in range(10)] \\\n",
    "                 + ['trg_embedding_pca_{}'.format(i) for i in range(10)]\n",
    "cat_features = ['abs_diff_occ_question_mark', 'abs_diff_occ_exclamation_mark']\n",
    "meta_features = ['src_sentence', 'trg_sentence']\n",
    "label = 'translation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit scaler on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column transformer / scaler\n",
    "numeric_pipeline = make_pipeline(StandardScaler())\n",
    "cat_pipeline     = make_pipeline(OneHotEncoder())\n",
    "\n",
    "transformers = [\n",
    "('num', numeric_pipeline, num_features),\n",
    "('cat', cat_pipeline, cat_features)\n",
    "]\n",
    "\n",
    "ct = ColumnTransformer(transformers, remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function that get feature names of transformed columns\n",
    "def get_transformer_feature_names(columnTransformer):\n",
    "\n",
    "    output_features = []\n",
    "\n",
    "    for name, pipe, features in columnTransformer.transformers_:\n",
    "        if name!='remainder':\n",
    "            for i in pipe:\n",
    "                trans_features = []\n",
    "                if hasattr(i,'categories_'):\n",
    "                    trans_features.extend(i.get_feature_names(features))\n",
    "                else:\n",
    "                    trans_features = features\n",
    "            output_features.extend(trans_features)\n",
    "\n",
    "    return output_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted.\n"
     ]
    }
   ],
   "source": [
    "# fit scaler on training data and scale training columns\n",
    "ct.fit(sens_avg.train_data[model_features])\n",
    "print('Fitted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data scaled.\n"
     ]
    }
   ],
   "source": [
    "sens_avg.train_data = pd.DataFrame(ct.transform(sens_avg.train_data[model_features]))\n",
    "sens_avg.train_data.columns = get_transformer_feature_names(ct) + meta_features + [label]\n",
    "sens_avg.train_data = sens_avg.train_data.infer_objects()\n",
    "print('Train data scaled.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide test collection into chunks which allows for faster operations on test collection\n",
    "n = 500000  #chunk row size\n",
    "chunks_test_collection = [sens_avg.test_collection[i:i+n] for i in range(0, sens_avg.test_collection.shape[0], n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0 scaled.\n",
      "Chunk 1 scaled.\n",
      "Chunk 2 scaled.\n",
      "Chunk 3 scaled.\n",
      "Chunk 4 scaled.\n",
      "Chunk 5 scaled.\n",
      "Chunk 6 scaled.\n",
      "Chunk 7 scaled.\n",
      "Chunk 8 scaled.\n",
      "Chunk 9 scaled.\n",
      "Chunk 10 scaled.\n",
      "Chunk 11 scaled.\n",
      "Chunk 12 scaled.\n",
      "Chunk 13 scaled.\n",
      "Chunk 14 scaled.\n",
      "Chunk 15 scaled.\n",
      "Chunk 16 scaled.\n",
      "Chunk 17 scaled.\n",
      "Chunk 18 scaled.\n",
      "Chunk 19 scaled.\n"
     ]
    }
   ],
   "source": [
    "# scale columns of test collection\n",
    "for i, chunk in enumerate(chunks_test_collection):\n",
    "    chunks_test_collection[i] = pd.DataFrame(ct.transform(chunk[model_features]))\n",
    "    chunks_test_collection[i].columns = get_transformer_feature_names(ct) + meta_features + [label]\n",
    "    chunks_test_collection[i] = chunks_test_collection[i].infer_objects()\n",
    "    print('Chunk {} scaled.'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update data attribute of Sentences object\n",
    "sens_avg.test_collection = pd.concat([chunk for chunk in chunks_test_collection], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline MLP models using \"average\" aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Use self-selected features based on intuition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_1 = 'norm_diff_translated_words norm_diff_num_punctuation abs_diff_occ_question_mark_0 abs_diff_occ_question_mark_1 abs_diff_occ_question_mark_2 abs_diff_occ_exclamation_mark_0 abs_diff_occ_exclamation_mark_1 abs_diff_occ_exclamation_mark_2 norm_diff_num_words euclidean_distance cosine_similarity'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time fitting the multilayer perceptron: 0:00:12.432663\n",
      "Accuracy: 0.9737696696696697\n",
      "Precision: 0.003631841552830935\n",
      "Recall: 0.955955955955956\n",
      "F1: 0.007236191565858815\n",
      "---- INFO: Start computing the MAP\n",
      "---- INFO: Probabilities predicted\n",
      "---- INFO: Dataframe with evaluation ranking created\n",
      "---- INFO: Probabilities sorted for each query\n",
      "---- INFO: Index of ranking of true translation retrieved\n",
      "MAP: 0.8000676445473803\n"
     ]
    }
   ],
   "source": [
    "# Create baseline MLP classifier\n",
    "mlp_1 = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(5,), random_state=1, learning_rate='adaptive', activation='tanh')\n",
    "\n",
    "# Fit baseline model on training data\n",
    "start = datetime.datetime.now()\n",
    "mlp_1.fit(sens_avg.train_data[features_1], sens_avg.train_data[label])\n",
    "stop = datetime.datetime.now()\n",
    "print('Computation time fitting the multilayer perceptron: {}'.format(stop-start))\n",
    "\n",
    "# Evaluate baseline model on test collection\n",
    "sup = sup_model.SupModel()\n",
    "sup.evaluate_boolean(mlp_1, sens_avg, features_1)\n",
    "print('Accuracy: {}'.format(sup.accuracy))\n",
    "print('Precision: {}'.format(sup.precision))\n",
    "print('Recall: {}'.format(sup.recall))\n",
    "print('F1: {}'.format(sup.f1))\n",
    "\n",
    "print('MAP: {}'.format(sup.compute_map(mlp_1, sens_avg, features_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Use features selected through RFECV (see logistic_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_2 = list(set(features_1 + ['abs_diff_num_words', 'abs_diff_num_punctuation']) - set(['norm_diff_num_punctuation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time fitting the multilayer perceptron: 0:00:13.530632\n",
      "Accuracy: 0.9767011011011011\n",
      "Precision: 0.00415916063688217\n",
      "Recall: 0.972972972972973\n",
      "F1: 0.008282914358755859\n",
      "---- INFO: Start computing the MAP\n",
      "---- INFO: Probabilities predicted\n",
      "---- INFO: Dataframe with evaluation ranking created\n",
      "---- INFO: Probabilities sorted for each query\n",
      "---- INFO: Index of ranking of true translation retrieved\n",
      "MAP: 0.8277222438347304\n"
     ]
    }
   ],
   "source": [
    "# Create baseline MLP classifier\n",
    "mlp_2 = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(5,), random_state=42, learning_rate='adaptive', activation='tanh')\n",
    "\n",
    "# Fit baseline model on training data\n",
    "start = datetime.datetime.now()\n",
    "mlp_2.fit(sens_avg.train_data[features_2], sens_avg.train_data[label])\n",
    "stop = datetime.datetime.now()\n",
    "print('Computation time fitting the multilayer perceptron: {}'.format(stop-start))\n",
    "\n",
    "# Evaluate baseline model on test collection\n",
    "sup = sup_model.SupModel()\n",
    "sup.evaluate_boolean(mlp_2, sens_avg, features_2)\n",
    "print('Accuracy: {}'.format(sup.accuracy))\n",
    "print('Precision: {}'.format(sup.precision))\n",
    "print('Recall: {}'.format(sup.recall))\n",
    "print('F1: {}'.format(sup.f1))\n",
    "\n",
    "print('MAP: {}'.format(sup.compute_map(mlp_2, sens_avg, features_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Use correlation-based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_corr = 'norm_diff_translated_words abs_diff_num_punctuation abs_diff_occ_question_mark_0 abs_diff_occ_question_mark_1 abs_diff_occ_question_mark_2 abs_diff_occ_exclamation_mark_0 abs_diff_occ_exclamation_mark_1 abs_diff_occ_exclamation_mark_2 abs_diff_num_words cosine_similarity'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time fitting the multilayer perceptron: 0:00:07.112758\n",
      "Accuracy: 0.9745493493493493\n",
      "Precision: 0.0037193661792428796\n",
      "Recall: 0.94994994994995\n",
      "F1: 0.00740972086667968\n",
      "---- INFO: Start computing the MAP\n",
      "---- INFO: Probabilities predicted\n",
      "---- INFO: Dataframe with evaluation ranking created\n",
      "---- INFO: Probabilities sorted for each query\n",
      "---- INFO: Index of ranking of true translation retrieved\n",
      "MAP: 0.8256640284049531\n"
     ]
    }
   ],
   "source": [
    "# Create baseline MLP classifier\n",
    "mlp_corr = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(5,), random_state=42, learning_rate='adaptive', activation='tanh')\n",
    "\n",
    "# Fit baseline model on training data\n",
    "start = datetime.datetime.now()\n",
    "mlp_corr.fit(sens_avg.train_data[features_corr], sens_avg.train_data[label])\n",
    "stop = datetime.datetime.now()\n",
    "print('Computation time fitting the multilayer perceptron: {}'.format(stop-start))\n",
    "\n",
    "# Evaluate baseline model on test collection\n",
    "sup = sup_model.SupModel()\n",
    "sup.evaluate_boolean(mlp_corr, sens_avg, features_corr)\n",
    "print('Accuracy: {}'.format(sup.accuracy))\n",
    "print('Precision: {}'.format(sup.precision))\n",
    "print('Recall: {}'.format(sup.recall))\n",
    "print('F1: {}'.format(sup.f1))\n",
    "\n",
    "print('MAP: {}'.format(sup.compute_map(mlp_corr, sens_avg, features_corr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Use all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_3 = features_2 + ['norm_diff_num_punctuation', 'rel_diff_num_words', 'rel_diff_num_punctuation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time fitting the multilayer perceptron: 0:00:14.093721\n",
      "Accuracy: 0.9767005005005005\n",
      "Precision: 0.004154810551763976\n",
      "Recall: 0.9719719719719719\n",
      "F1: 0.008274251823573523\n",
      "---- INFO: Start computing the MAP\n",
      "---- INFO: Probabilities predicted\n",
      "---- INFO: Dataframe with evaluation ranking created\n",
      "---- INFO: Probabilities sorted for each query\n",
      "---- INFO: Index of ranking of true translation retrieved\n",
      "MAP: 0.821184407892351\n"
     ]
    }
   ],
   "source": [
    "# Create baseline MLP classifier\n",
    "mlp_3 = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(5,), random_state=1, learning_rate='adaptive', activation='tanh')\n",
    "\n",
    "# Fit baseline model on training data\n",
    "start = datetime.datetime.now()\n",
    "mlp_3.fit(sens_avg.train_data[features_3], sens_avg.train_data[label])\n",
    "stop = datetime.datetime.now()\n",
    "print('Computation time fitting the multilayer perceptron: {}'.format(stop-start))\n",
    "\n",
    "# Evaluate baseline model on test collection\n",
    "sup = sup_model.SupModel()\n",
    "sup.evaluate_boolean(mlp_3, sens_avg, features_3)\n",
    "print('Accuracy: {}'.format(sup.accuracy))\n",
    "print('Precision: {}'.format(sup.precision))\n",
    "print('Recall: {}'.format(sup.recall))\n",
    "print('F1: {}'.format(sup.f1))\n",
    "\n",
    "print('MAP: {}'.format(sup.compute_map(mlp_3, sens_avg, features_3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Use best of {1,2,3,4} + extracted elements of dimension reduced sentence embedding (10-dim) as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_4 = features_2 + ['src_embedding_pca_{}'.format(i) for i in range(10)] + ['trg_embedding_pca_{}'.format(i) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time fitting the multilayer perceptron: 0:00:20.210128\n",
      "Accuracy: 0.9838556556556557\n",
      "Precision: 0.006040322232700332\n",
      "Recall: 0.980980980980981\n",
      "F1: 0.012006713958417565\n",
      "---- INFO: Start computing the MAP\n",
      "---- INFO: Probabilities predicted\n",
      "---- INFO: Dataframe with evaluation ranking created\n",
      "---- INFO: Probabilities sorted for each query\n",
      "---- INFO: Index of ranking of true translation retrieved\n",
      "MAP: 0.850281183980444\n"
     ]
    }
   ],
   "source": [
    "mlp_4 = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(8,), random_state=1, learning_rate='adaptive', activation='tanh')\n",
    "\n",
    "# Fit baseline model on training data\n",
    "start = datetime.datetime.now()\n",
    "mlp_4.fit(sens_avg.train_data[features_4], sens_avg.train_data[label])\n",
    "stop = datetime.datetime.now()\n",
    "print('Computation time fitting the multilayer perceptron: {}'.format(stop-start))\n",
    "\n",
    "# Evaluate baseline model on test collection\n",
    "sup = sup_model.SupModel()\n",
    "sup.evaluate_boolean(mlp_4, sens_avg, features_4)\n",
    "print('Accuracy: {}'.format(sup.accuracy))\n",
    "print('Precision: {}'.format(sup.precision))\n",
    "print('Recall: {}'.format(sup.recall))\n",
    "print('F1: {}'.format(sup.f1))\n",
    "\n",
    "print('MAP: {}'.format(sup.compute_map(mlp_4, sens_avg, features_4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparametertuning of best model (variant 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create random grid for tuning best model (1st run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden layers\n",
    "hidden_layers = [(4,4), (3,3,2), (8,), (2,2,2,1), (8,3,2), (7,), (9,), (4,3,2)]\n",
    "\n",
    "# Activation function\n",
    "activation = ['identity', 'logistic', 'tanh', 'relu']\n",
    "\n",
    "# Optimizer\n",
    "optimizer = ['lbfgs', 'sgd', 'adam']\n",
    "\n",
    "# Alpha\n",
    "alpha = [0.1, 0.01, 0.001, 0.0001]\n",
    "\n",
    "# Batch size\n",
    "batch_size = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "# Learning rate\n",
    "learning_rate = ['constant', 'invscaling', 'adaptive']\n",
    "\n",
    "# Learning rate init\n",
    "learning_rate_init = [0.1, 0.01, 0.001, 0.0001]\n",
    "\n",
    "# Maximum iterations\n",
    "max_iter = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {\n",
    "    'hidden_layer_sizes': hidden_layers,\n",
    "    'activation': activation,\n",
    "    'solver': optimizer,\n",
    "    'alpha': alpha,\n",
    "    'batch_size': batch_size,\n",
    "    'learning_rate': learning_rate,\n",
    "    'learning_rate_init': learning_rate_init,\n",
    "    'max_iter': max_iter\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform random search for optimal hyperparameters (1st run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, random_state=42)\n",
    "mlp = MLPClassifier(random_state=42)\n",
    "randomized_search = RandomizedSearchCV(estimator = mlp, param_distributions = parameter_grid, n_iter = 50, \n",
    "                                       cv = cv, verbose=20, random_state=42, n_jobs = -1)\n",
    "randomized_search.fit(sens_avg.train_data[features_4], sens_avg.train_data[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate random search to identify optimal hyperparameters and resulting MAP (1st run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'solver': 'lbfgs',\n",
       " 'max_iter': 1200,\n",
       " 'learning_rate_init': 0.001,\n",
       " 'learning_rate': 'adaptive',\n",
       " 'hidden_layer_sizes': (9,),\n",
       " 'batch_size': 2000,\n",
       " 'alpha': 0.1,\n",
       " 'activation': 'tanh'}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify best hyperparameters retrieved by random search\n",
    "randomized_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9742503350737163"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify best hyperparameters retrieved by random search\n",
    "randomized_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit best model on training data\n",
    "best_model = randomized_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time fitting the multilayer perceptron: 0:01:35.418652\n",
      "Accuracy: 0.9847024024024024\n",
      "Precision: 0.006391833019051954\n",
      "Recall: 0.983983983983984\n",
      "F1: 0.012701160935208573\n",
      "---- INFO: Start computing the MAP\n",
      "---- INFO: Probabilities predicted\n",
      "---- INFO: Dataframe with evaluation ranking created\n",
      "---- INFO: Probabilities sorted for each query\n",
      "---- INFO: Index of ranking of true translation retrieved\n",
      "MAP: 0.8666164677324514\n"
     ]
    }
   ],
   "source": [
    "# Evaluate best model on test collection\n",
    "start = datetime.datetime.now()\n",
    "best_model.fit(sens_avg.train_data[features_4], sens_avg.train_data[label])\n",
    "stop = datetime.datetime.now()\n",
    "print('Computation time fitting the multilayer perceptron: {}'.format(stop-start))\n",
    "\n",
    "# Evaluation on test collection\n",
    "sup = sup_model.SupModel()\n",
    "sup.evaluate_boolean(best_model, sens_avg, features_4)\n",
    "print('Accuracy: {}'.format(sup.accuracy))\n",
    "print('Precision: {}'.format(sup.precision))\n",
    "print('Recall: {}'.format(sup.recall))\n",
    "print('F1: {}'.format(sup.f1))\n",
    "\n",
    "print('MAP: {}'.format(sup.compute_map(best_model, sens_avg, features_4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create random grid for tuning best model (variant 5) (2nd run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden layers\n",
    "hidden_layers_2 = [(i,) for i in range(10, 32, 2)]\n",
    "\n",
    "# Activation function\n",
    "activation_2 = ['identity', 'logistic', 'tanh', 'relu']\n",
    "\n",
    "# Optimizer\n",
    "optimizer_2 = ['lbfgs', 'sgd', 'adam']\n",
    "\n",
    "# Alpha\n",
    "alpha_2 = [0.001, 0.005, 0.05, 0.1, 0.15, 0.2]\n",
    "\n",
    "# Batch size\n",
    "batch_size_2 = [int(x) for x in np.linspace(start = 1500, stop = 2500, num = 5)]\n",
    "\n",
    "# Learning rate\n",
    "learning_rate_2 = ['constant', 'invscaling', 'adaptive']\n",
    "\n",
    "# Learning rate init\n",
    "learning_rate_init_2 = [0.0005, 0.001, 0.0015, 0.002]\n",
    "\n",
    "# Maximum iterations\n",
    "max_iter_2 = [int(x) for x in np.linspace(start = 500, stop = 1500, num = 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid_2 = {\n",
    "    'hidden_layer_sizes': hidden_layers_2,\n",
    "    'activation': activation_2,\n",
    "    'solver': optimizer_2,\n",
    "    'alpha': alpha_2,\n",
    "    'batch_size': batch_size_2,\n",
    "    'learning_rate': learning_rate_2,\n",
    "    'learning_rate_init': learning_rate_init_2,\n",
    "    'max_iter': max_iter_2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform random search for optimal hyperparameters (2nd run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, random_state=42)\n",
    "mlp_final = MLPClassifier()\n",
    "randomized_search_2 = RandomizedSearchCV(estimator = mlp_final, param_distributions = parameter_grid_2, n_iter = 50, \n",
    "                                         cv = cv, verbose=20, random_state=42, n_jobs = -1)\n",
    "randomized_search_2.fit(sens_avg.train_data[features_4], sens_avg.train_data[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate random search to identify optimal hyperparameters (2nd run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'solver': 'lbfgs',\n",
       " 'max_iter': 1250,\n",
       " 'learning_rate_init': 0.001,\n",
       " 'learning_rate': 'adaptive',\n",
       " 'hidden_layer_sizes': (26,),\n",
       " 'batch_size': 2250,\n",
       " 'alpha': 0.001,\n",
       " 'activation': 'tanh'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify best hyperparameters retrieved by random search\n",
    "randomized_search_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9759167016743684"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify best hyperparameters retrieved by random search\n",
    "randomized_search_2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit best model on training data\n",
    "best_model_2 = randomized_search_2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time fitting the multilayer perceptron: 0:02:12.130973\n",
      "Accuracy: 0.9855294294294294\n",
      "Precision: 0.006775049129413058\n",
      "Recall: 0.986986986986987\n",
      "F1: 0.013457719421563744\n",
      "---- INFO: Start computing the MAP\n",
      "---- INFO: Probabilities predicted\n",
      "---- INFO: Dataframe with evaluation ranking created\n",
      "---- INFO: Probabilities sorted for each query\n",
      "---- INFO: Index of ranking of true translation retrieved\n",
      "MAP: 0.8584644422131052\n"
     ]
    }
   ],
   "source": [
    "# Evaluate best model on test collection\n",
    "start = datetime.datetime.now()\n",
    "best_model_2.fit(sens_avg.train_data[features_4], sens_avg.train_data[label])\n",
    "stop = datetime.datetime.now()\n",
    "print('Computation time fitting the multilayer perceptron: {}'.format(stop-start))\n",
    "\n",
    "# Evaluation on test collection\n",
    "sup = sup_model.SupModel()\n",
    "sup.evaluate_boolean(best_model_2, sens_avg, features_4)\n",
    "print('Accuracy: {}'.format(sup.accuracy))\n",
    "print('Precision: {}'.format(sup.precision))\n",
    "print('Recall: {}'.format(sup.recall))\n",
    "print('F1: {}'.format(sup.f1))\n",
    "\n",
    "print('MAP: {}'.format(sup.compute_map(best_model_2, sens_avg, features_4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Did not further improve w.r.t. MAP -> choose model from first random search as best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_model.SupModel.save_model(model=best_model, name='mlp_avg_best', prepared_features=sens_avg.prepared_features, features_dict=sens_avg.features_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../main/models/scaler/ct.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(ct, '../main/models/scaler/ct.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prefix in ['src', 'trg']:\n",
    "    joblib.dump(pca['{}'.format(prefix)], '../main/models/pca/pca_{}.pkl'.format(prefix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save mean_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prefix in ['src', 'trg']:\n",
    "    joblib.dump(mean_scaler['{}'.format(prefix)], '../main/models/mean_scaler/mean_scaler_{}.pkl'.format(prefix))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
