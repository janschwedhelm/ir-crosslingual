{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, os, importlib, pickle\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ir_crosslingual.features.element_based' from '/Users/jani/PycharmProjects/ir-crosslingual/ir_crosslingual/features/element_based.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ir_crosslingual.utils import paths\n",
    "importlib.reload(paths)\n",
    "\n",
    "from ir_crosslingual.sentences import sentences\n",
    "importlib.reload(sentences)\n",
    "\n",
    "from ir_crosslingual.supervised_classification import sup_model\n",
    "importlib.reload(sup_model)\n",
    "\n",
    "from ir_crosslingual.features import element_based\n",
    "importlib.reload(element_based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time(start, stop, message):\n",
    "    print('Computation time {}: {}'.format(message, stop-start))\n",
    "    print('Finished at: {}'.format(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model, mlp_prepared_features, mlp_features_dict = sup_model.SupModel.load_model(name='mlp_avg_best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_features = ['norm_diff_num_words', 'euclidean_distance', 'abs_diff_occ_exclamation_mark_0',\n",
    " 'abs_diff_occ_question_mark_2', 'abs_diff_occ_question_mark_0', 'cosine_similarity', 'norm_diff_translated_words',\n",
    " 'abs_diff_occ_exclamation_mark_1', 'abs_diff_occ_question_mark_1', 'abs_diff_num_words',\n",
    " 'abs_diff_occ_exclamation_mark_2', 'abs_diff_num_punctuation', 'src_embedding_pca_0', 'src_embedding_pca_1',\n",
    " 'src_embedding_pca_2', 'src_embedding_pca_3', 'src_embedding_pca_4', 'src_embedding_pca_5', 'src_embedding_pca_6',\n",
    " 'src_embedding_pca_7', 'src_embedding_pca_8', 'src_embedding_pca_9', 'trg_embedding_pca_0', 'trg_embedding_pca_1',\n",
    " 'trg_embedding_pca_2', 'trg_embedding_pca_3', 'trg_embedding_pca_4', 'trg_embedding_pca_5', 'trg_embedding_pca_6',\n",
    " 'trg_embedding_pca_7', 'trg_embedding_pca_8', 'trg_embedding_pca_9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define features\n",
    "model_features = ['src_sentence', 'trg_sentence', 'translation',\n",
    "                  'norm_diff_translated_words', 'abs_diff_num_words', 'abs_diff_num_punctuation',\n",
    "                  'abs_diff_occ_question_mark', 'abs_diff_occ_exclamation_mark',\n",
    "                  'rel_diff_num_words', 'rel_diff_num_punctuation', 'norm_diff_num_words',\n",
    "                  'norm_diff_num_punctuation', 'euclidean_distance', 'cosine_similarity'] \\\n",
    "                 + ['src_embedding_pca_{}'.format(i) for i in range(10)] \\\n",
    "                 + ['trg_embedding_pca_{}'.format(i) for i in range(10)]\n",
    "meta_features = ['src_sentence', 'trg_sentence']\n",
    "label = 'translation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = {}\n",
    "mean_scaler = {}\n",
    "scaler = joblib.load(open('../main/models/scaler/ct.pkl', 'rb'))\n",
    "for prefix in ['src', 'trg']:\n",
    "    mean_scaler['{}'.format(prefix)] = joblib.load(open('../main/models/mean_scaler/mean_scaler_{}.pkl'.format(prefix),\n",
    "                                                        'rb'))\n",
    "    pca['{}'.format(prefix)] = joblib.load(open('../main/models/pca/pca_{}.pkl'.format(prefix), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function that get feature names of transformed columns\n",
    "def get_transformer_feature_names(columnTransformer):\n",
    "\n",
    "    output_features = []\n",
    "\n",
    "    for name, pipe, features in columnTransformer.transformers_:\n",
    "        if name!='remainder':\n",
    "            for i in pipe:\n",
    "                trans_features = []\n",
    "                if hasattr(i,'categories_'):\n",
    "                    trans_features.extend(i.get_feature_names(features))\n",
    "                else:\n",
    "                    trans_features = features\n",
    "            output_features.extend(trans_features)\n",
    "\n",
    "    return output_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English/Finnish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load test collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- INFO: Learn projection matrix for en-fi\n",
      "---- INFO: Found 10141 valid translation pairs in expert dictionary.\n",
      "---- INFO: 1355 other pairs contained at least one unknown word (0 in source language, 1355 in target language).\n",
      "---- INFO: Resulting subspace dimension: (10141, 300)\n",
      "---- INFO: Resulting subspace dimension: (10141, 300)\n",
      "---- DONE: Projection matrix learned from en to fi\n",
      "---- INFO: Learn projection matrix for fi-en\n",
      "---- INFO: Found 6946 valid translation pairs in expert dictionary.\n",
      "---- INFO: 185 other pairs contained at least one unknown word (0 in source language, 185 in target language).\n",
      "---- INFO: Resulting subspace dimension: (6946, 300)\n",
      "---- INFO: Resulting subspace dimension: (6946, 300)\n",
      "---- DONE: Projection matrix learned from fi to en\n",
      "---- DONE: All chunks loaded\n"
     ]
    }
   ],
   "source": [
    "enfi_sens, enfi_chunks = sentences.Sentences.load_chunks_from_file('en', 'fi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "enfi_sens.test_collection = pd.concat(enfi_chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- INFO: Unique queries extracted\n",
      "---- INFO: Unique documents extracted\n",
      "---- INFO: src_embedding_pca elements extracted for unique queries.\n",
      "---- INFO: Unique queries merged to test collection\n",
      "---- INFO: trg_embedding_pca elements extracted for unique documents.\n",
      "---- INFO: Unique documents merged to test collection\n",
      "---- DONE: Extracted all vector elements and merged to test collection\n"
     ]
    }
   ],
   "source": [
    "enfi_sens = element_based.vec2features(enfi_sens, pca, mean_scaler, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide test collection into chunks which allows for faster operations on test collection\n",
    "n = 500000  #chunk row size\n",
    "chunks_test_collection = [enfi_sens.test_collection[i:i+n] for i in range(0, enfi_sens.test_collection.shape[0], n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0 scaled.\n",
      "Chunk 1 scaled.\n",
      "Chunk 2 scaled.\n",
      "Chunk 3 scaled.\n",
      "Chunk 4 scaled.\n",
      "Chunk 5 scaled.\n",
      "Chunk 6 scaled.\n",
      "Chunk 7 scaled.\n",
      "Chunk 8 scaled.\n",
      "Chunk 9 scaled.\n",
      "Chunk 10 scaled.\n",
      "Chunk 11 scaled.\n",
      "Chunk 12 scaled.\n",
      "Chunk 13 scaled.\n",
      "Chunk 14 scaled.\n",
      "Chunk 15 scaled.\n",
      "Chunk 16 scaled.\n",
      "Chunk 17 scaled.\n",
      "Chunk 18 scaled.\n",
      "Chunk 19 scaled.\n"
     ]
    }
   ],
   "source": [
    "# scale columns of test collection\n",
    "for i, chunk in enumerate(chunks_test_collection):\n",
    "    chunks_test_collection[i] = pd.DataFrame(scaler.transform(chunk[model_features]))\n",
    "    chunks_test_collection[i].columns = get_transformer_feature_names(scaler) + meta_features + [label]\n",
    "    chunks_test_collection[i] = chunks_test_collection[i].infer_objects()\n",
    "    print('Chunk {} scaled.'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update data attribute of Sentences object\n",
    "enfi_sens.test_collection = pd.concat([chunk for chunk in chunks_test_collection], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate using MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.402218\n",
      "Precision: 0.00016575249122147376\n",
      "Recall: 0.9831349206349206\n",
      "F1: 0.0003314491014919892\n",
      "Computation time evaluating boolean: 0:00:36.017086\n",
      "Finished at: 2020-05-25 02:31:46.985434\n",
      "---- INFO: Start computing the MAP\n",
      "---- INFO: Probabilities predicted\n",
      "---- INFO: Dataframe with evaluation ranking created\n",
      "---- INFO: Probabilities sorted for each query\n",
      "---- INFO: Index of ranking of true translation retrieved\n",
      "MAP: 0.4139631811202036\n",
      "Computation time computing the MAP score: 0:08:53.518892\n",
      "Finished at: 2020-05-25 02:40:40.517635\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on best MLP model (averaging)\n",
    "start = datetime.datetime.now()\n",
    "sup = sup_model.SupModel()\n",
    "sup.evaluate_boolean(mlp_model, enfi_sens, mlp_features)\n",
    "print('Accuracy: {}'.format(sup.accuracy))\n",
    "print('Precision: {}'.format(sup.precision))\n",
    "print('Recall: {}'.format(sup.recall))\n",
    "print('F1: {}'.format(sup.f1))\n",
    "stop = datetime.datetime.now()\n",
    "time(start, stop, 'evaluating boolean')\n",
    "start = datetime.datetime.now()\n",
    "print('MAP: {}'.format(sup.compute_map(mlp_model, enfi_sens, mlp_features)))\n",
    "stop = datetime.datetime.now()\n",
    "time(start, stop, 'computing the MAP score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finnish/English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- INFO: Learn projection matrix for fi-en\n",
      "---- INFO: Found 6946 valid translation pairs in expert dictionary.\n",
      "---- INFO: 185 other pairs contained at least one unknown word (0 in source language, 185 in target language).\n",
      "---- INFO: Resulting subspace dimension: (6946, 300)\n",
      "---- INFO: Resulting subspace dimension: (6946, 300)\n",
      "---- DONE: Projection matrix learned from fi to en\n",
      "---- INFO: Learn projection matrix for en-fi\n",
      "---- INFO: Found 10141 valid translation pairs in expert dictionary.\n",
      "---- INFO: 1355 other pairs contained at least one unknown word (0 in source language, 1355 in target language).\n",
      "---- INFO: Resulting subspace dimension: (10141, 300)\n",
      "---- INFO: Resulting subspace dimension: (10141, 300)\n",
      "---- DONE: Projection matrix learned from en to fi\n",
      "---- DONE: All chunks loaded\n"
     ]
    }
   ],
   "source": [
    "fien_sens, fien_chunks = sentences.Sentences.load_chunks_from_file('fi', 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fien_sens.test_collection = pd.concat(fien_chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- INFO: Unique queries extracted\n",
      "---- INFO: Unique documents extracted\n",
      "---- INFO: src_embedding_pca elements extracted for unique queries.\n",
      "---- INFO: Unique queries merged to test collection\n",
      "---- INFO: trg_embedding_pca elements extracted for unique documents.\n",
      "---- INFO: Unique documents merged to test collection\n",
      "---- DONE: Extracted all vector elements and merged to test collection\n"
     ]
    }
   ],
   "source": [
    "fien_sens = element_based.vec2features(fien_sens, pca, mean_scaler, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide test collection into chunks which allows for faster operations on test collection\n",
    "n = 500000  #chunk row size\n",
    "chunks_test_collection = [fien_sens.test_collection[i:i+n] for i in range(0, fien_sens.test_collection.shape[0], n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0 scaled.\n",
      "Chunk 1 scaled.\n",
      "Chunk 2 scaled.\n",
      "Chunk 3 scaled.\n",
      "Chunk 4 scaled.\n",
      "Chunk 5 scaled.\n",
      "Chunk 6 scaled.\n",
      "Chunk 7 scaled.\n",
      "Chunk 8 scaled.\n",
      "Chunk 9 scaled.\n",
      "Chunk 10 scaled.\n",
      "Chunk 11 scaled.\n",
      "Chunk 12 scaled.\n",
      "Chunk 13 scaled.\n",
      "Chunk 14 scaled.\n",
      "Chunk 15 scaled.\n",
      "Chunk 16 scaled.\n",
      "Chunk 17 scaled.\n",
      "Chunk 18 scaled.\n",
      "Chunk 19 scaled.\n"
     ]
    }
   ],
   "source": [
    "# scale columns of test collection\n",
    "for i, chunk in enumerate(chunks_test_collection):\n",
    "    chunks_test_collection[i] = pd.DataFrame(scaler.transform(chunk[model_features]))\n",
    "    chunks_test_collection[i].columns = get_transformer_feature_names(scaler) + meta_features + [label]\n",
    "    chunks_test_collection[i] = chunks_test_collection[i].infer_objects()\n",
    "    print('Chunk {} scaled.'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update data attribute of Sentences object\n",
    "fien_sens.test_collection = pd.concat([chunk for chunk in chunks_test_collection], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5082956\n",
      "Precision: 0.0002002843427664209\n",
      "Recall: 0.9791252485089463\n",
      "F1: 0.0004004867642173818\n",
      "Computation time evaluating boolean: 0:00:43.795049\n",
      "Finished at: 2020-05-25 02:55:40.501795\n",
      "---- INFO: Start computing the MAP\n",
      "---- INFO: Probabilities predicted\n",
      "---- INFO: Dataframe with evaluation ranking created\n",
      "---- INFO: Probabilities sorted for each query\n",
      "---- INFO: Index of ranking of true translation retrieved\n",
      "MAP: 0.47729229459696015\n",
      "Computation time computing the MAP score: 0:08:15.265381\n",
      "Finished at: 2020-05-25 03:03:55.786329\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on best MLP model (averaging)\n",
    "start = datetime.datetime.now()\n",
    "sup = sup_model.SupModel()\n",
    "sup.evaluate_boolean(mlp_model, fien_sens, mlp_features)\n",
    "print('Accuracy: {}'.format(sup.accuracy))\n",
    "print('Precision: {}'.format(sup.precision))\n",
    "print('Recall: {}'.format(sup.recall))\n",
    "print('F1: {}'.format(sup.f1))\n",
    "stop = datetime.datetime.now()\n",
    "time(start, stop, 'evaluating boolean')\n",
    "start = datetime.datetime.now()\n",
    "print('MAP: {}'.format(sup.compute_map(mlp_model, fien_sens, mlp_features)))\n",
    "stop = datetime.datetime.now()\n",
    "time(start, stop, 'computing the MAP score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English/French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- INFO: Learn projection matrix for en-fr\n",
      "---- INFO: Found 10369 valid translation pairs in expert dictionary.\n",
      "---- INFO: 503 other pairs contained at least one unknown word (0 in source language, 503 in target language).\n",
      "---- INFO: Resulting subspace dimension: (10369, 300)\n",
      "---- INFO: Resulting subspace dimension: (10369, 300)\n",
      "---- DONE: Projection matrix learned from en to fr\n",
      "---- INFO: Learn projection matrix for fr-en\n",
      "---- INFO: Found 7938 valid translation pairs in expert dictionary.\n",
      "---- INFO: 332 other pairs contained at least one unknown word (0 in source language, 332 in target language).\n",
      "---- INFO: Resulting subspace dimension: (7938, 300)\n",
      "---- INFO: Resulting subspace dimension: (7938, 300)\n",
      "---- DONE: Projection matrix learned from fr to en\n",
      "---- DONE: All chunks loaded\n"
     ]
    }
   ],
   "source": [
    "enfr_sens, enfr_chunks = sentences.Sentences.load_chunks_from_file('en', 'fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "enfr_sens.test_collection = pd.concat(enfr_chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- INFO: Unique queries extracted\n",
      "---- INFO: Unique documents extracted\n",
      "---- INFO: src_embedding_pca elements extracted for unique queries.\n",
      "---- INFO: Unique queries merged to test collection\n",
      "---- INFO: trg_embedding_pca elements extracted for unique documents.\n",
      "---- INFO: Unique documents merged to test collection\n",
      "---- DONE: Extracted all vector elements and merged to test collection\n"
     ]
    }
   ],
   "source": [
    "enfr_sens = element_based.vec2features(enfr_sens, pca, mean_scaler, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide test collection into chunks which allows for faster operations on test collection\n",
    "n = 500000  #chunk row size\n",
    "chunks_test_collection = [enfr_sens.test_collection[i:i+n] for i in range(0, enfr_sens.test_collection.shape[0], n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0 scaled.\n",
      "Chunk 1 scaled.\n",
      "Chunk 2 scaled.\n",
      "Chunk 3 scaled.\n",
      "Chunk 4 scaled.\n",
      "Chunk 5 scaled.\n",
      "Chunk 6 scaled.\n",
      "Chunk 7 scaled.\n",
      "Chunk 8 scaled.\n",
      "Chunk 9 scaled.\n",
      "Chunk 10 scaled.\n",
      "Chunk 11 scaled.\n",
      "Chunk 12 scaled.\n",
      "Chunk 13 scaled.\n",
      "Chunk 14 scaled.\n",
      "Chunk 15 scaled.\n",
      "Chunk 16 scaled.\n",
      "Chunk 17 scaled.\n",
      "Chunk 18 scaled.\n",
      "Chunk 19 scaled.\n"
     ]
    }
   ],
   "source": [
    "# scale columns of test collection\n",
    "for i, chunk in enumerate(chunks_test_collection):\n",
    "    chunks_test_collection[i] = pd.DataFrame(scaler.transform(chunk[model_features]))\n",
    "    chunks_test_collection[i].columns = get_transformer_feature_names(scaler) + meta_features + [label]\n",
    "    chunks_test_collection[i] = chunks_test_collection[i].infer_objects()\n",
    "    print('Chunk {} scaled.'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update data attribute of Sentences object\n",
    "enfr_sens.test_collection = pd.concat([chunk for chunk in chunks_test_collection], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on logistic regression model\n",
      "Accuracy: 0.7297366\n",
      "Precision: 0.0003709834019140968\n",
      "Recall: 0.9881773399014778\n",
      "F1: 0.0007416883577851396\n",
      "Computation time evaluating boolean: 0:00:42.494557\n",
      "Finished at: 2020-05-25 03:22:41.938356\n",
      "---- INFO: Start computing the MAP\n",
      "---- INFO: Probabilities predicted\n",
      "---- INFO: Dataframe with evaluation ranking created\n",
      "---- INFO: Probabilities sorted for each query\n",
      "---- INFO: Index of ranking of true translation retrieved\n",
      "MAP: 0.8029382924535479\n",
      "Computation time computing the MAP score: 0:08:04.816642\n",
      "Finished at: 2020-05-25 03:30:46.760768\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on best MLP model (averaging)\n",
    "print('Evaluation on logistic regression model')\n",
    "start = datetime.datetime.now()\n",
    "sup = sup_model.SupModel()\n",
    "sup.evaluate_boolean(mlp_model, enfr_sens, mlp_features)\n",
    "print('Accuracy: {}'.format(sup.accuracy))\n",
    "print('Precision: {}'.format(sup.precision))\n",
    "print('Recall: {}'.format(sup.recall))\n",
    "print('F1: {}'.format(sup.f1))\n",
    "stop = datetime.datetime.now()\n",
    "time(start, stop, 'evaluating boolean')\n",
    "start = datetime.datetime.now()\n",
    "print('MAP: {}'.format(sup.compute_map(mlp_model, enfr_sens, mlp_features)))\n",
    "stop = datetime.datetime.now()\n",
    "time(start, stop, 'computing the MAP score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## French/English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- INFO: Learn projection matrix for fr-en\n",
      "---- INFO: Found 7938 valid translation pairs in expert dictionary.\n",
      "---- INFO: 332 other pairs contained at least one unknown word (0 in source language, 332 in target language).\n",
      "---- INFO: Resulting subspace dimension: (7938, 300)\n",
      "---- INFO: Resulting subspace dimension: (7938, 300)\n",
      "---- DONE: Projection matrix learned from fr to en\n",
      "---- INFO: Learn projection matrix for en-fr\n",
      "---- INFO: Found 10369 valid translation pairs in expert dictionary.\n",
      "---- INFO: 503 other pairs contained at least one unknown word (0 in source language, 503 in target language).\n",
      "---- INFO: Resulting subspace dimension: (10369, 300)\n",
      "---- INFO: Resulting subspace dimension: (10369, 300)\n",
      "---- DONE: Projection matrix learned from en to fr\n",
      "---- DONE: All chunks loaded\n"
     ]
    }
   ],
   "source": [
    "fren_sens, fren_chunks = sentences.Sentences.load_chunks_from_file('fr', 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fren_sens.test_collection = pd.concat(fren_chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- INFO: Unique queries extracted\n",
      "---- INFO: Unique documents extracted\n",
      "---- INFO: src_embedding_pca elements extracted for unique queries.\n",
      "---- INFO: Unique queries merged to test collection\n",
      "---- INFO: trg_embedding_pca elements extracted for unique documents.\n",
      "---- INFO: Unique documents merged to test collection\n",
      "---- DONE: Extracted all vector elements and merged to test collection\n"
     ]
    }
   ],
   "source": [
    "fren_sens = element_based.vec2features(fren_sens, pca, mean_scaler, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide test collection into chunks which allows for faster operations on test collection\n",
    "n = 500000  #chunk row size\n",
    "chunks_test_collection = [fren_sens.test_collection[i:i+n] for i in range(0, fren_sens.test_collection.shape[0], n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0 scaled.\n",
      "Chunk 1 scaled.\n",
      "Chunk 2 scaled.\n",
      "Chunk 3 scaled.\n",
      "Chunk 4 scaled.\n",
      "Chunk 5 scaled.\n",
      "Chunk 6 scaled.\n",
      "Chunk 7 scaled.\n",
      "Chunk 8 scaled.\n",
      "Chunk 9 scaled.\n",
      "Chunk 10 scaled.\n",
      "Chunk 11 scaled.\n",
      "Chunk 12 scaled.\n",
      "Chunk 13 scaled.\n",
      "Chunk 14 scaled.\n",
      "Chunk 15 scaled.\n",
      "Chunk 16 scaled.\n",
      "Chunk 17 scaled.\n",
      "Chunk 18 scaled.\n",
      "Chunk 19 scaled.\n"
     ]
    }
   ],
   "source": [
    "# scale columns of test collection\n",
    "for i, chunk in enumerate(chunks_test_collection):\n",
    "    chunks_test_collection[i] = pd.DataFrame(scaler.transform(chunk[model_features]))\n",
    "    chunks_test_collection[i].columns = get_transformer_feature_names(scaler) + meta_features + [label]\n",
    "    chunks_test_collection[i] = chunks_test_collection[i].infer_objects()\n",
    "    print('Chunk {} scaled.'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update data attribute of Sentences object\n",
    "fren_sens.test_collection = pd.concat([chunk for chunk in chunks_test_collection], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on logistic regression model\n",
      "Accuracy: 0.6560946\n",
      "Precision: 0.00029330909342490546\n",
      "Recall: 0.994088669950739\n",
      "F1: 0.0005864451543007527\n",
      "Computation time evaluating boolean: 0:00:35.001575\n",
      "Finished at: 2020-05-25 03:43:41.698965\n",
      "---- INFO: Start computing the MAP\n",
      "---- INFO: Probabilities predicted\n",
      "---- INFO: Dataframe with evaluation ranking created\n",
      "---- INFO: Probabilities sorted for each query\n",
      "---- INFO: Index of ranking of true translation retrieved\n",
      "MAP: 0.8590039263547499\n",
      "Computation time computing the MAP score: 0:08:42.451902\n",
      "Finished at: 2020-05-25 03:52:24.156955\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on best MLP model (averaging)\n",
    "print('Evaluation on logistic regression model')\n",
    "start = datetime.datetime.now()\n",
    "sup = sup_model.SupModel()\n",
    "sup.evaluate_boolean(mlp_model, fren_sens, mlp_features)\n",
    "print('Accuracy: {}'.format(sup.accuracy))\n",
    "print('Precision: {}'.format(sup.precision))\n",
    "print('Recall: {}'.format(sup.recall))\n",
    "print('F1: {}'.format(sup.f1))\n",
    "stop = datetime.datetime.now()\n",
    "time(start, stop, 'evaluating boolean')\n",
    "start = datetime.datetime.now()\n",
    "print('MAP: {}'.format(sup.compute_map(mlp_model, fren_sens, mlp_features)))\n",
    "stop = datetime.datetime.now()\n",
    "time(start, stop, 'computing the MAP score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## German/English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- INFO: Learn projection matrix for de-en\n",
      "---- INFO: Found 10604 valid translation pairs in expert dictionary.\n",
      "---- INFO: 262 other pairs contained at least one unknown word (0 in source language, 262 in target language).\n",
      "---- DONE: Seed dictionary extracted for the languages: de-en\n",
      "---- INFO: Resulting subspace dimension: (10604, 300)\n",
      "---- INFO: Resulting subspace dimension: (10604, 300)\n",
      "---- DONE: Projection matrix learned from de to en\n",
      "---- INFO: Learn projection matrix for en-de\n",
      "---- INFO: Found 13700 valid translation pairs in expert dictionary.\n",
      "---- INFO: 977 other pairs contained at least one unknown word (0 in source language, 977 in target language).\n",
      "---- DONE: Seed dictionary extracted for the languages: en-de\n",
      "---- INFO: Resulting subspace dimension: (13700, 300)\n",
      "---- INFO: Resulting subspace dimension: (13700, 300)\n",
      "---- DONE: Projection matrix learned from en to de\n",
      "---- DONE: All chunks loaded\n"
     ]
    }
   ],
   "source": [
    "deen_sens, deen_chunks = sentences.Sentences.load_chunks_from_file('de', 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "deen_sens.test_collection = pd.concat(deen_chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- INFO: Unique queries extracted\n",
      "---- INFO: Unique documents extracted\n",
      "---- INFO: src_embedding_pca elements extracted for unique queries.\n",
      "---- INFO: Unique queries merged to test collection\n",
      "---- INFO: trg_embedding_pca elements extracted for unique documents.\n",
      "---- INFO: Unique documents merged to test collection\n",
      "---- DONE: Extracted all vector elements and merged to test collection\n"
     ]
    }
   ],
   "source": [
    "deen_sens = element_based.vec2features(deen_sens, pca, mean_scaler, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide test collection into chunks which allows for faster operations on test collection\n",
    "n = 500000  #chunk row size\n",
    "chunks_test_collection = [deen_sens.test_collection[i:i+n] for i in range(0, deen_sens.test_collection.shape[0], n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0 scaled.\n",
      "Chunk 1 scaled.\n",
      "Chunk 2 scaled.\n",
      "Chunk 3 scaled.\n",
      "Chunk 4 scaled.\n",
      "Chunk 5 scaled.\n",
      "Chunk 6 scaled.\n",
      "Chunk 7 scaled.\n",
      "Chunk 8 scaled.\n",
      "Chunk 9 scaled.\n",
      "Chunk 10 scaled.\n",
      "Chunk 11 scaled.\n",
      "Chunk 12 scaled.\n",
      "Chunk 13 scaled.\n",
      "Chunk 14 scaled.\n",
      "Chunk 15 scaled.\n",
      "Chunk 16 scaled.\n",
      "Chunk 17 scaled.\n",
      "Chunk 18 scaled.\n",
      "Chunk 19 scaled.\n"
     ]
    }
   ],
   "source": [
    "# scale columns of test collection\n",
    "for i, chunk in enumerate(chunks_test_collection):\n",
    "    chunks_test_collection[i] = pd.DataFrame(scaler.transform(chunk[model_features]))\n",
    "    chunks_test_collection[i].columns = get_transformer_feature_names(scaler) + meta_features + [label]\n",
    "    chunks_test_collection[i] = chunks_test_collection[i].infer_objects()\n",
    "    print('Chunk {} scaled.'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update data attribute of Sentences object\n",
    "deen_sens.test_collection = pd.concat([chunk for chunk in chunks_test_collection], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on logistic regression model\n",
      "Accuracy: 0.5912253\n",
      "Precision: 0.00024604126694132306\n",
      "Recall: 0.9921104536489151\n",
      "F1: 0.0004919605287255313\n",
      "Computation time evaluating boolean: 0:00:24.749746\n",
      "Finished at: 2020-05-23 23:46:26.109598\n",
      "---- INFO: Start computing the MAP\n",
      "---- INFO: Probabilities predicted\n",
      "---- INFO: Dataframe with evaluation ranking created\n",
      "---- INFO: Probabilities sorted for each query\n",
      "---- INFO: Index of ranking of true translation retrieved\n",
      "MAP: 0.7857719010404002\n",
      "Computation time computing the MAP score: 0:09:12.013899\n",
      "Finished at: 2020-05-23 23:55:38.123721\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on best MLP model (averaging)\n",
    "print('Evaluation on logistic regression model')\n",
    "start = datetime.datetime.now()\n",
    "sup = sup_model.SupModel()\n",
    "sup.evaluate_boolean(mlp_model, deen_sens, mlp_features)\n",
    "print('Accuracy: {}'.format(sup.accuracy))\n",
    "print('Precision: {}'.format(sup.precision))\n",
    "print('Recall: {}'.format(sup.recall))\n",
    "print('F1: {}'.format(sup.f1))\n",
    "stop = datetime.datetime.now()\n",
    "time(start, stop, 'evaluating boolean')\n",
    "start = datetime.datetime.now()\n",
    "print('MAP: {}'.format(sup.compute_map(mlp_model, deen_sens, mlp_features)))\n",
    "stop = datetime.datetime.now()\n",
    "time(start, stop, 'computing the MAP score')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
