{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib, pickle, joblib\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ir_crosslingual.features.element_based' from '/Users/i500969/Desktop/Admin/Uni-Mannheim/02_Courses/2020_FSS/Information-Retrieval/03_Project/03_Implementation/06_Dev/ir-crosslingual/ir_crosslingual/features/element_based.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ir_crosslingual.utils import paths\n",
    "importlib.reload(paths)\n",
    "\n",
    "from ir_crosslingual.sentences import sentences\n",
    "importlib.reload(sentences)\n",
    "\n",
    "from ir_crosslingual.supervised_classification import sup_model\n",
    "importlib.reload(sup_model)\n",
    "\n",
    "from ir_crosslingual.unsupervised_classification import unsup_model\n",
    "importlib.reload(unsup_model)\n",
    "\n",
    "from ir_crosslingual.features import element_based\n",
    "importlib.reload(element_based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time(start, stop, message):\n",
    "    print(f'---- TIME {datetime.now()}: Computation time {message}: {stop - start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load documents data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- INFO: Learn projection matrix for en-de\n",
      "---- INFO: Found 13700 valid translation pairs in expert dictionary.\n",
      "---- INFO: 977 other pairs contained at least one unknown word (0 in source language, 977 in target language).\n",
      "---- INFO: Resulting subspace dimension: (13700, 300)\n",
      "---- INFO: Resulting subspace dimension: (13700, 300)\n",
      "---- DONE: Projection matrix learned from en to de\n",
      "---- INFO: Learn projection matrix for de-en\n",
      "---- INFO: Found 10604 valid translation pairs in expert dictionary.\n",
      "---- INFO: 262 other pairs contained at least one unknown word (0 in source language, 262 in target language).\n",
      "---- INFO: Resulting subspace dimension: (10604, 300)\n",
      "---- INFO: Resulting subspace dimension: (10604, 300)\n",
      "---- DONE: Projection matrix learned from de to en\n",
      "---- INFO: Files loaded containing training data\n",
      "---- INFO: Files loaded containing test collection\n",
      "---- DONE: All chunks loaded\n"
     ]
    }
   ],
   "source": [
    "sens, train_chunks, test_chunks = sentences.Sentences.load_chunks_from_file(docs=True, train=[13,40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens.train_data = pd.concat(train_chunks)\n",
    "sens.test_collection = pd.concat(test_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unsupervised evaluation on documents data\n",
      "------------------------------------------------------------\n",
      "---- INFO: Start computing the MAP\n",
      "---- INFO: Probabilities predicted\n",
      "---- INFO: Dataframe with evaluation ranking created\n",
      "---- INFO: Probabilities sorted for each query\n",
      "---- INFO: Index of ranking of true translation retrieved\n",
      "---- DONE: MAP Score = 0.2941381472817646\n",
      "---- TIME 2020-05-24 18:24:52.612839: Computation time computing the MAP score: 0:10:26.706793\n"
     ]
    }
   ],
   "source": [
    "model = unsup_model.UnsupModel()\n",
    "sup = sup_model.SupModel()\n",
    "start = datetime.now()\n",
    "print('Unsupervised evaluation on documents data')\n",
    "print('-' * 60)\n",
    "print('---- DONE: MAP Score = {}'.format(sup.compute_map(model, sens, ['src_embedding_aligned', 'trg_embedding', 'cosine_similarity'])))\n",
    "time(start, datetime.now(), 'computing the MAP score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Pre-trained model from sentence level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load pre-trained model from sentence level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model, mlp_prepared_features, mlp_features_dict = sup_model.SupModel.load_model(name='mlp_avg_best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_features = ['norm_diff_num_words', 'euclidean_distance', 'abs_diff_occ_exclamation_mark_0',\n",
    " 'abs_diff_occ_question_mark_2', 'abs_diff_occ_question_mark_0', 'cosine_similarity', 'norm_diff_translated_words',\n",
    " 'abs_diff_occ_exclamation_mark_1', 'abs_diff_occ_question_mark_1', 'abs_diff_num_words',\n",
    " 'abs_diff_occ_exclamation_mark_2', 'abs_diff_num_punctuation', 'src_embedding_pca_0', 'src_embedding_pca_1',\n",
    " 'src_embedding_pca_2', 'src_embedding_pca_3', 'src_embedding_pca_4', 'src_embedding_pca_5', 'src_embedding_pca_6',\n",
    " 'src_embedding_pca_7', 'src_embedding_pca_8', 'src_embedding_pca_9', 'trg_embedding_pca_0', 'trg_embedding_pca_1',\n",
    " 'trg_embedding_pca_2', 'trg_embedding_pca_3', 'trg_embedding_pca_4', 'trg_embedding_pca_5', 'trg_embedding_pca_6',\n",
    " 'trg_embedding_pca_7', 'trg_embedding_pca_8', 'trg_embedding_pca_9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define features\n",
    "model_features = ['src_sentence', 'trg_sentence', 'translation',\n",
    "                  'norm_diff_translated_words', 'abs_diff_num_words', 'abs_diff_num_punctuation',\n",
    "                  'abs_diff_occ_question_mark', 'abs_diff_occ_exclamation_mark',\n",
    "                  'rel_diff_num_words', 'rel_diff_num_punctuation', 'norm_diff_num_words',\n",
    "                  'norm_diff_num_punctuation', 'euclidean_distance', 'cosine_similarity'] \\\n",
    "                 + ['src_embedding_pca_{}'.format(i) for i in range(10)] \\\n",
    "                 + ['trg_embedding_pca_{}'.format(i) for i in range(10)]\n",
    "meta_features = ['src_sentence', 'trg_sentence']\n",
    "label = 'translation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = {}\n",
    "mean_scaler = {}\n",
    "scaler = joblib.load(open('../main/models/scaler/ct.pkl', 'rb'))\n",
    "for prefix in ['src', 'trg']:\n",
    "    mean_scaler['{}'.format(prefix)] = joblib.load(open('../main/models/mean_scaler/mean_scaler_{}.pkl'.format(prefix),\n",
    "                                                        'rb'))\n",
    "    pca['{}'.format(prefix)] = joblib.load(open('../main/models/pca/pca_{}.pkl'.format(prefix), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function that get feature names of transformed columns\n",
    "def get_transformer_feature_names(columnTransformer):\n",
    "\n",
    "    output_features = []\n",
    "\n",
    "    for name, pipe, features in columnTransformer.transformers_:\n",
    "        if name!='remainder':\n",
    "            for i in pipe:\n",
    "                trans_features = []\n",
    "                if hasattr(i,'categories_'):\n",
    "                    trans_features.extend(i.get_feature_names(features))\n",
    "                else:\n",
    "                    trans_features = features\n",
    "            output_features.extend(trans_features)\n",
    "\n",
    "    return output_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- INFO: Unique queries extracted\n",
      "---- INFO: Unique documents extracted\n",
      "---- INFO: src_embedding_pca elements extracted for unique queries.\n",
      "---- INFO: Unique queries merged to test collection\n",
      "---- INFO: trg_embedding_pca elements extracted for unique documents.\n",
      "---- INFO: Unique documents merged to test collection\n",
      "---- DONE: Extracted all vector elements and merged to test collection\n"
     ]
    }
   ],
   "source": [
    "sens = element_based.vec2features(sens, pca, mean_scaler, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train best model from sentence level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide test collection into chunks which allows for faster operations on test collection\n",
    "n = 250000  #chunk row size\n",
    "chunks_test_collection = [sens.test_collection[i:i+n] for i in range(0, sens.test_collection.shape[0], n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scale columns of test collection\n",
    "for i, chunk in enumerate(chunks_test_collection):\n",
    "    chunks_test_collection[i] = pd.DataFrame(scaler.transform(chunk[model_features]))\n",
    "    chunks_test_collection[i].columns = get_transformer_feature_names(scaler) + meta_features + [label]\n",
    "    chunks_test_collection[i] = chunks_test_collection[i].infer_objects()\n",
    "    print('Chunk {} scaled.'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update data attribute of Sentences object\n",
    "sens.test_collection = pd.concat(chunks_test_collection, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervised evaluation on documents data using pre-trained model from sentence level\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy: 0.9823317331733173\n",
      "Precision: 0.0009432193325870916\n",
      "Recall: 0.16533864541832669\n",
      "F1: 0.0018757380068588733\n",
      "---- TIME 2020-05-24 18:50:16.218380: Computation time evaluating boolean: 0:00:33.296554\n",
      "---- INFO: Start computing the MAP\n",
      "---- INFO: Probabilities predicted\n",
      "---- INFO: Dataframe with evaluation ranking created\n",
      "---- INFO: Probabilities sorted for each query\n",
      "---- INFO: Index of ranking of true translation retrieved\n",
      "MAP: 0.01217209786811421\n",
      "---- TIME 2020-05-24 18:58:54.565830: Computation time computing the MAP score: 0:08:38.346174\n"
     ]
    }
   ],
   "source": [
    "print('Supervised evaluation on documents data using pre-trained model from sentence level')\n",
    "print('-' * 80)\n",
    "start = datetime.now()\n",
    "sup = sup_model.SupModel()\n",
    "sup.evaluate_boolean(mlp_model, sens, mlp_features)\n",
    "print('Accuracy: {}'.format(sup.accuracy))\n",
    "print('Precision: {}'.format(sup.precision))\n",
    "print('Recall: {}'.format(sup.recall))\n",
    "print('F1: {}'.format(sup.f1))\n",
    "time(start, datetime.now(), 'evaluating boolean')\n",
    "start = datetime.now()\n",
    "print('MAP: {}'.format(sup.compute_map(mlp_model, sens, mlp_features)))\n",
    "time(start, datetime.now(), 'computing the MAP score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Explicitely trained model on document level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- INFO: Learn projection matrix for en-de\n",
      "---- INFO: Found 13700 valid translation pairs in expert dictionary.\n",
      "---- INFO: 977 other pairs contained at least one unknown word (0 in source language, 977 in target language).\n",
      "---- INFO: Resulting subspace dimension: (13700, 300)\n",
      "---- INFO: Resulting subspace dimension: (13700, 300)\n",
      "---- DONE: Projection matrix learned from en to de\n",
      "---- INFO: Learn projection matrix for de-en\n",
      "---- INFO: Found 10604 valid translation pairs in expert dictionary.\n",
      "---- INFO: 262 other pairs contained at least one unknown word (0 in source language, 262 in target language).\n",
      "---- INFO: Resulting subspace dimension: (10604, 300)\n",
      "---- INFO: Resulting subspace dimension: (10604, 300)\n",
      "---- DONE: Projection matrix learned from de to en\n",
      "---- INFO: Files loaded containing training data\n",
      "---- INFO: Files loaded containing test collection\n",
      "---- DONE: All chunks loaded\n"
     ]
    }
   ],
   "source": [
    "sens, train_chunks, test_chunks = sentences.Sentences.load_chunks_from_file(docs=True, train=[13,40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens.train_data = pd.concat(train_chunks, ignore_index=True)\n",
    "sens.test_collection = pd.concat(test_chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduce embedding dimensionality and extract elements as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_scaler = {}\n",
    "for prefix in ['src', 'trg']:\n",
    "    mean_scaler['{}'.format(prefix)] = StandardScaler(with_std=False)\n",
    "    X = np.vstack(sens.train_data['{}_embedding'.format(prefix)])\n",
    "    mean_scaler['{}'.format(prefix)].fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = {}\n",
    "for prefix in ['src', 'trg']:\n",
    "    pca['{}'.format(prefix)] = PCA(n_components=10, random_state=42)\n",
    "    X = np.vstack(sens.train_data['{}_embedding'.format(prefix)])\n",
    "    X = mean_scaler['{}'.format(prefix)].transform(X)\n",
    "    pca['{}'.format(prefix)].fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- INFO: Unique queries extracted\n",
      "---- INFO: Unique documents extracted\n",
      "---- INFO: Started extraction for src language.\n",
      "---- INFO: src_embedding_pca elements extracted for train data.\n",
      "---- INFO: src_embedding_pca elements extracted for unique queries.\n",
      "---- INFO: Unique queries merged to test collection\n",
      "---- INFO: Started extraction for trg language.\n",
      "---- INFO: trg_embedding_pca elements extracted for train data.\n",
      "---- INFO: trg_embedding_pca elements extracted for unique documents.\n",
      "---- INFO: Unique documents merged to test collection\n",
      "---- DONE: Extracted all vector elements and merged to test collection\n"
     ]
    }
   ],
   "source": [
    "sens = element_based.vec2features(sens, pca, mean_scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale features (z-scores for numerical, OneHotEncoding for categorical variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define features\n",
    "model_features = ['src_sentence', 'trg_sentence', 'translation',\n",
    "                  'norm_diff_translated_words', 'abs_diff_num_words', 'abs_diff_num_punctuation',\n",
    "                  'abs_diff_occ_question_mark', 'abs_diff_occ_exclamation_mark',\n",
    "                  'rel_diff_num_words', 'rel_diff_num_punctuation', 'norm_diff_num_words',\n",
    "                  'norm_diff_num_punctuation', 'euclidean_distance', 'cosine_similarity'] \\\n",
    "                 + ['src_embedding_pca_{}'.format(i) for i in range(10)] \\\n",
    "                 + ['trg_embedding_pca_{}'.format(i) for i in range(10)]\n",
    "num_features = ['norm_diff_translated_words', 'abs_diff_num_words', 'abs_diff_num_punctuation',\n",
    "                'rel_diff_num_words', 'rel_diff_num_punctuation', 'norm_diff_num_words',\n",
    "                'norm_diff_num_punctuation', 'euclidean_distance', 'cosine_similarity'] \\\n",
    "                 + ['src_embedding_pca_{}'.format(i) for i in range(10)] \\\n",
    "                 + ['trg_embedding_pca_{}'.format(i) for i in range(10)]\n",
    "\n",
    "cat_features = ['abs_diff_occ_question_mark', 'abs_diff_occ_exclamation_mark']\n",
    "meta_features = ['src_sentence', 'trg_sentence']\n",
    "label = 'translation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fit scaler on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column transformer / scaler\n",
    "numeric_pipeline = make_pipeline(StandardScaler())\n",
    "cat_pipeline     = make_pipeline(OneHotEncoder())\n",
    "\n",
    "transformers = [\n",
    "('num', numeric_pipeline, num_features),\n",
    "('cat', cat_pipeline, cat_features)\n",
    "]\n",
    "\n",
    "ct = ColumnTransformer(transformers, remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function that get feature names of transformed columns\n",
    "def get_transformer_feature_names(columnTransformer):\n",
    "\n",
    "    output_features = []\n",
    "\n",
    "    for name, pipe, features in columnTransformer.transformers_:\n",
    "        if name!='remainder':\n",
    "            for i in pipe:\n",
    "                trans_features = []\n",
    "                if hasattr(i,'categories_'):\n",
    "                    trans_features.extend(i.get_feature_names(features))\n",
    "                else:\n",
    "                    trans_features = features\n",
    "            output_features.extend(trans_features)\n",
    "\n",
    "    return output_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted.\n"
     ]
    }
   ],
   "source": [
    "# fit scaler on training data and scale training columns\n",
    "ct.fit(sens.train_data[model_features])\n",
    "print('Fitted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data scaled.\n"
     ]
    }
   ],
   "source": [
    "sens.train_data = pd.DataFrame(ct.transform(sens.train_data[model_features]))\n",
    "sens.train_data.columns = get_transformer_feature_names(ct) + meta_features + [label]\n",
    "sens.train_data = sens.train_data.infer_objects()\n",
    "print('Train data scaled.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide test collection into chunks which allows for faster operations on test collection\n",
    "n = 250000  #chunk row size\n",
    "chunks_test_collection = [sens.test_collection[i:i+n] for i in range(0, sens.test_collection.shape[0], n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scale columns of test collection\n",
    "for i, chunk in enumerate(chunks_test_collection):\n",
    "    chunks_test_collection[i] = pd.DataFrame(ct.transform(chunk[model_features]))\n",
    "    chunks_test_collection[i].columns = get_transformer_feature_names(ct) + meta_features + [label]\n",
    "    chunks_test_collection[i] = chunks_test_collection[i].infer_objects()\n",
    "    print('Chunk {} scaled.'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update data attribute of Sentences object\n",
    "sens.test_collection = pd.concat([chunk for chunk in chunks_test_collection], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model from sentence level\n",
    "documents_mlp = MLPClassifier(activation='tanh', alpha=0.1, batch_size=2000, beta_1=0.9,\n",
    "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "              hidden_layer_sizes=(9,), learning_rate='adaptive',\n",
    "              learning_rate_init=0.001, max_fun=15000, max_iter=1200,\n",
    "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
    "              power_t=0.5, random_state=42, shuffle=True, solver='lbfgs',\n",
    "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
    "              warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit on training data\n",
    "start = datetime.now()\n",
    "documents_mlp.fit(sens.train_data[mlp_features], sens.train_data[label])\n",
    "time(start, datetime.now(), 'fitting the multilayer percptron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervised evaluation on documents data using best sentence level model trained on document data\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy: 0.7192008200820083\n",
      "Precision: 0.00022863321143123323\n",
      "Recall: 0.6394422310756972\n",
      "F1: 0.0004571029852313728\n",
      "---- TIME 2020-05-24 20:04:58.623353: Computation time evaluating boolean: 0:00:27.926235\n",
      "---- INFO: Start computing the MAP\n",
      "---- INFO: Probabilities predicted\n",
      "---- INFO: Dataframe with evaluation ranking created\n",
      "---- INFO: Probabilities sorted for each query\n",
      "---- INFO: Index of ranking of true translation retrieved\n",
      "MAP: 0.0011508661640863384\n",
      "---- TIME 2020-05-24 20:14:42.849330: Computation time computing the MAP score: 0:09:44.225033\n"
     ]
    }
   ],
   "source": [
    "print('Supervised evaluation on documents data using best sentence level model trained on document data')\n",
    "print('-' * 80)\n",
    "start = datetime.now()\n",
    "sup = sup_model.SupModel()\n",
    "sup.evaluate_boolean(documents_mlp, sens, mlp_features)\n",
    "print('Accuracy: {}'.format(sup.accuracy))\n",
    "print('Precision: {}'.format(sup.precision))\n",
    "print('Recall: {}'.format(sup.recall))\n",
    "print('F1: {}'.format(sup.f1))\n",
    "time(start, datetime.now(), 'evaluating boolean')\n",
    "start = datetime.now()\n",
    "print('MAP: {}'.format(sup.compute_map(documents_mlp, sens, mlp_features)))\n",
    "time(start, datetime.now(), 'computing the MAP score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Train sentence level data on reasonable document features and evaluate document data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- INFO: Learn projection matrix for en-de\n",
      "---- INFO: Found 13700 valid translation pairs in expert dictionary.\n",
      "---- INFO: 977 other pairs contained at least one unknown word (0 in source language, 977 in target language).\n",
      "---- INFO: Resulting subspace dimension: (13700, 300)\n",
      "---- INFO: Resulting subspace dimension: (13700, 300)\n",
      "---- DONE: Projection matrix learned from en to de\n",
      "---- INFO: Learn projection matrix for de-en\n",
      "---- INFO: Found 10604 valid translation pairs in expert dictionary.\n",
      "---- INFO: 262 other pairs contained at least one unknown word (0 in source language, 262 in target language).\n",
      "---- INFO: Resulting subspace dimension: (10604, 300)\n",
      "---- INFO: Resulting subspace dimension: (10604, 300)\n",
      "---- DONE: Projection matrix learned from de to en\n",
      "---- INFO: File loaded containing training data\n",
      "---- INFO: File loaded containing test collection\n",
      "---- DONE: All files loaded and features extracted\n"
     ]
    }
   ],
   "source": [
    "train_file = f'{paths.data_path}extracted_data/global/en-de/training_data_avg.pkl'\n",
    "test_file = f'{paths.data_path}extracted_data/global/en-de/test_collection_avg.pkl'\n",
    "sens_level, train_data_sens, test_collection_sens, features_sens = sentences.Sentences.load_from_file(train_file, test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens_level.test_collection = pd.concat(test_chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce embedding dimensionality and extract elements as features\n",
    "mean_scaler = {}\n",
    "for prefix in ['src', 'trg']:\n",
    "    mean_scaler['{}'.format(prefix)] = StandardScaler(with_std=False)\n",
    "    X = np.vstack(sens_level.train_data['{}_embedding'.format(prefix)])\n",
    "    mean_scaler['{}'.format(prefix)].fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = {}\n",
    "for prefix in ['src', 'trg']:\n",
    "    pca['{}'.format(prefix)] = PCA(n_components=10, random_state=42)\n",
    "    X = np.vstack(sens_level.train_data['{}_embedding'.format(prefix)])\n",
    "    X = mean_scaler['{}'.format(prefix)].transform(X)\n",
    "    pca['{}'.format(prefix)].fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- INFO: Unique queries extracted\n",
      "---- INFO: Unique documents extracted\n",
      "---- INFO: Started extraction for src language.\n",
      "---- INFO: src_embedding_pca elements extracted for train data.\n",
      "---- INFO: src_embedding_pca elements extracted for unique queries.\n",
      "---- INFO: Unique queries merged to test collection\n",
      "---- INFO: Started extraction for trg language.\n",
      "---- INFO: trg_embedding_pca elements extracted for train data.\n",
      "---- INFO: trg_embedding_pca elements extracted for unique documents.\n",
      "---- INFO: Unique documents merged to test collection\n",
      "---- DONE: Extracted all vector elements and merged to test collection\n"
     ]
    }
   ],
   "source": [
    "sens_level = element_based.vec2features(sens_level, pca, mean_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column transformer / scaler\n",
    "numeric_pipeline = make_pipeline(StandardScaler())\n",
    "cat_pipeline     = make_pipeline(OneHotEncoder())\n",
    "\n",
    "transformers = [\n",
    "('num', numeric_pipeline, num_features),\n",
    "('cat', cat_pipeline, cat_features)\n",
    "]\n",
    "\n",
    "ct = ColumnTransformer(transformers, remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted.\n"
     ]
    }
   ],
   "source": [
    "# fit scaler on training data and scale training columns\n",
    "ct.fit(sens_level.train_data[model_features])\n",
    "print('Fitted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data scaled.\n"
     ]
    }
   ],
   "source": [
    "sens_level.train_data = pd.DataFrame(ct.transform(sens_level.train_data[model_features]))\n",
    "sens_level.train_data.columns = get_transformer_feature_names(ct) + meta_features + [label]\n",
    "sens_level.train_data = sens_level.train_data.infer_objects()\n",
    "print('Train data scaled.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide test collection into chunks which allows for faster operations on test collection\n",
    "n = 250000  #chunk row size\n",
    "chunks_test_collection = [sens_level.test_collection[i:i+n] for i in range(0, sens_level.test_collection.shape[0], n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scale columns of test collection\n",
    "for i, chunk in enumerate(chunks_test_collection):\n",
    "    chunks_test_collection[i] = pd.DataFrame(ct.transform(chunk[model_features]))\n",
    "    chunks_test_collection[i].columns = get_transformer_feature_names(ct) + meta_features + [label]\n",
    "    chunks_test_collection[i] = chunks_test_collection[i].infer_objects()\n",
    "    print('Chunk {} scaled.'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update data attribute of Sentences object\n",
    "sens_level.test_collection = pd.concat(chunks_test_collection, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model from sentence level\n",
    "documents_mlp = MLPClassifier(activation='tanh', alpha=0.1, batch_size=2000, beta_1=0.9,\n",
    "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "              hidden_layer_sizes=(9,), learning_rate='adaptive',\n",
    "              learning_rate_init=0.001, max_fun=15000, max_iter=1200,\n",
    "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
    "              power_t=0.5, random_state=42, shuffle=True, solver='lbfgs',\n",
    "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
    "              warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- TIME 2020-05-25 01:16:45.010695: Computation time fitting the multilayer percptron: 0:01:21.312951\n"
     ]
    }
   ],
   "source": [
    "# Fit on sentence level training data\n",
    "start = datetime.now()\n",
    "documents_mlp.fit(sens_level.train_data[documents_features], sens_level.train_data[label])\n",
    "time(start, datetime.now(), 'fitting the multilayer percptron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervised evaluation on documents data using reasonable documents features only, trained on sentence level data\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Accuracy: 0.43374157415741577\n",
      "Precision: 0.00017376004373667443\n",
      "Recall: 0.9800796812749004\n",
      "F1: 0.00034745848594964747\n",
      "---- TIME 2020-05-25 01:19:35.182085: Computation time evaluating boolean: 0:00:34.930362\n",
      "---- INFO: Start computing the MAP\n",
      "---- INFO: Probabilities predicted\n",
      "---- INFO: Dataframe with evaluation ranking created\n",
      "---- INFO: Probabilities sorted for each query\n",
      "---- INFO: Index of ranking of true translation retrieved\n",
      "MAP: 0.2384825701666099\n",
      "---- TIME 2020-05-25 01:29:07.241004: Computation time computing the MAP score: 0:09:32.057834\n"
     ]
    }
   ],
   "source": [
    "print('Supervised evaluation on documents data using reasonable documents features only, trained on sentence level data')\n",
    "print('-' * 100)\n",
    "start = datetime.now()\n",
    "sup = sup_model.SupModel()\n",
    "sup.evaluate_boolean(documents_mlp, sens_level, documents_features)\n",
    "print('Accuracy: {}'.format(sup.accuracy))\n",
    "print('Precision: {}'.format(sup.precision))\n",
    "print('Recall: {}'.format(sup.recall))\n",
    "print('F1: {}'.format(sup.f1))\n",
    "time(start, datetime.now(), 'evaluating boolean')\n",
    "start = datetime.now()\n",
    "print('MAP: {}'.format(sup.compute_map(documents_mlp, sens_level, documents_features)))\n",
    "time(start, datetime.now(), 'computing the MAP score')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
