{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import importlib, datetime\n",
    "import copy\n",
    "from sklearn.externals import joblib\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ir_crosslingual.features.element_based' from '/Users/jani/PycharmProjects/ir-crosslingual/ir_crosslingual/features/element_based.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ir_crosslingual.supervised_classification import sup_model\n",
    "importlib.reload(sup_model)\n",
    "\n",
    "from ir_crosslingual.utils import paths\n",
    "importlib.reload(paths)\n",
    "\n",
    "from ir_crosslingual.embeddings import embeddings\n",
    "importlib.reload(embeddings)\n",
    "\n",
    "from ir_crosslingual.sentences import sentences\n",
    "importlib.reload(sentences)\n",
    "\n",
    "from ir_crosslingual.features import element_based\n",
    "importlib.reload(element_based)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- INFO: Learn projection matrix for en-de\n",
      "---- INFO: Found 13700 valid translation pairs in expert dictionary.\n",
      "---- INFO: 977 other pairs contained at least one unknown word (0 in source language, 977 in target language).\n",
      "---- DONE: Seed dictionary extracted for the languages: en-de\n",
      "---- INFO: Resulting subspace dimension: (13700, 300)\n",
      "---- INFO: Resulting subspace dimension: (13700, 300)\n",
      "---- DONE: Projection matrix learned from en to de\n",
      "---- INFO: Learn projection matrix for de-en\n",
      "---- INFO: Found 10604 valid translation pairs in expert dictionary.\n",
      "---- INFO: 262 other pairs contained at least one unknown word (0 in source language, 262 in target language).\n",
      "---- DONE: Seed dictionary extracted for the languages: de-en\n",
      "---- INFO: Resulting subspace dimension: (10604, 300)\n",
      "---- INFO: Resulting subspace dimension: (10604, 300)\n",
      "---- DONE: Projection matrix learned from de to en\n",
      "---- INFO: File loaded containing training data\n"
     ]
    }
   ],
   "source": [
    "train_file_avg = f'{paths.data_path}extracted_data/global/training_data_tfidf.pkl'\n",
    "test_file_avg = f'{paths.data_path}extracted_data/global/test_collection_tfidf.pkl'\n",
    "sens_avg, train_data_avg, test_collection_avg, features_avg = sentences.Sentences.load_from_file(train_file_avg, test_file_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce embedding dimensionality and extract elements as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_scaler = {}\n",
    "for prefix in ['src', 'trg']:\n",
    "    mean_scaler['{}'.format(prefix)] = StandardScaler(with_std=False)\n",
    "    X = np.vstack(sens_avg.train_data['{}_embedding'.format(prefix)])\n",
    "    mean_scaler['{}'.format(prefix)].fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = {}\n",
    "for prefix in ['src', 'trg']:\n",
    "    pca['{}'.format(prefix)] = PCA(n_components=10, random_state=42)\n",
    "    X = np.vstack(sens_avg.train_data['{}_embedding'.format(prefix)])\n",
    "    X = mean_scaler['{}'.format(prefix)].transform(X)\n",
    "    pca['{}'.format(prefix)].fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens_avg = element_based.vec2features(sens_avg, pca, mean_scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove pairs that cointain sentences equal to '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens_avg.train_data = sens_avg.train_data[(sens_avg.train_data['src_sentence'] != '.') & (sens_avg.train_data['trg_sentence'] != '.')]\n",
    "sens_avg.test_collection = sens_avg.test_collection[(sens_avg.test_collection['src_sentence'] != '.') & (sens_avg.test_collection['trg_sentence'] != '.')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale features (z-scores for numerical, OneHotEncoding for categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define features\n",
    "model_features = ['src_sentence', 'trg_sentence', 'translation',\n",
    "                  'norm_diff_translated_words', 'abs_diff_num_words', 'abs_diff_num_punctuation',\n",
    "                  'abs_diff_occ_question_mark', 'abs_diff_occ_exclamation_mark',\n",
    "                  'rel_diff_num_words', 'rel_diff_num_punctuation', 'norm_diff_num_words',\n",
    "                  'norm_diff_num_punctuation', 'euclidean_distance', 'cosine_similarity'] \\\n",
    "                 + ['src_embedding_pca_{}'.format(i) for i in range(10)] \\\n",
    "                 + ['trg_embedding_pca_{}'.format(i) for i in range(10)]\n",
    "num_features = ['norm_diff_translated_words', 'abs_diff_num_words', 'abs_diff_num_punctuation',\n",
    "                'rel_diff_num_words', 'rel_diff_num_punctuation', 'norm_diff_num_words',\n",
    "                'norm_diff_num_punctuation', 'euclidean_distance', 'cosine_similarity'] \\\n",
    "                 + ['src_embedding_pca_{}'.format(i) for i in range(10)] \\\n",
    "                 + ['trg_embedding_pca_{}'.format(i) for i in range(10)]\n",
    "cat_features = ['abs_diff_occ_question_mark', 'abs_diff_occ_exclamation_mark']\n",
    "meta_features = ['src_sentence', 'trg_sentence']\n",
    "label = 'translation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit scaler on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column transformer / scaler\n",
    "numeric_pipeline = make_pipeline(StandardScaler())\n",
    "cat_pipeline     = make_pipeline(OneHotEncoder())\n",
    "\n",
    "transformers = [\n",
    "('num', numeric_pipeline, num_features),\n",
    "('cat', cat_pipeline, cat_features)\n",
    "]\n",
    "\n",
    "ct = ColumnTransformer(transformers, remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function that get feature names of transformed columns\n",
    "def get_transformer_feature_names(columnTransformer):\n",
    "\n",
    "    output_features = []\n",
    "\n",
    "    for name, pipe, features in columnTransformer.transformers_:\n",
    "        if name!='remainder':\n",
    "            for i in pipe:\n",
    "                trans_features = []\n",
    "                if hasattr(i,'categories_'):\n",
    "                    trans_features.extend(i.get_feature_names(features))\n",
    "                else:\n",
    "                    trans_features = features\n",
    "            output_features.extend(trans_features)\n",
    "\n",
    "    return output_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit scaler on training data and scale training columns\n",
    "ct.fit(sens_avg.train_data[model_features])\n",
    "print('Fitted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens_avg.train_data = pd.DataFrame(ct.transform(sens_avg.train_data[model_features]))\n",
    "sens_avg.train_data.columns = get_transformer_feature_names(ct) + meta_features + [label]\n",
    "sens_avg.train_data = sens_avg.train_data.infer_objects()\n",
    "print('Train data scaled.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide test collection into chunks which allows for faster operations on test collection\n",
    "n = 500000  #chunk row size\n",
    "chunks_test_collection = [sens_avg.test_collection[i:i+n] for i in range(0, sens_avg.test_collection.shape[0], n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scale columns of test collection\n",
    "for i, chunk in enumerate(chunks_test_collection):\n",
    "    chunks_test_collection[i] = pd.DataFrame(ct.transform(chunk[model_features]))\n",
    "    chunks_test_collection[i].columns = get_transformer_feature_names(ct) + meta_features + [label]\n",
    "    chunks_test_collection[i] = chunks_test_collection[i].infer_objects()\n",
    "    print('Chunk {} scaled.'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update data attribute of Sentences object\n",
    "sens_avg.test_collection = pd.concat([chunk for chunk in chunks_test_collection], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline MLP models using \"TF-IDF\" aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Use self-selected features based on intuition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_1 = 'norm_diff_translated_words norm_diff_num_punctuation abs_diff_occ_question_mark_0 abs_diff_occ_question_mark_1 abs_diff_occ_question_mark_2 abs_diff_occ_exclamation_mark_0 abs_diff_occ_exclamation_mark_1 abs_diff_occ_exclamation_mark_2 norm_diff_num_words euclidean_distance cosine_similarity'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MLPClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7b93283eca4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create baseline MLP classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmlp_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layer_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adaptive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tanh'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Fit baseline model on training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MLPClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# Create baseline MLP classifier\n",
    "mlp_1 = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(5,), random_state=1, learning_rate='adaptive', activation='tanh')\n",
    "\n",
    "# Fit baseline model on training data\n",
    "start = datetime.datetime.now()\n",
    "mlp_1.fit(sens_avg.train_data[features_1], sens_avg.train_data[label])\n",
    "stop = datetime.datetime.now()\n",
    "print('Computation time fitting the multilayer perceptron: {}'.format(stop-start))\n",
    "\n",
    "# Evaluate baseline model on test collection\n",
    "sup = sup_model.SupModel()\n",
    "sup.evaluate_boolean(mlp_1, sens_avg, features_1)\n",
    "print('Accuracy: {}'.format(sup.accuracy))\n",
    "print('Precision: {}'.format(sup.precision))\n",
    "print('Recall: {}'.format(sup.recall))\n",
    "print('F1: {}'.format(sup.f1))\n",
    "\n",
    "print('MAP: {}'.format(sup.compute_map(mlp_1, sens_avg, features_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Use features selected through RFECV (see logistic_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_2 = list(set(features_1 + ['abs_diff_num_words', 'abs_diff_num_punctuation']) - set(['norm_diff_num_punctuation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time fitting the multilayer perceptron: 0:00:14.572112\n",
      "Accuracy: 0.9797467467467468\n",
      "Precision: 0.004810932327202428\n",
      "Recall: 0.978978978978979\n",
      "F1: 0.009574811783480021\n",
      "---- INFO: Start computing the MAP\n",
      "---- INFO: Probabilities predicted\n",
      "---- INFO: Dataframe with evaluation ranking created\n",
      "---- INFO: Probabilities sorted for each query\n",
      "---- INFO: Index of ranking of true translation retrieved\n",
      "MAP: 0.8124413906367084\n"
     ]
    }
   ],
   "source": [
    "# Create baseline MLP classifier\n",
    "mlp_2 = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(5,), random_state=1, learning_rate='adaptive', activation='tanh')\n",
    "\n",
    "# Fit baseline model on training data\n",
    "start = datetime.datetime.now()\n",
    "mlp_2.fit(sens_avg.train_data[features_2], sens_avg.train_data[label])\n",
    "stop = datetime.datetime.now()\n",
    "print('Computation time fitting the multilayer perceptron: {}'.format(stop-start))\n",
    "\n",
    "# Evaluate baseline model on test collection\n",
    "sup = sup_model.SupModel()\n",
    "sup.evaluate_boolean(mlp_2, sens_avg, features_2)\n",
    "print('Accuracy: {}'.format(sup.accuracy))\n",
    "print('Precision: {}'.format(sup.precision))\n",
    "print('Recall: {}'.format(sup.recall))\n",
    "print('F1: {}'.format(sup.f1))\n",
    "\n",
    "print('MAP: {}'.format(sup.compute_map(mlp_2, sens_avg, features_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Use correlation-based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_corr = 'norm_diff_translated_words abs_diff_num_punctuation abs_diff_occ_question_mark_0 abs_diff_occ_question_mark_1 abs_diff_occ_question_mark_2 abs_diff_occ_exclamation_mark_0 abs_diff_occ_exclamation_mark_1 abs_diff_occ_exclamation_mark_2 abs_diff_num_words cosine_similarity'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time fitting the multilayer perceptron: 0:00:10.812997\n",
      "Accuracy: 0.975727927927928\n",
      "Precision: 0.003915606960165992\n",
      "Recall: 0.953953953953954\n",
      "F1: 0.007799201257038103\n",
      "---- INFO: Start computing the MAP\n",
      "---- INFO: Probabilities predicted\n",
      "---- INFO: Dataframe with evaluation ranking created\n",
      "---- INFO: Probabilities sorted for each query\n",
      "---- INFO: Index of ranking of true translation retrieved\n",
      "MAP: 0.8230814144009025\n"
     ]
    }
   ],
   "source": [
    "# Create baseline MLP classifier\n",
    "mlp_corr = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(5,), random_state=1, learning_rate='adaptive', activation='tanh')\n",
    "\n",
    "# Fit baseline model on training data\n",
    "start = datetime.datetime.now()\n",
    "mlp_corr.fit(sens_avg.train_data[features_corr], sens_avg.train_data[label])\n",
    "stop = datetime.datetime.now()\n",
    "print('Computation time fitting the multilayer perceptron: {}'.format(stop-start))\n",
    "\n",
    "# Evaluate baseline model on test collection\n",
    "sup = sup_model.SupModel()\n",
    "sup.evaluate_boolean(mlp_corr, sens_avg, features_corr)\n",
    "print('Accuracy: {}'.format(sup.accuracy))\n",
    "print('Precision: {}'.format(sup.precision))\n",
    "print('Recall: {}'.format(sup.recall))\n",
    "print('F1: {}'.format(sup.f1))\n",
    "\n",
    "print('MAP: {}'.format(sup.compute_map(mlp_corr, sens_avg, features_corr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Use all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_3 = features_2 + ['norm_diff_num_punctuation', 'rel_diff_num_words', 'rel_diff_num_punctuation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time fitting the multilayer perceptron: 0:00:15.807366\n",
      "Accuracy: 0.9781803803803804\n",
      "Precision: 0.0044534986228411955\n",
      "Recall: 0.975975975975976\n",
      "F1: 0.00886653813975483\n",
      "---- INFO: Start computing the MAP\n",
      "---- INFO: Probabilities predicted\n",
      "---- INFO: Dataframe with evaluation ranking created\n",
      "---- INFO: Probabilities sorted for each query\n",
      "---- INFO: Index of ranking of true translation retrieved\n",
      "MAP: 0.8340932730192272\n"
     ]
    }
   ],
   "source": [
    "# Create baseline MLP classifier\n",
    "mlp_3 = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(5,), random_state=1, learning_rate='adaptive', activation='tanh')\n",
    "\n",
    "# Fit baseline model on training data\n",
    "start = datetime.datetime.now()\n",
    "mlp_3.fit(sens_avg.train_data[features_3], sens_avg.train_data[label])\n",
    "stop = datetime.datetime.now()\n",
    "print('Computation time fitting the multilayer perceptron: {}'.format(stop-start))\n",
    "\n",
    "# Evaluate baseline model on test collection\n",
    "sup = sup_model.SupModel()\n",
    "sup.evaluate_boolean(mlp_3, sens_avg, features_3)\n",
    "print('Accuracy: {}'.format(sup.accuracy))\n",
    "print('Precision: {}'.format(sup.precision))\n",
    "print('Recall: {}'.format(sup.recall))\n",
    "print('F1: {}'.format(sup.f1))\n",
    "\n",
    "print('MAP: {}'.format(sup.compute_map(mlp_3, sens_avg, features_3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Use best of {1,2,3,4} + extracted elements of dimension reduced sentence embedding (10-dim) as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_4 = features_3 + ['src_embedding_pca_{}'.format(i) for i in range(10)] + ['trg_embedding_pca_{}'.format(i) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time fitting the multilayer perceptron: 0:00:18.585914\n",
      "Accuracy: 0.9843890890890891\n",
      "Precision: 0.006270631269038121\n",
      "Recall: 0.984984984984985\n",
      "F1: 0.012461927166114703\n",
      "---- INFO: Start computing the MAP\n",
      "---- INFO: Probabilities predicted\n",
      "---- INFO: Dataframe with evaluation ranking created\n",
      "---- INFO: Probabilities sorted for each query\n",
      "---- INFO: Index of ranking of true translation retrieved\n",
      "MAP: 0.8605594531873866\n"
     ]
    }
   ],
   "source": [
    "# Create baseline MLP classifier\n",
    "mlp_4 = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(8,), random_state=1, learning_rate='adaptive', activation='tanh')\n",
    "\n",
    "# Fit baseline model on training data\n",
    "start = datetime.datetime.now()\n",
    "mlp_4.fit(sens_avg.train_data[features_4], sens_avg.train_data[label])\n",
    "stop = datetime.datetime.now()\n",
    "print('Computation time fitting the multilayer perceptron: {}'.format(stop-start))\n",
    "\n",
    "# Evaluate baseline model on test collection\n",
    "sup = sup_model.SupModel()\n",
    "sup.evaluate_boolean(mlp_4, sens_avg, features_4)\n",
    "print('Accuracy: {}'.format(sup.accuracy))\n",
    "print('Precision: {}'.format(sup.precision))\n",
    "print('Recall: {}'.format(sup.recall))\n",
    "print('F1: {}'.format(sup.f1))\n",
    "\n",
    "print('MAP: {}'.format(sup.compute_map(mlp_4, sens_avg, features_4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparametertuning of best model (variant 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create random grid for tuning best model (1st run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden layers\n",
    "hidden_layers = [(4,4), (3,3,2), (8,), (2,2,2,1), (8,3,2), (7,), (9,), (4,3,2)]\n",
    "\n",
    "# Activation function\n",
    "activation = ['identity', 'logistic', 'tanh', 'relu']\n",
    "\n",
    "# Optimizer\n",
    "optimizer = ['lbfgs', 'sgd', 'adam']\n",
    "\n",
    "# Alpha\n",
    "alpha = [0.1, 0.01, 0.001, 0.0001]\n",
    "\n",
    "# Batch size\n",
    "batch_size = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "# Learning rate\n",
    "learning_rate = ['constant', 'invscaling', 'adaptive']\n",
    "\n",
    "# Learning rate init\n",
    "learning_rate_init = [0.1, 0.01, 0.001, 0.0001]\n",
    "\n",
    "# Maximum iterations\n",
    "max_iter = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {\n",
    "    'hidden_layer_sizes': hidden_layers,\n",
    "    'activation': activation,\n",
    "    'solver': optimizer,\n",
    "    'alpha': alpha,\n",
    "    'batch_size': batch_size,\n",
    "    'learning_rate': learning_rate,\n",
    "    'learning_rate_init': learning_rate_init,\n",
    "    'max_iter': max_iter\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform random search for optimal hyperparameters (1st run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   25.8s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:   25.8s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   26.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   40.9s\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=-1)]: Done  39 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done  43 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed: 11.6min\n",
      "[Parallel(n_jobs=-1)]: Done  47 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed: 13.0min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=-1)]: Done  54 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=-1)]: Done  55 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed: 13.4min\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed: 13.4min\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed: 13.4min\n",
      "[Parallel(n_jobs=-1)]: Done  59 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=-1)]: Done  60 tasks      | elapsed: 13.7min\n",
      "[Parallel(n_jobs=-1)]: Done  61 tasks      | elapsed: 14.8min\n",
      "[Parallel(n_jobs=-1)]: Done  62 tasks      | elapsed: 18.8min\n",
      "[Parallel(n_jobs=-1)]: Done  63 tasks      | elapsed: 19.0min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 19.0min\n",
      "[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed: 19.3min\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed: 19.4min\n",
      "[Parallel(n_jobs=-1)]: Done  67 tasks      | elapsed: 19.4min\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed: 19.7min\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed: 19.7min\n",
      "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed: 20.0min\n",
      "[Parallel(n_jobs=-1)]: Done  71 tasks      | elapsed: 21.1min\n",
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed: 21.4min\n",
      "[Parallel(n_jobs=-1)]: Done  73 tasks      | elapsed: 21.5min\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed: 21.6min\n",
      "[Parallel(n_jobs=-1)]: Done  75 tasks      | elapsed: 21.6min\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed: 21.7min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed: 21.7min\n",
      "[Parallel(n_jobs=-1)]: Done  78 tasks      | elapsed: 21.7min\n",
      "[Parallel(n_jobs=-1)]: Done  79 tasks      | elapsed: 21.8min\n",
      "[Parallel(n_jobs=-1)]: Done  80 tasks      | elapsed: 22.7min\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed: 23.0min\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed: 23.1min\n",
      "[Parallel(n_jobs=-1)]: Done  83 tasks      | elapsed: 23.2min\n",
      "[Parallel(n_jobs=-1)]: Done  84 tasks      | elapsed: 23.2min\n",
      "[Parallel(n_jobs=-1)]: Done  85 tasks      | elapsed: 23.4min\n",
      "[Parallel(n_jobs=-1)]: Done  86 tasks      | elapsed: 23.5min\n",
      "[Parallel(n_jobs=-1)]: Done  87 tasks      | elapsed: 23.6min\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed: 23.6min\n",
      "[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed: 23.8min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 24.2min\n",
      "[Parallel(n_jobs=-1)]: Done  91 tasks      | elapsed: 24.6min\n",
      "[Parallel(n_jobs=-1)]: Done  92 tasks      | elapsed: 24.7min\n",
      "[Parallel(n_jobs=-1)]: Done  93 tasks      | elapsed: 24.9min\n",
      "[Parallel(n_jobs=-1)]: Done  94 tasks      | elapsed: 24.9min\n",
      "[Parallel(n_jobs=-1)]: Done  95 tasks      | elapsed: 25.1min\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed: 25.3min\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed: 25.3min\n",
      "[Parallel(n_jobs=-1)]: Done  98 tasks      | elapsed: 25.5min\n",
      "[Parallel(n_jobs=-1)]: Done  99 tasks      | elapsed: 25.6min\n",
      "[Parallel(n_jobs=-1)]: Done 100 tasks      | elapsed: 25.7min\n",
      "[Parallel(n_jobs=-1)]: Done 101 tasks      | elapsed: 25.9min\n",
      "[Parallel(n_jobs=-1)]: Done 102 tasks      | elapsed: 26.1min\n",
      "[Parallel(n_jobs=-1)]: Done 103 tasks      | elapsed: 26.2min\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed: 26.4min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed: 26.6min\n",
      "[Parallel(n_jobs=-1)]: Done 106 tasks      | elapsed: 29.1min\n",
      "[Parallel(n_jobs=-1)]: Done 107 tasks      | elapsed: 29.1min\n",
      "[Parallel(n_jobs=-1)]: Done 108 tasks      | elapsed: 29.2min\n",
      "[Parallel(n_jobs=-1)]: Done 109 tasks      | elapsed: 29.6min\n",
      "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed: 30.3min\n",
      "[Parallel(n_jobs=-1)]: Done 111 tasks      | elapsed: 30.4min\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed: 30.6min\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed: 30.8min\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed: 31.5min\n",
      "[Parallel(n_jobs=-1)]: Done 115 tasks      | elapsed: 31.5min\n",
      "[Parallel(n_jobs=-1)]: Done 116 tasks      | elapsed: 34.5min\n",
      "[Parallel(n_jobs=-1)]: Done 117 tasks      | elapsed: 34.6min\n",
      "[Parallel(n_jobs=-1)]: Done 118 tasks      | elapsed: 35.5min\n",
      "[Parallel(n_jobs=-1)]: Done 119 tasks      | elapsed: 35.5min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed: 36.2min\n",
      "[Parallel(n_jobs=-1)]: Done 121 tasks      | elapsed: 37.0min\n",
      "[Parallel(n_jobs=-1)]: Done 122 tasks      | elapsed: 37.0min\n",
      "[Parallel(n_jobs=-1)]: Done 123 tasks      | elapsed: 37.8min\n",
      "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed: 37.9min\n",
      "[Parallel(n_jobs=-1)]: Done 125 tasks      | elapsed: 38.5min\n",
      "[Parallel(n_jobs=-1)]: Done 126 tasks      | elapsed: 40.6min\n",
      "[Parallel(n_jobs=-1)]: Done 127 tasks      | elapsed: 42.2min\n",
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed: 43.1min\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed: 43.8min\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed: 43.8min\n",
      "[Parallel(n_jobs=-1)]: Done 131 tasks      | elapsed: 43.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed: 44.4min\n",
      "[Parallel(n_jobs=-1)]: Done 133 tasks      | elapsed: 44.6min\n",
      "[Parallel(n_jobs=-1)]: Done 134 tasks      | elapsed: 44.6min\n",
      "[Parallel(n_jobs=-1)]: Done 135 tasks      | elapsed: 44.7min\n",
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed: 44.7min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed: 44.8min\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed: 44.8min\n",
      "[Parallel(n_jobs=-1)]: Done 139 tasks      | elapsed: 44.9min\n",
      "[Parallel(n_jobs=-1)]: Done 140 tasks      | elapsed: 44.9min\n",
      "[Parallel(n_jobs=-1)]: Done 141 tasks      | elapsed: 45.6min\n",
      "[Parallel(n_jobs=-1)]: Done 142 tasks      | elapsed: 45.6min\n",
      "[Parallel(n_jobs=-1)]: Done 143 tasks      | elapsed: 45.6min\n",
      "[Parallel(n_jobs=-1)]: Done 144 tasks      | elapsed: 45.6min\n",
      "[Parallel(n_jobs=-1)]: Done 145 tasks      | elapsed: 46.3min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 47.1min\n",
      "[Parallel(n_jobs=-1)]: Done 147 tasks      | elapsed: 47.2min\n",
      "[Parallel(n_jobs=-1)]: Done 148 tasks      | elapsed: 47.6min\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed: 47.7min\n",
      "[Parallel(n_jobs=-1)]: Done 150 tasks      | elapsed: 48.1min\n",
      "[Parallel(n_jobs=-1)]: Done 151 tasks      | elapsed: 50.6min\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed: 50.9min\n",
      "[Parallel(n_jobs=-1)]: Done 153 tasks      | elapsed: 51.0min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 51.2min\n",
      "[Parallel(n_jobs=-1)]: Done 155 tasks      | elapsed: 51.3min\n",
      "[Parallel(n_jobs=-1)]: Done 156 tasks      | elapsed: 51.3min\n",
      "[Parallel(n_jobs=-1)]: Done 157 tasks      | elapsed: 51.6min\n",
      "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed: 51.7min\n",
      "[Parallel(n_jobs=-1)]: Done 159 tasks      | elapsed: 51.8min\n",
      "[Parallel(n_jobs=-1)]: Done 160 tasks      | elapsed: 53.6min\n",
      "[Parallel(n_jobs=-1)]: Done 161 tasks      | elapsed: 54.7min\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed: 54.8min\n",
      "[Parallel(n_jobs=-1)]: Done 163 tasks      | elapsed: 54.9min\n",
      "[Parallel(n_jobs=-1)]: Done 164 tasks      | elapsed: 57.0min\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed: 58.3min\n",
      "[Parallel(n_jobs=-1)]: Done 166 tasks      | elapsed: 58.9min\n",
      "[Parallel(n_jobs=-1)]: Done 167 tasks      | elapsed: 59.0min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed: 59.9min\n",
      "[Parallel(n_jobs=-1)]: Done 169 tasks      | elapsed: 60.4min\n",
      "[Parallel(n_jobs=-1)]: Done 170 tasks      | elapsed: 60.6min\n",
      "[Parallel(n_jobs=-1)]: Done 171 tasks      | elapsed: 61.0min\n",
      "[Parallel(n_jobs=-1)]: Done 172 tasks      | elapsed: 61.4min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed: 61.5min\n",
      "[Parallel(n_jobs=-1)]: Done 174 tasks      | elapsed: 61.6min\n",
      "[Parallel(n_jobs=-1)]: Done 175 tasks      | elapsed: 61.7min\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed: 61.8min\n",
      "[Parallel(n_jobs=-1)]: Done 177 tasks      | elapsed: 61.9min\n",
      "[Parallel(n_jobs=-1)]: Done 178 tasks      | elapsed: 61.9min\n",
      "[Parallel(n_jobs=-1)]: Done 179 tasks      | elapsed: 62.0min\n",
      "[Parallel(n_jobs=-1)]: Done 180 tasks      | elapsed: 62.3min\n",
      "[Parallel(n_jobs=-1)]: Done 181 tasks      | elapsed: 62.3min\n",
      "[Parallel(n_jobs=-1)]: Done 182 tasks      | elapsed: 62.4min\n",
      "[Parallel(n_jobs=-1)]: Done 183 tasks      | elapsed: 62.4min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 62.4min\n",
      "[Parallel(n_jobs=-1)]: Done 185 tasks      | elapsed: 62.4min\n",
      "[Parallel(n_jobs=-1)]: Done 186 tasks      | elapsed: 62.4min\n",
      "[Parallel(n_jobs=-1)]: Done 187 tasks      | elapsed: 62.4min\n",
      "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed: 62.4min\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed: 62.7min\n",
      "[Parallel(n_jobs=-1)]: Done 190 tasks      | elapsed: 62.7min\n",
      "[Parallel(n_jobs=-1)]: Done 191 tasks      | elapsed: 62.7min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 62.9min\n",
      "[Parallel(n_jobs=-1)]: Done 193 tasks      | elapsed: 63.0min\n",
      "[Parallel(n_jobs=-1)]: Done 194 tasks      | elapsed: 63.0min\n",
      "[Parallel(n_jobs=-1)]: Done 195 tasks      | elapsed: 63.0min\n",
      "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed: 63.2min\n",
      "[Parallel(n_jobs=-1)]: Done 197 tasks      | elapsed: 63.3min\n",
      "[Parallel(n_jobs=-1)]: Done 198 tasks      | elapsed: 63.3min\n",
      "[Parallel(n_jobs=-1)]: Done 199 tasks      | elapsed: 63.3min\n",
      "[Parallel(n_jobs=-1)]: Done 200 tasks      | elapsed: 63.6min\n",
      "[Parallel(n_jobs=-1)]: Done 201 tasks      | elapsed: 63.8min\n",
      "[Parallel(n_jobs=-1)]: Done 202 tasks      | elapsed: 63.8min\n",
      "[Parallel(n_jobs=-1)]: Done 203 tasks      | elapsed: 63.8min\n",
      "[Parallel(n_jobs=-1)]: Done 204 tasks      | elapsed: 64.1min\n",
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed: 64.4min\n",
      "[Parallel(n_jobs=-1)]: Done 206 tasks      | elapsed: 66.5min\n",
      "[Parallel(n_jobs=-1)]: Done 207 tasks      | elapsed: 67.4min\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed: 67.7min\n",
      "[Parallel(n_jobs=-1)]: Done 209 tasks      | elapsed: 67.9min\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed: 68.1min\n",
      "[Parallel(n_jobs=-1)]: Done 211 tasks      | elapsed: 68.3min\n",
      "[Parallel(n_jobs=-1)]: Done 212 tasks      | elapsed: 68.6min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed: 68.6min\n",
      "[Parallel(n_jobs=-1)]: Done 214 tasks      | elapsed: 68.7min\n",
      "[Parallel(n_jobs=-1)]: Done 215 tasks      | elapsed: 68.7min\n",
      "[Parallel(n_jobs=-1)]: Done 216 tasks      | elapsed: 68.8min\n",
      "[Parallel(n_jobs=-1)]: Done 217 tasks      | elapsed: 68.9min\n",
      "[Parallel(n_jobs=-1)]: Done 218 tasks      | elapsed: 68.9min\n",
      "[Parallel(n_jobs=-1)]: Done 219 tasks      | elapsed: 69.0min\n",
      "[Parallel(n_jobs=-1)]: Done 220 tasks      | elapsed: 69.8min\n",
      "[Parallel(n_jobs=-1)]: Done 221 tasks      | elapsed: 70.9min\n",
      "[Parallel(n_jobs=-1)]: Done 222 tasks      | elapsed: 72.5min\n",
      "[Parallel(n_jobs=-1)]: Done 223 tasks      | elapsed: 72.7min\n",
      "[Parallel(n_jobs=-1)]: Done 224 tasks      | elapsed: 72.9min\n",
      "[Parallel(n_jobs=-1)]: Done 225 tasks      | elapsed: 73.0min\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed: 73.1min\n",
      "[Parallel(n_jobs=-1)]: Done 227 tasks      | elapsed: 73.2min\n",
      "[Parallel(n_jobs=-1)]: Done 228 tasks      | elapsed: 73.3min\n",
      "[Parallel(n_jobs=-1)]: Done 229 tasks      | elapsed: 73.3min\n",
      "[Parallel(n_jobs=-1)]: Done 230 tasks      | elapsed: 73.4min\n",
      "[Parallel(n_jobs=-1)]: Done 231 tasks      | elapsed: 73.4min\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed: 73.5min\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed: 73.5min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed: 74.2min\n",
      "[Parallel(n_jobs=-1)]: Done 235 tasks      | elapsed: 74.7min\n",
      "[Parallel(n_jobs=-1)]: Done 236 tasks      | elapsed: 74.7min\n",
      "[Parallel(n_jobs=-1)]: Done 237 tasks      | elapsed: 75.4min\n",
      "[Parallel(n_jobs=-1)]: Done 238 tasks      | elapsed: 75.9min\n",
      "[Parallel(n_jobs=-1)]: Done 239 tasks      | elapsed: 75.9min\n",
      "[Parallel(n_jobs=-1)]: Done 240 tasks      | elapsed: 76.2min\n",
      "[Parallel(n_jobs=-1)]: Done 241 tasks      | elapsed: 76.7min\n",
      "[Parallel(n_jobs=-1)]: Done 242 tasks      | elapsed: 76.7min\n",
      "[Parallel(n_jobs=-1)]: Done 243 tasks      | elapsed: 76.9min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed: 78.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=False),\n",
       "                   error_score=nan,\n",
       "                   estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
       "                                           batch_size='auto', beta_1=0.9,\n",
       "                                           beta_2=0.999, early_stopping=False,\n",
       "                                           epsilon=1e-08,\n",
       "                                           hidden_layer_sizes=(100,),\n",
       "                                           learning_rate='constant',\n",
       "                                           learning_rate_init=0.001,\n",
       "                                           max_fun=15000, max_iter=200,\n",
       "                                           momentum=0.9, n_iter...\n",
       "                                        'hidden_layer_sizes': [(4, 4),\n",
       "                                                               (3, 3, 2), (8,),\n",
       "                                                               (2, 2, 2, 1),\n",
       "                                                               (8, 3, 2), (7,),\n",
       "                                                               (9,),\n",
       "                                                               (4, 3, 2)],\n",
       "                                        'learning_rate': ['constant',\n",
       "                                                          'invscaling',\n",
       "                                                          'adaptive'],\n",
       "                                        'learning_rate_init': [0.1, 0.01, 0.001,\n",
       "                                                               0.0001],\n",
       "                                        'max_iter': [200, 400, 600, 800, 1000,\n",
       "                                                     1200, 1400, 1600, 1800,\n",
       "                                                     2000],\n",
       "                                        'solver': ['lbfgs', 'sgd', 'adam']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=20)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, random_state=42)\n",
    "mlp = MLPClassifier(random_state=42)\n",
    "randomized_search = RandomizedSearchCV(estimator = mlp, param_distributions = parameter_grid, n_iter = 50, \n",
    "                                       cv = cv, verbose=20, random_state=42, n_jobs = -1)\n",
    "randomized_search.fit(sens_avg.train_data[features_4], sens_avg.train_data[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate random search to identify optimal hyperparameters and resulting MAP (1st run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'solver': 'lbfgs',\n",
       " 'max_iter': 800,\n",
       " 'learning_rate_init': 0.001,\n",
       " 'learning_rate': 'invscaling',\n",
       " 'hidden_layer_sizes': (8, 3, 2),\n",
       " 'batch_size': 800,\n",
       " 'alpha': 0.0001,\n",
       " 'activation': 'tanh'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify best hyperparameters retrieved by random search\n",
    "randomized_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9746584248534678"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify best hyperparameters retrieved by random search\n",
    "randomized_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit best model on training data\n",
    "best_model = randomized_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time fitting the multilayer perceptron: 0:01:59.143913\n",
      "Accuracy: 0.9841304304304305\n",
      "Precision: 0.006181430631308382\n",
      "Recall: 0.986986986986987\n",
      "F1: 0.012285915431533435\n",
      "---- INFO: Start computing the MAP\n",
      "---- INFO: Probabilities predicted\n",
      "---- INFO: Dataframe with evaluation ranking created\n",
      "---- INFO: Probabilities sorted for each query\n",
      "---- INFO: Index of ranking of true translation retrieved\n",
      "MAP: 0.8720985970673748\n"
     ]
    }
   ],
   "source": [
    "# Evaluate best model on test collection\n",
    "start = datetime.datetime.now()\n",
    "best_model.fit(sens_avg.train_data[features_4], sens_avg.train_data[label])\n",
    "stop = datetime.datetime.now()\n",
    "print('Computation time fitting the multilayer perceptron: {}'.format(stop-start))\n",
    "\n",
    "# Evaluation on test collection\n",
    "sup = sup_model.SupModel()\n",
    "sup.evaluate_boolean(best_model, sens_avg, features_4)\n",
    "print('Accuracy: {}'.format(sup.accuracy))\n",
    "print('Precision: {}'.format(sup.precision))\n",
    "print('Recall: {}'.format(sup.recall))\n",
    "print('F1: {}'.format(sup.f1))\n",
    "\n",
    "print('MAP: {}'.format(sup.compute_map(best_model, sens_avg, features_4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create random grid for tuning best model (variant 4) (2nd run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden layers\n",
    "hidden_layers_2 = [(i,) for i in range(10, 32, 2)]\n",
    "\n",
    "# Activation function\n",
    "activation_2 = ['identity', 'logistic', 'tanh', 'relu']\n",
    "\n",
    "# Optimizer\n",
    "optimizer_2 = ['lbfgs', 'sgd', 'adam']\n",
    "\n",
    "# Alpha\n",
    "alpha_2 = [0.001, 0.005, 0.05, 0.1, 0.15, 0.2]\n",
    "\n",
    "# Batch size\n",
    "batch_size_2 = [int(x) for x in np.linspace(start = 1500, stop = 2500, num = 5)]\n",
    "\n",
    "# Learning rate\n",
    "learning_rate_2 = ['constant', 'invscaling', 'adaptive']\n",
    "\n",
    "# Learning rate init\n",
    "learning_rate_init_2 = [0.0005, 0.001, 0.0015, 0.002]\n",
    "\n",
    "# Maximum iterations\n",
    "max_iter_2 = [int(x) for x in np.linspace(start = 500, stop = 1500, num = 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid_2 = {\n",
    "    'hidden_layer_sizes': hidden_layers_2,\n",
    "    'activation': activation_2,\n",
    "    'solver': optimizer_2,\n",
    "    'alpha': alpha_2,\n",
    "    'batch_size': batch_size_2,\n",
    "    'learning_rate': learning_rate_2,\n",
    "    'learning_rate_init': learning_rate_init_2,\n",
    "    'max_iter': max_iter_2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform random search for optimal hyperparameters (2nd run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parameter_grid_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-727d22e827d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmlp_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m randomized_search_2 = RandomizedSearchCV(estimator = mlp_final, param_distributions = parameter_grid_2, n_iter = 50, \n\u001b[0m\u001b[1;32m      4\u001b[0m                                        cv = cv, verbose=20, random_state=42, n_jobs = -1)\n\u001b[1;32m      5\u001b[0m \u001b[0mrandomized_search_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msens_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures_4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msens_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'parameter_grid_2' is not defined"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, random_state=42)\n",
    "mlp_final = MLPClassifier()\n",
    "randomized_search_2 = RandomizedSearchCV(estimator = mlp_final, param_distributions = parameter_grid_2, n_iter = 50, \n",
    "                                       cv = cv, verbose=20, random_state=42, n_jobs = -1)\n",
    "randomized_search_2.fit(sens_avg.train_data[features_4], sens_avg.train_data[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate random search to identify optimal hyperparameters (2nd run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'solver': 'lbfgs',\n",
       " 'max_iter': 944,\n",
       " 'learning_rate_init': 0.005,\n",
       " 'learning_rate': 'adaptive',\n",
       " 'hidden_layer_sizes': (20,),\n",
       " 'batch_size': 644,\n",
       " 'alpha': 0.00015,\n",
       " 'activation': 'logistic'}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify best hyperparameters retrieved by random search\n",
    "randomized_search_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.975372581968033"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify best hyperparameters retrieved by random search\n",
    "randomized_search_2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit best model on training data\n",
    "best_model_2 = randomized_search_2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time fitting the multilayer perceptron: 0:01:04.480817\n",
      "Accuracy: 0.9809367367367368\n",
      "Precision: 0.0051200869369863585\n",
      "Recall: 0.980980980980981\n",
      "F1: 0.010187004293094666\n",
      "---- INFO: Probabilities predicted\n",
      "---- INFO: Dataframe with evaluation ranking created\n",
      "---- INFO: Probabilities sorted for each query\n",
      "---- INFO: Index of ranking of true translation retrieved\n",
      "MAP: 0.8493836640299568\n"
     ]
    }
   ],
   "source": [
    "# Evaluate best model on test collection\n",
    "start = datetime.datetime.now()\n",
    "best_model_2.fit(train_data_avg[features_4], train_data_avg[label])\n",
    "stop = datetime.datetime.now()\n",
    "print('Computation time fitting the multilayer perceptron: {}'.format(stop-start))\n",
    "\n",
    "# Evaluation on test collection\n",
    "sup = sup_model.SupModel()\n",
    "sup.evaluate_boolean(best_model_2, sens_avg, features_4)\n",
    "print('Accuracy: {}'.format(sup.accuracy))\n",
    "print('Precision: {}'.format(sup.precision))\n",
    "print('Recall: {}'.format(sup.recall))\n",
    "print('F1: {}'.format(sup.f1))\n",
    "\n",
    "print('MAP: {}'.format(sup.compute_map(best_model_2, sens_avg, features_4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Did not further improve w.r.t. MAP -> choose model from first random search as best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "params ={'solver': 'lbfgs',\n",
    "         'max_iter': 1200,\n",
    "         'learning_rate_init': 0.001,\n",
    "         'learning_rate': 'adaptive',\n",
    "         'hidden_layer_sizes': (9,),\n",
    "         'batch_size': 2000,\n",
    "         'alpha': 0.1,\n",
    "         'activation': 'tanh',\n",
    "         'random_state': 42}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = MLPClassifier(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.1, batch_size=2000, beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(9,), learning_rate='adaptive',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=1200,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=42, shuffle=True, solver='lbfgs',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(sens_avg.train_data[features_4], sens_avg.train_data[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time fitting the multilayer perceptron: 0:01:20.504808\n",
      "Accuracy: 0.979692992992993\n",
      "Precision: 0.004827410271002178\n",
      "Recall: 0.984984984984985\n",
      "F1: 0.009607733053433251\n",
      "---- INFO: Probabilities predicted\n",
      "---- INFO: Dataframe with evaluation ranking created\n",
      "---- INFO: Probabilities sorted for each query\n",
      "                                                    query  \\\n",
      "0       I would also like to comment on the budget for...   \n",
      "10001   I very recently became the second Vice-Chairma...   \n",
      "20002   Exactly the same is true with regard to the op...   \n",
      "30003   If we really want to make a success of the Lis...   \n",
      "40004   Investments in youth and intelligence are the ...   \n",
      "50005   I would therefore also like to make it clear t...   \n",
      "60006     This would not allow us to meet new challenges.   \n",
      "70007   Corrections must be made, and we will also pus...   \n",
      "80008   Mr President, today the European Parliament, i...   \n",
      "90009   This amount has been available to the Commissi...   \n",
      "100010  The Commission did not come up to expectations...   \n",
      "110011  The Commission did not come up to expectations...   \n",
      "120012  The Commission will not come up to expectation...   \n",
      "130013  We know that not all of the budget funds will ...   \n",
      "140014  Who is to blame when the budget, which has bee...   \n",
      "150015  Not just the Commission, but also the Member S...   \n",
      "160016  Not all Member States draft their programmes i...   \n",
      "170017  With regard to the other sections of the budge...   \n",
      "180018  The Commission neither wishes, for political r...   \n",
      "190019  Consequently, the preparation of the Union’s b...   \n",
      "200020  The Commission will put on a show of proposing...   \n",
      "210021  The Council will pretend to be satisfied with ...   \n",
      "220022  The European Parliament will make a show of st...   \n",
      "230023  Everyone, however, will know that there is mor...   \n",
      "240024  Our group takes a critical view of the cuts th...   \n",
      "250025  This means that the other priorities that Parl...   \n",
      "260026  Iraq is the new pretext for failing to fully i...   \n",
      "270027  As a result, we are fulfilling certain countri...   \n",
      "280028           This budget is a step in that direction.   \n",
      "290029  I am a new MEP, representing the June List – t...   \n",
      "\n",
      "                                         true_translation  \\\n",
      "0                          Eine Bemerkung zum Kulturetat.   \n",
      "10001   Ich bin nun seit ganz kurzer Zeit zweite stell...   \n",
      "20002   Genau so ist es mit unseren Möglichkeiten, den...   \n",
      "30003   Wenn wir denn wirklich mit der Lissabon-Strate...   \n",
      "40004   Denn in Jugend und Intelligenz zu investieren,...   \n",
      "50005   Deswegen möchte ich auch deutlich machen, dass...   \n",
      "60006   Damit können wir die neuen Herausforderungen n...   \n",
      "70007   Da muss es zu einer Korrektur kommen, und dafü...   \n",
      "80008   Herr Präsident! Heute hat das Europäische Parl...   \n",
      "90009   Diese Summe stand der Kommission zur Verfügung...   \n",
      "100010  Im Jahr 2003 hat die Kommission die Erwartunge...   \n",
      "110011  In den Jahren davor hat die Kommission die Erw...   \n",
      "120012  Auch im nächsten Jahr wird die Kommission die ...   \n",
      "130013  Wir wissen, dass auch im nächsten Jahr nicht a...   \n",
      "140014  Wer hat Schuld, wenn der vom Rat und vom Europ...   \n",
      "150015  Nicht nur die Kommission, sondern auch die Mit...   \n",
      "160016  Nicht alle Mitgliedstaaten erarbeiten ihre Pro...   \n",
      "170017  Bei den anderen Einzelplänen des Haushaltsplan...   \n",
      "180018  Entweder möchte die Kommission den Haushaltspl...   \n",
      "190019  Folglich wird die Ausarbeitung des Haushaltspl...   \n",
      "200020  Die Kommission wird eine Show aufführen und Mi...   \n",
      "210021  Der Rat wird vorgeben, mit den Einsparungen zu...   \n",
      "220022  Das Europäische Parlament wird eine Show abzie...   \n",
      "230023  Jedoch wird jeder wissen, dass eigentlich mehr...   \n",
      "240024  Unsere Fraktion steht den Einschnitten skeptis...   \n",
      "250025  Das bedeutet, dass andere, aus Sicht des Parla...   \n",
      "260026  Der Irak ist der neue Vorwand dafür, dass der ...   \n",
      "270027  Somit erfüllen wir das Ziel gewisser Länder, n...   \n",
      "280028  Dieser Haushaltsplan stellt einen Schritt in d...   \n",
      "290029  Ich gehöre zu den neuen Abgeordneten hier im P...   \n",
      "\n",
      "                                                  ranking  rank_true  \n",
      "0       [Wenn Sie das noch einmal erläutern könnten, w...         39  \n",
      "10001   [Ich bin nun seit ganz kurzer Zeit zweite stel...          1  \n",
      "20002   [Es treten durchaus Probleme wie Überkreuzbest...          2  \n",
      "30003   [Wenn wir denn wirklich mit der Lissabon-Strat...          1  \n",
      "40004   [Denn in Jugend und Intelligenz zu investieren...          1  \n",
      "50005   [Deswegen möchte ich auch deutlich machen, das...          1  \n",
      "60006   [Damit können wir die neuen Herausforderungen ...          1  \n",
      "70007   [Das haben wir mit Tampere I deutlich gemacht,...        181  \n",
      "80008   [Am 9. Mai hat das Europäische Parlament den B...          2  \n",
      "90009   [Diese Summe stand der Kommission zur Verfügun...          1  \n",
      "100010  [Auch im nächsten Jahr wird die Kommission die...          2  \n",
      "110011  [In den Jahren davor hat die Kommission die Er...          1  \n",
      "120012  [Auch im nächsten Jahr wird die Kommission die...          1  \n",
      "130013  [Wir wissen, dass auch im nächsten Jahr nicht ...          1  \n",
      "140014  [Wer hat Schuld, wenn der vom Rat und vom Euro...          1  \n",
      "150015  [Alle Mitglieder der Kommission haben zugesagt...          3  \n",
      "160016  [Nicht alle Mitgliedstaaten erarbeiten ihre Pr...          1  \n",
      "170017  [Sie haben darauf hingewiesen, dass die Kommis...         31  \n",
      "180018  [Entweder möchte die Kommission den Haushaltsp...          1  \n",
      "190019  [Folglich wird die Ausarbeitung des Haushaltsp...          1  \n",
      "200020  [Die Kommission wird eine Show aufführen und M...          1  \n",
      "210021  [Der Rat wird vorgeben, mit den Einsparungen z...          1  \n",
      "220022  [Das Europäische Parlament wird eine Show abzi...          1  \n",
      "230023  [Jedoch wird jeder wissen, dass eigentlich meh...          1  \n",
      "240024  [Unsere Fraktion steht den Einschnitten skepti...          1  \n",
      "250025  [Das bedeutet, dass andere, aus Sicht des Parl...          1  \n",
      "260026  [Der Irak ist der neue Vorwand dafür, dass der...          1  \n",
      "270027  [Somit erfüllen wir das Ziel gewisser Länder, ...          1  \n",
      "280028  [Die dritte Geldwäscherichtlinie ist ein neuer...          3  \n",
      "290029  [Ich gehöre zu den neuen Abgeordneten hier im ...          1  \n",
      "---- INFO: Index of ranking of true translation retrieved\n",
      "MAP: 0.8532606323265344\n"
     ]
    }
   ],
   "source": [
    "# Evaluate best model on test collection\n",
    "start = datetime.datetime.now()\n",
    "best_model.fit(train_data_avg[features_4], train_data_avg[label])\n",
    "stop = datetime.datetime.now()\n",
    "print('Computation time fitting the multilayer perceptron: {}'.format(stop-start))\n",
    "\n",
    "# Evaluation on test collection\n",
    "sup = sup_model.SupModel()\n",
    "sup.evaluate_boolean(best_model, sens_avg, features_4)\n",
    "print('Accuracy: {}'.format(sup.accuracy))\n",
    "print('Precision: {}'.format(sup.precision))\n",
    "print('Recall: {}'.format(sup.recall))\n",
    "print('F1: {}'.format(sup.f1))\n",
    "\n",
    "print('MAP: {}'.format(sup.compute_map(best_model, sens_avg, features_4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_model.SupModel.save_model(model=best_model, name='mlp_tfidf_best', prepared_features=sens_avg.prepared_features, features_dict=sens_avg.features_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../main/models/scaler/ct.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(ct, '../main/models/scaler/ct_tfidf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prefix in ['src', 'trg']:\n",
    "    joblib.dump(pca['{}'.format(prefix)], '../main/models/pca/pca_tfidf_{}.pkl'.format(prefix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save mean_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prefix in ['src', 'trg']:\n",
    "    joblib.dump(mean_scaler['{}'.format(prefix)], '../main/models/mean_scaler/mean_scaler_tfidf_{}.pkl'.format(prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['norm_diff_num_words',\n",
       " 'euclidean_distance',\n",
       " 'abs_diff_occ_exclamation_mark_0',\n",
       " 'abs_diff_occ_question_mark_2',\n",
       " 'abs_diff_occ_question_mark_0',\n",
       " 'cosine_similarity',\n",
       " 'norm_diff_translated_words',\n",
       " 'abs_diff_occ_exclamation_mark_1',\n",
       " 'abs_diff_occ_question_mark_1',\n",
       " 'abs_diff_num_words',\n",
       " 'abs_diff_occ_exclamation_mark_2',\n",
       " 'abs_diff_num_punctuation',\n",
       " 'src_embedding_pca_0',\n",
       " 'src_embedding_pca_1',\n",
       " 'src_embedding_pca_2',\n",
       " 'src_embedding_pca_3',\n",
       " 'src_embedding_pca_4',\n",
       " 'src_embedding_pca_5',\n",
       " 'src_embedding_pca_6',\n",
       " 'src_embedding_pca_7',\n",
       " 'src_embedding_pca_8',\n",
       " 'src_embedding_pca_9',\n",
       " 'trg_embedding_pca_0',\n",
       " 'trg_embedding_pca_1',\n",
       " 'trg_embedding_pca_2',\n",
       " 'trg_embedding_pca_3',\n",
       " 'trg_embedding_pca_4',\n",
       " 'trg_embedding_pca_5',\n",
       " 'trg_embedding_pca_6',\n",
       " 'trg_embedding_pca_7',\n",
       " 'trg_embedding_pca_8',\n",
       " 'trg_embedding_pca_9']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
