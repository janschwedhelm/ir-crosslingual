{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import importlib, datetime\n",
    "import copy\n",
    "from sklearn.externals import joblib\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ir_crosslingual.features.element_based' from '/Users/jani/PycharmProjects/ir-crosslingual/ir_crosslingual/features/element_based.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ir_crosslingual.supervised_classification import sup_model\n",
    "importlib.reload(sup_model)\n",
    "\n",
    "from ir_crosslingual.utils import paths\n",
    "importlib.reload(paths)\n",
    "\n",
    "from ir_crosslingual.embeddings import embeddings\n",
    "importlib.reload(embeddings)\n",
    "\n",
    "from ir_crosslingual.sentences import sentences\n",
    "importlib.reload(sentences)\n",
    "\n",
    "from ir_crosslingual.features import element_based\n",
    "importlib.reload(element_based)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- INFO: Learn projection matrix for en-de\n",
      "---- INFO: Found 13700 valid translation pairs in expert dictionary.\n",
      "---- INFO: 977 other pairs contained at least one unknown word (0 in source language, 977 in target language).\n",
      "---- INFO: Resulting subspace dimension: (13700, 300)\n",
      "---- INFO: Resulting subspace dimension: (13700, 300)\n",
      "---- DONE: Projection matrix learned from en to de\n",
      "---- INFO: Learn projection matrix for de-en\n",
      "---- INFO: Found 10604 valid translation pairs in expert dictionary.\n",
      "---- INFO: 262 other pairs contained at least one unknown word (0 in source language, 262 in target language).\n",
      "---- INFO: Resulting subspace dimension: (10604, 300)\n",
      "---- INFO: Resulting subspace dimension: (10604, 300)\n",
      "---- DONE: Projection matrix learned from de to en\n",
      "---- INFO: File loaded containing training data\n",
      "---- INFO: File loaded containing test collection\n",
      "---- DONE: All files loaded and features extracted\n"
     ]
    }
   ],
   "source": [
    "train_file_avg = f'{paths.data_path}extracted_data/global/training_data_tfidf.pkl'\n",
    "test_file_avg = f'{paths.data_path}extracted_data/global/test_collection_tfidf.pkl'\n",
    "sens_avg, train_data_avg, test_collection_avg, features_avg = sentences.Sentences.load_from_file(train_file_avg, test_file_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce embedding dimensionality and extract elements as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_scaler = {}\n",
    "for prefix in ['src', 'trg']:\n",
    "    mean_scaler['{}'.format(prefix)] = StandardScaler(with_std=False)\n",
    "    X = np.vstack(sens_avg.train_data['{}_embedding'.format(prefix)])\n",
    "    mean_scaler['{}'.format(prefix)].fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = {}\n",
    "for prefix in ['src', 'trg']:\n",
    "    pca['{}'.format(prefix)] = PCA(n_components=10, random_state=42)\n",
    "    X = np.vstack(sens_avg.train_data['{}_embedding'.format(prefix)])\n",
    "    X = mean_scaler['{}'.format(prefix)].transform(X)\n",
    "    pca['{}'.format(prefix)].fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- INFO: Unique queries extracted\n",
      "---- INFO: Unique documents extracted\n",
      "---- INFO: Started extraction for src language.\n",
      "---- INFO: src_embedding_pca elements extracted for train data.\n",
      "---- INFO: src_embedding_pca elements extracted for unique queries.\n",
      "---- INFO: Unique queries merged to test collection\n",
      "---- INFO: Started extraction for trg language.\n",
      "---- INFO: trg_embedding_pca elements extracted for train data.\n",
      "---- INFO: trg_embedding_pca elements extracted for unique documents.\n",
      "---- INFO: Unique documents merged to test collection\n",
      "---- DONE: Extracted all vector elements and merged to test collection\n"
     ]
    }
   ],
   "source": [
    "sens_avg = element_based.vec2features(sens_avg, pca, mean_scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove pairs that cointain sentences equal to '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens_avg.train_data = sens_avg.train_data[(sens_avg.train_data['src_sentence'] != '.') & (sens_avg.train_data['trg_sentence'] != '.')]\n",
    "sens_avg.test_collection = sens_avg.test_collection[(sens_avg.test_collection['src_sentence'] != '.') & (sens_avg.test_collection['trg_sentence'] != '.')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale features (z-scores for numerical, OneHotEncoding for categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define features\n",
    "model_features = ['src_sentence', 'trg_sentence', 'translation',\n",
    "                  'norm_diff_translated_words', 'abs_diff_num_words', 'abs_diff_num_punctuation',\n",
    "                  'abs_diff_occ_question_mark', 'abs_diff_occ_exclamation_mark',\n",
    "                  'rel_diff_num_words', 'rel_diff_num_punctuation', 'norm_diff_num_words',\n",
    "                  'norm_diff_num_punctuation', 'euclidean_distance', 'cosine_similarity'] \\\n",
    "                 + ['src_embedding_pca_{}'.format(i) for i in range(10)] \\\n",
    "                 + ['trg_embedding_pca_{}'.format(i) for i in range(10)]\n",
    "num_features = ['norm_diff_translated_words', 'abs_diff_num_words', 'abs_diff_num_punctuation',\n",
    "                'rel_diff_num_words', 'rel_diff_num_punctuation', 'norm_diff_num_words',\n",
    "                'norm_diff_num_punctuation', 'euclidean_distance', 'cosine_similarity'] \\\n",
    "                 + ['src_embedding_pca_{}'.format(i) for i in range(10)] \\\n",
    "                 + ['trg_embedding_pca_{}'.format(i) for i in range(10)]\n",
    "cat_features = ['abs_diff_occ_question_mark', 'abs_diff_occ_exclamation_mark']\n",
    "meta_features = ['src_sentence', 'trg_sentence']\n",
    "label = 'translation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit scaler on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column transformer / scaler\n",
    "numeric_pipeline = make_pipeline(StandardScaler())\n",
    "cat_pipeline     = make_pipeline(OneHotEncoder())\n",
    "\n",
    "transformers = [\n",
    "('num', numeric_pipeline, num_features),\n",
    "('cat', cat_pipeline, cat_features)\n",
    "]\n",
    "\n",
    "ct = ColumnTransformer(transformers, remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function that get feature names of transformed columns\n",
    "def get_transformer_feature_names(columnTransformer):\n",
    "\n",
    "    output_features = []\n",
    "\n",
    "    for name, pipe, features in columnTransformer.transformers_:\n",
    "        if name!='remainder':\n",
    "            for i in pipe:\n",
    "                trans_features = []\n",
    "                if hasattr(i,'categories_'):\n",
    "                    trans_features.extend(i.get_feature_names(features))\n",
    "                else:\n",
    "                    trans_features = features\n",
    "            output_features.extend(trans_features)\n",
    "\n",
    "    return output_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted.\n"
     ]
    }
   ],
   "source": [
    "# fit scaler on training data and scale training columns\n",
    "ct.fit(sens_avg.train_data[model_features])\n",
    "print('Fitted.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data scaled.\n"
     ]
    }
   ],
   "source": [
    "sens_avg.train_data = pd.DataFrame(ct.transform(sens_avg.train_data[model_features]))\n",
    "sens_avg.train_data.columns = get_transformer_feature_names(ct) + meta_features + [label]\n",
    "sens_avg.train_data = sens_avg.train_data.infer_objects()\n",
    "print('Train data scaled.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide test collection into chunks which allows for faster operations on test collection\n",
    "n = 500000  #chunk row size\n",
    "chunks_test_collection = [sens_avg.test_collection[i:i+n] for i in range(0, sens_avg.test_collection.shape[0], n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0 scaled.\n",
      "Chunk 1 scaled.\n",
      "Chunk 2 scaled.\n",
      "Chunk 3 scaled.\n",
      "Chunk 4 scaled.\n",
      "Chunk 5 scaled.\n",
      "Chunk 6 scaled.\n",
      "Chunk 7 scaled.\n",
      "Chunk 8 scaled.\n",
      "Chunk 9 scaled.\n",
      "Chunk 10 scaled.\n",
      "Chunk 11 scaled.\n",
      "Chunk 12 scaled.\n",
      "Chunk 13 scaled.\n",
      "Chunk 14 scaled.\n",
      "Chunk 15 scaled.\n",
      "Chunk 16 scaled.\n",
      "Chunk 17 scaled.\n",
      "Chunk 18 scaled.\n",
      "Chunk 19 scaled.\n"
     ]
    }
   ],
   "source": [
    "# scale columns of test collection\n",
    "for i, chunk in enumerate(chunks_test_collection):\n",
    "    chunks_test_collection[i] = pd.DataFrame(ct.transform(chunk[model_features]))\n",
    "    chunks_test_collection[i].columns = get_transformer_feature_names(ct) + meta_features + [label]\n",
    "    chunks_test_collection[i] = chunks_test_collection[i].infer_objects()\n",
    "    print('Chunk {} scaled.'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update data attribute of Sentences object\n",
    "sens_avg.test_collection = pd.concat([chunk for chunk in chunks_test_collection], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline MLP models using \"TF-IDF\" aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Use self-selected features based on intuition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_1 = 'norm_diff_translated_words norm_diff_num_punctuation abs_diff_occ_question_mark_0 abs_diff_occ_question_mark_1 abs_diff_occ_question_mark_2 abs_diff_occ_exclamation_mark_0 abs_diff_occ_exclamation_mark_1 abs_diff_occ_exclamation_mark_2 norm_diff_num_words euclidean_distance cosine_similarity'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time fitting the multilayer perceptron: 0:00:17.669874\n",
      "Accuracy: 0.9751078078078078\n",
      "Precision: 0.0038502219586852354\n",
      "Recall: 0.9619619619619619\n",
      "F1: 0.007669746004509268\n",
      "---- INFO: Start computing the MAP\n",
      "---- INFO: Probabilities predicted\n",
      "---- INFO: Dataframe with evaluation ranking created\n",
      "---- INFO: Probabilities sorted for each query\n",
      "---- INFO: Index of ranking of true translation retrieved\n",
      "MAP: 0.8241543836769055\n"
     ]
    }
   ],
   "source": [
    "# Create baseline MLP classifier\n",
    "mlp_1 = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(5,), random_state=1, learning_rate='adaptive', activation='tanh')\n",
    "\n",
    "# Fit baseline model on training data\n",
    "start = datetime.datetime.now()\n",
    "mlp_1.fit(sens_avg.train_data[features_1], sens_avg.train_data[label])\n",
    "stop = datetime.datetime.now()\n",
    "print('Computation time fitting the multilayer perceptron: {}'.format(stop-start))\n",
    "\n",
    "# Evaluate baseline model on test collection\n",
    "sup = sup_model.SupModel()\n",
    "sup.evaluate_boolean(mlp_1, sens_avg, features_1)\n",
    "print('Accuracy: {}'.format(sup.accuracy))\n",
    "print('Precision: {}'.format(sup.precision))\n",
    "print('Recall: {}'.format(sup.recall))\n",
    "print('F1: {}'.format(sup.f1))\n",
    "\n",
    "print('MAP: {}'.format(sup.compute_map(mlp_1, sens_avg, features_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Use features selected through RFECV (see logistic_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_2 = list(set(features_1 + ['abs_diff_num_words', 'abs_diff_num_punctuation']) - set(['norm_diff_num_punctuation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time fitting the multilayer perceptron: 0:00:14.572112\n",
      "Accuracy: 0.9797467467467468\n",
      "Precision: 0.004810932327202428\n",
      "Recall: 0.978978978978979\n",
      "F1: 0.009574811783480021\n",
      "---- INFO: Start computing the MAP\n",
      "---- INFO: Probabilities predicted\n",
      "---- INFO: Dataframe with evaluation ranking created\n",
      "---- INFO: Probabilities sorted for each query\n",
      "---- INFO: Index of ranking of true translation retrieved\n",
      "MAP: 0.8124413906367084\n"
     ]
    }
   ],
   "source": [
    "# Create baseline MLP classifier\n",
    "mlp_2 = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(5,), random_state=1, learning_rate='adaptive', activation='tanh')\n",
    "\n",
    "# Fit baseline model on training data\n",
    "start = datetime.datetime.now()\n",
    "mlp_2.fit(sens_avg.train_data[features_2], sens_avg.train_data[label])\n",
    "stop = datetime.datetime.now()\n",
    "print('Computation time fitting the multilayer perceptron: {}'.format(stop-start))\n",
    "\n",
    "# Evaluate baseline model on test collection\n",
    "sup = sup_model.SupModel()\n",
    "sup.evaluate_boolean(mlp_2, sens_avg, features_2)\n",
    "print('Accuracy: {}'.format(sup.accuracy))\n",
    "print('Precision: {}'.format(sup.precision))\n",
    "print('Recall: {}'.format(sup.recall))\n",
    "print('F1: {}'.format(sup.f1))\n",
    "\n",
    "print('MAP: {}'.format(sup.compute_map(mlp_2, sens_avg, features_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Use correlation-based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_corr = 'norm_diff_translated_words abs_diff_num_punctuation abs_diff_occ_question_mark_0 abs_diff_occ_question_mark_1 abs_diff_occ_question_mark_2 abs_diff_occ_exclamation_mark_0 abs_diff_occ_exclamation_mark_1 abs_diff_occ_exclamation_mark_2 abs_diff_num_words cosine_similarity'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time fitting the multilayer perceptron: 0:00:10.812997\n",
      "Accuracy: 0.975727927927928\n",
      "Precision: 0.003915606960165992\n",
      "Recall: 0.953953953953954\n",
      "F1: 0.007799201257038103\n",
      "---- INFO: Start computing the MAP\n",
      "---- INFO: Probabilities predicted\n",
      "---- INFO: Dataframe with evaluation ranking created\n",
      "---- INFO: Probabilities sorted for each query\n",
      "---- INFO: Index of ranking of true translation retrieved\n",
      "MAP: 0.8230814144009025\n"
     ]
    }
   ],
   "source": [
    "# Create baseline MLP classifier\n",
    "mlp_corr = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(5,), random_state=1, learning_rate='adaptive', activation='tanh')\n",
    "\n",
    "# Fit baseline model on training data\n",
    "start = datetime.datetime.now()\n",
    "mlp_corr.fit(sens_avg.train_data[features_corr], sens_avg.train_data[label])\n",
    "stop = datetime.datetime.now()\n",
    "print('Computation time fitting the multilayer perceptron: {}'.format(stop-start))\n",
    "\n",
    "# Evaluate baseline model on test collection\n",
    "sup = sup_model.SupModel()\n",
    "sup.evaluate_boolean(mlp_corr, sens_avg, features_corr)\n",
    "print('Accuracy: {}'.format(sup.accuracy))\n",
    "print('Precision: {}'.format(sup.precision))\n",
    "print('Recall: {}'.format(sup.recall))\n",
    "print('F1: {}'.format(sup.f1))\n",
    "\n",
    "print('MAP: {}'.format(sup.compute_map(mlp_corr, sens_avg, features_corr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Use all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_3 = features_2 + ['norm_diff_num_punctuation', 'rel_diff_num_words', 'rel_diff_num_punctuation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time fitting the multilayer perceptron: 0:00:15.807366\n",
      "Accuracy: 0.9781803803803804\n",
      "Precision: 0.0044534986228411955\n",
      "Recall: 0.975975975975976\n",
      "F1: 0.00886653813975483\n",
      "---- INFO: Start computing the MAP\n",
      "---- INFO: Probabilities predicted\n",
      "---- INFO: Dataframe with evaluation ranking created\n",
      "---- INFO: Probabilities sorted for each query\n",
      "---- INFO: Index of ranking of true translation retrieved\n",
      "MAP: 0.8340932730192272\n"
     ]
    }
   ],
   "source": [
    "# Create baseline MLP classifier\n",
    "mlp_3 = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(5,), random_state=1, learning_rate='adaptive', activation='tanh')\n",
    "\n",
    "# Fit baseline model on training data\n",
    "start = datetime.datetime.now()\n",
    "mlp_3.fit(sens_avg.train_data[features_3], sens_avg.train_data[label])\n",
    "stop = datetime.datetime.now()\n",
    "print('Computation time fitting the multilayer perceptron: {}'.format(stop-start))\n",
    "\n",
    "# Evaluate baseline model on test collection\n",
    "sup = sup_model.SupModel()\n",
    "sup.evaluate_boolean(mlp_3, sens_avg, features_3)\n",
    "print('Accuracy: {}'.format(sup.accuracy))\n",
    "print('Precision: {}'.format(sup.precision))\n",
    "print('Recall: {}'.format(sup.recall))\n",
    "print('F1: {}'.format(sup.f1))\n",
    "\n",
    "print('MAP: {}'.format(sup.compute_map(mlp_3, sens_avg, features_3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Use best of {1,2,3,4} + extracted elements of dimension reduced sentence embedding (10-dim) as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_4 = features_3 + ['src_embedding_pca_{}'.format(i) for i in range(10)] + ['trg_embedding_pca_{}'.format(i) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time fitting the multilayer perceptron: 0:00:18.585914\n",
      "Accuracy: 0.9843890890890891\n",
      "Precision: 0.006270631269038121\n",
      "Recall: 0.984984984984985\n",
      "F1: 0.012461927166114703\n",
      "---- INFO: Start computing the MAP\n",
      "---- INFO: Probabilities predicted\n",
      "---- INFO: Dataframe with evaluation ranking created\n",
      "---- INFO: Probabilities sorted for each query\n",
      "---- INFO: Index of ranking of true translation retrieved\n",
      "MAP: 0.8605594531873866\n"
     ]
    }
   ],
   "source": [
    "mlp_4 = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(8,), random_state=1, learning_rate='adaptive', activation='tanh')\n",
    "\n",
    "# Fit baseline model on training data\n",
    "start = datetime.datetime.now()\n",
    "mlp_4.fit(sens_avg.train_data[features_4], sens_avg.train_data[label])\n",
    "stop = datetime.datetime.now()\n",
    "print('Computation time fitting the multilayer perceptron: {}'.format(stop-start))\n",
    "\n",
    "# Evaluate baseline model on test collection\n",
    "sup = sup_model.SupModel()\n",
    "sup.evaluate_boolean(mlp_4, sens_avg, features_4)\n",
    "print('Accuracy: {}'.format(sup.accuracy))\n",
    "print('Precision: {}'.format(sup.precision))\n",
    "print('Recall: {}'.format(sup.recall))\n",
    "print('F1: {}'.format(sup.f1))\n",
    "\n",
    "print('MAP: {}'.format(sup.compute_map(mlp_4, sens_avg, features_4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparametertuning of best model (variant 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create random grid for tuning best model (1st run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden layers\n",
    "hidden_layers = [(4,4), (3,3,2), (8,), (2,2,2,1), (8,3,2), (7,), (9,), (4,3,2)]\n",
    "\n",
    "# Activation function\n",
    "activation = ['identity', 'logistic', 'tanh', 'relu']\n",
    "\n",
    "# Optimizer\n",
    "optimizer = ['lbfgs', 'sgd', 'adam']\n",
    "\n",
    "# Alpha\n",
    "alpha = [0.1, 0.01, 0.001, 0.0001]\n",
    "\n",
    "# Batch size\n",
    "batch_size = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "# Learning rate\n",
    "learning_rate = ['constant', 'invscaling', 'adaptive']\n",
    "\n",
    "# Learning rate init\n",
    "learning_rate_init = [0.1, 0.01, 0.001, 0.0001]\n",
    "\n",
    "# Maximum iterations\n",
    "max_iter = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {\n",
    "    'hidden_layer_sizes': hidden_layers,\n",
    "    'activation': activation,\n",
    "    'solver': optimizer,\n",
    "    'alpha': alpha,\n",
    "    'batch_size': batch_size,\n",
    "    'learning_rate': learning_rate,\n",
    "    'learning_rate_init': learning_rate_init,\n",
    "    'max_iter': max_iter\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform random search for optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, random_state=42)\n",
    "mlp = MLPClassifier(random_state=42)\n",
    "randomized_search = RandomizedSearchCV(estimator = mlp, param_distributions = parameter_grid, n_iter = 50, \n",
    "                                       cv = cv, verbose=20, random_state=42, n_jobs = -1)\n",
    "randomized_search.fit(sens_avg.train_data[features_4], sens_avg.train_data[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate random search to identify optimal hyperparameters and resulting MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'solver': 'lbfgs',\n",
       " 'max_iter': 800,\n",
       " 'learning_rate_init': 0.001,\n",
       " 'learning_rate': 'invscaling',\n",
       " 'hidden_layer_sizes': (8, 3, 2),\n",
       " 'batch_size': 800,\n",
       " 'alpha': 0.0001,\n",
       " 'activation': 'tanh'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify best hyperparameters retrieved by random search\n",
    "randomized_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9746584248534678"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify best hyperparameters retrieved by random search\n",
    "randomized_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit best model on training data\n",
    "best_model = randomized_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time fitting the multilayer perceptron: 0:01:59.143913\n",
      "Accuracy: 0.9841304304304305\n",
      "Precision: 0.006181430631308382\n",
      "Recall: 0.986986986986987\n",
      "F1: 0.012285915431533435\n",
      "---- INFO: Start computing the MAP\n",
      "---- INFO: Probabilities predicted\n",
      "---- INFO: Dataframe with evaluation ranking created\n",
      "---- INFO: Probabilities sorted for each query\n",
      "---- INFO: Index of ranking of true translation retrieved\n",
      "MAP: 0.8720985970673748\n"
     ]
    }
   ],
   "source": [
    "# Evaluate best model on test collection\n",
    "start = datetime.datetime.now()\n",
    "best_model.fit(sens_avg.train_data[features_4], sens_avg.train_data[label])\n",
    "stop = datetime.datetime.now()\n",
    "print('Computation time fitting the multilayer perceptron: {}'.format(stop-start))\n",
    "\n",
    "# Evaluation on test collection\n",
    "sup = sup_model.SupModel()\n",
    "sup.evaluate_boolean(best_model, sens_avg, features_4)\n",
    "print('Accuracy: {}'.format(sup.accuracy))\n",
    "print('Precision: {}'.format(sup.precision))\n",
    "print('Recall: {}'.format(sup.recall))\n",
    "print('F1: {}'.format(sup.f1))\n",
    "\n",
    "print('MAP: {}'.format(sup.compute_map(best_model, sens_avg, features_4)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
